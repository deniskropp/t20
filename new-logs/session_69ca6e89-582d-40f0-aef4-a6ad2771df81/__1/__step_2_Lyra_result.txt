{"output":"Defined the high-level architecture for the TypeScript Node.js runtime based on the extracted Task Agnostic Steps (TAS). This includes identifying key modules, classes, and their interactions, adhering to SOTA principles.","artifact":{"task":"T3","files":[{"path":"src/index.ts","content":"import { System } from './system/System';\nimport { Agent } from './agent/Agent';\nimport { Orchestrator } from './orchestrator/Orchestrator';\nimport { Session } from './core/Session';\nimport { ExecutionContext } from './core/ExecutionContext';\nimport { LLM } from './llm/LLM';\nimport { Logger } from './logger/Logger';\nimport { Config } from './config/Config';\nimport { Plan, Task, Artifact, Role, Prompt, Team, AgentOutput, File } from './custom_types';\n\nexport {\n  System,\n  Agent,\n  Orchestrator,\n  Session,\n  ExecutionContext,\n  LLM,\n  Logger,\n  Config,\n  Plan,\n  Task,\n  Artifact,\n  Role,\n  Prompt,\n  Team,\n  AgentOutput,\n  File\n};\n\n// Export default logger instance\nexport const logger = Logger.getInstance();\n\n// Example usage (can be moved to a CLI entry point like sysmain.ts later)\nasync function main() {\n  logger.info('Starting runtime initialization...');\n\n  try {\n    // 1. Load Configuration\n    const config = await Config.load('runtime.yaml'); // Assuming runtime.yaml is in the root or a config dir\n    logger.info('Configuration loaded successfully.');\n\n    // 2. Initialize System\n    const system = new System(config.projectRoot || '.', config.defaultModel || 'gemini-2.5-flash-lite');\n    await system.setup(); // Load agents, prompts, etc.\n    logger.info('System setup complete.');\n\n    // 3. Define a high-level goal and initial files (example)\n    const highLevelGoal = 'Reimplement runtime using TypeScript in Node.js following SOTA coding principles';\n    const initialFiles: File[] = [\n      // Example: { path: 'docs/runtime.md', content: '...' } \n    ];\n\n    // 4. Start the workflow to generate a plan\n    const plan = await system.start(highLevelGoal, initialFiles);\n    logger.info('Workflow plan generated.');\n    console.log('\\n--- Generated Plan ---');\n    console.log(JSON.stringify(plan, null, 2));\n    console.log('----------------------\\n');\n\n    // 5. Run the workflow for a specified number of rounds\n    const rounds = config.workflowRounds || 3;\n    await system.run(plan, rounds, initialFiles);\n    logger.info('Workflow execution finished.');\n\n  } catch (error) {\n    logger.error('Runtime initialization failed:', error);\n  }\n}\n\n// Uncomment to run the example main function\n// main();\n"},{"path":"src/system/System.ts","content":"import { Agent, AgentSpec, PromptSpec } from '../agent/Agent';\nimport { Orchestrator } from '../orchestrator/Orchestrator';\nimport { Session } from '../core/Session';\nimport { ExecutionContext } from '../core/ExecutionContext';\nimport { LLM } from '../llm/LLM';\nimport { Logger } from '../logger/Logger';\nimport { Config } from '../config/Config';\nimport { Plan, Task, Artifact, Role, Prompt, Team, AgentOutput, File } from '../custom_types';\nimport { readFileSync } from 'fs';\nimport { join } from 'path';\n\nconst logger = Logger.getInstance();\n\nexport class System {\n  private config: Config;\n  private agents: Agent[] = [];\n  private session: Session | null = null;\n  private orchestrator: Orchestrator | null = null;\n  private readonly rootDir: string;\n  private readonly defaultModel: string;\n\n  constructor(rootDir: string, defaultModel: string = 'gemini-2.5-flash-lite') {\n    this.rootDir = rootDir;\n    this.defaultModel = defaultModel;\n    logger.info(`System initialized with root directory: ${this.rootDir} and default model: ${this.defaultModel}`);\n  }\n\n  async setup(): Promise<void> {\n    logger.info('--- System Setup ---');\n    this.config = await Config.load('runtime.yaml', this.rootDir);\n    logger.info('Configuration loaded.');\n\n    const agentSpecs = this._loadAgentSpecs(join(this.rootDir, this.config.agentDir || 'agents'));\n    const prompts = this._loadPrompts(join(this.rootDir, this.config.promptDir || 'prompts'));\n\n    const allTeamMembers = new Set<string>();\n    agentSpecs.forEach(spec => {\n      spec.team?.forEach(member => allTeamMembers.add(member.name.toLowerCase()));\n    });\n\n    // Instantiate agents, excluding those already defined as part of another agent's team\n    for (const spec of agentSpecs) {\n      if (!allTeamMembers.has(spec.name.toLowerCase())) {\n        const agent = this._instantiateAgent(spec, prompts, agentSpecs);\n        if (agent) {\n          this.agents.push(agent);\n        }\n      }\n    }\n\n    if (this.agents.length === 0) {\n      throw new Error('No agents could be instantiated. System setup failed.');\n    }\n\n    // Find and set the orchestrator\n    const orchestratorSpec = this.agents.find(\n      agent => agent.role.toLowerCase() === 'orchestrator'\n    );\n    if (!orchestratorSpec) {\n      throw new Error('Orchestrator agent not found. System setup failed.');\n    }\n    this.orchestrator = orchestratorSpec as Orchestrator;\n    logger.info(`Orchestrator set to: ${this.orchestrator.name}`);\n\n    // Initialize session\n    this.session = new Session(this.agents, this.rootDir);\n    logger.info('Session initialized.');\n\n    logger.info('--- System Setup Complete ---');\n  }\n\n  async start(highLevelGoal: string, initialFiles: File[] = []): Promise<Plan> {\n    if (!this.orchestrator || !this.session) {\n      throw new Error('System is not set up. Please call setup() before start().');\n    }\n\n    logger.info(`Generating plan for goal: \"${highLevelGoal}\"`);\n    const plan = await this.orchestrator.generatePlan(this.session, highLevelGoal, initialFiles);\n\n    if (!plan) {\n      throw new Error('Orchestration failed: Could not generate a valid plan.');\n    }\n\n    logger.info('Plan generated successfully.');\n    this.session.addArtifact('initial_plan.json', JSON.stringify(plan.toJSON(), null, 2));\n    logger.debug(`Plan details: ${JSON.stringify(plan)}`);\n\n    return plan;\n  }\n\n  async run(plan: Plan, rounds: number = 1, initialFiles: File[] = []): Promise<void> {\n    if (!this.orchestrator || !this.session) {\n      throw new Error('System is not set up. Please call start() before run().');\n    }\n\n    logger.info(`--- Starting Workflow (Rounds: ${rounds}) ---`);\n\n    const context = new ExecutionContext(this.session, plan);\n    context.recordInitial('files', new Artifact({ task: 'initial', files: initialFiles }));\n\n    for (let roundNum = 1; roundNum <= rounds; roundNum++) {\n      context.roundNum = roundNum;\n      context.resetStepIndex();\n      logger.info(`Starting workflow round ${roundNum} for goal: \"${plan.highLevelGoal}\"`);\n\n      while (context.stepIndex < plan.tasks.length) {\n        const currentTask = context.currentStep();\n        let delegateAgent = this.agents.find(agent => agent.name.toLowerCase() === currentTask.agent.toLowerCase());\n\n        if (!delegateAgent) {\n          logger.warn(`Agent '${currentTask.agent}' not found for task '${currentTask.description}'. Falling back to Orchestrator.`);\n          delegateAgent = this.orchestrator;\n        }\n\n        logger.info(`Executing step ${context.stepIndex + 1}/${plan.tasks.length}: '${currentTask.description}' by Agent '${delegateAgent.name}' (Role: ${currentTask.role})`);\n\n        try {\n          const agentOutput = await delegateAgent.executeTask(context);\n          if (agentOutput) {\n            context.recordArtifact(`${delegateAgent.name}_result.txt`, agentOutput.output, true);\n            if (agentOutput.artifact) {\n              agentOutput.artifact.files.forEach(file => {\n                this.session?.addArtifact(file.path, file.content);\n                console.log(`\\n--- File: ${file.path} ---\\n${file.content}\\n`);\n              });\n            }\n            if (agentOutput.team?.prompts) {\n              logger.info(`Agent '${delegateAgent.name}' provided ${agentOutput.team.prompts.length} prompt updates.`);\n              for (const promptData of agentOutput.team.prompts) {\n                this._updateAgentPrompt(promptData.agent, promptData.systemPrompt);\n              }\n            }\n          }\n        } catch (error) {\n          logger.error(`Error executing task '${currentTask.description}' by agent '${delegateAgent.name}':`, error);\n          // Decide on error handling strategy: stop, retry, or continue\n          // For now, we log and continue to the next task.\n        }\n        context.nextStep();\n      }\n      logger.info(`Completed workflow round ${roundNum}.`);\n    }\n\n    logger.info('--- Workflow Complete ---');\n  }\n\n  private _updateAgentPrompt(agentName: string, newPrompt: string): void {\n    const targetAgent = this.agents.find(agent => agent.name.toLowerCase() === agentName.toLowerCase());\n    if (targetAgent) {\n      targetAgent.updateSystemPrompt(newPrompt);\n      logger.info(`Updated system prompt for agent '${targetAgent.name}'.`);\n    } else {\n      logger.warn(`Agent '${agentName}' not found for prompt update.`);\n    }\n  }\n\n  private _instantiateAgent(spec: AgentSpec, prompts: Record<string, string>, allAgentSpecs: AgentSpec[]): Agent | null {\n    const promptKey = `${spec.name.toLowerCase()}_instructions.txt`;\n    const systemPrompt = prompts[promptKey] || spec.systemPrompt || ''; // Use provided systemPrompt if available, else default to empty\n\n    const model = spec.model || this.defaultModel;\n\n    let agent: Agent;\n\n    // Special handling for Orchestrator to ensure it's an Orchestrator instance\n    if (spec.role.toLowerCase() === 'orchestrator') {\n      agent = new Orchestrator(\n        spec.name,\n        spec.role,\n        spec.goal,\n        model,\n        systemPrompt\n      );\n      // Pass team members to Orchestrator\n      if (spec.team && spec.team.length > 0) {\n        (agent as Orchestrator).team = this._buildTeam(spec.team, prompts, allAgentSpecs);\n      }\n    } else {\n      agent = new Agent(\n        spec.name,\n        spec.role,\n        spec.goal,\n        model,\n        systemPrompt\n      );\n    }\n\n    logger.info(`Instantiated Agent: ${agent.name} (Role: ${agent.role}, Model: ${agent.model})`);\n    return agent;\n  }\n\n  private _buildTeam(teamSpecs: PromptSpec[], allAgentSpecs: AgentSpec[], depth = 0): Record<string, Agent> {\n    const team: Record<string, Agent> = {};\n    const maxDepth = 5; // Prevent infinite recursion\n\n    if (depth > maxDepth) {\n      logger.error('Maximum team nesting depth reached. Stopping team creation.');\n      return {};\n    }\n\n    for (const teamSpec of teamSpecs) {\n      const memberSpec = allAgentSpecs.find(spec => spec.name.toLowerCase() === teamSpec.name.toLowerCase());\n      if (memberSpec) {\n        const memberAgent = this._instantiateAgent(memberSpec, this.loadPrompts(join(this.rootDir, this.config.promptDir || 'prompts')), allAgentSpecs, depth + 1);\n        if (memberAgent) {\n          team[teamSpec.name] = memberAgent;\n        } else {\n          logger.warn(`Failed to instantiate team member '${teamSpec.name}'. Skipping.`);\n        }\n      } else {\n        logger.warn(`Team member specification for '${teamSpec.name}' not found. Creating a placeholder agent.`);\n        // Create a placeholder agent if spec is not found\n        const placeholderAgent = new Agent(\n          teamSpec.name,\n          teamSpec.role || 'Unknown Role',\n          teamSpec.goal || 'No specific goal defined',\n          this.defaultModel,\n          '' // No prompt for placeholder\n        );\n        team[teamSpec.name] = placeholderAgent;\n      }\n    }\n    return team;\n  }\n\n  // Helper to load prompts, ensuring it can be called recursively\n  private loadPrompts(promptsDir: string): Record<string, string> {\n    return this._loadPrompts(promptsDir);\n  }\n\n  private _loadAgentSpecs(agentsDir: string): AgentSpec[] {\n    logger.info(`Loading agent specifications from: ${agentsDir}`);\n    const agentFiles = globSync(join(agentsDir, '*.yaml')); // Use globSync for simplicity here\n    const specs: AgentSpec[] = [];\n    agentFiles.forEach(filePath => {\n      try {\n        const content = readFileSync(filePath, 'utf-8');\n        const spec = yaml.load(content) as AgentSpec;\n        // Resolve prompt path relative to the agent file's directory\n        if (spec.systemPromptPath) {\n          const baseDir = dirname(filePath);\n          spec.systemPrompt = readFileSync(join(baseDir, spec.systemPromptPath), 'utf-8');\n        }\n        spec.model = spec.model || this.defaultModel;\n        specs.push(spec);\n        logger.debug(`Loaded agent spec: ${spec.name}`);\n      } catch (error) {\n        logger.error(`Error loading agent spec from ${filePath}:`, error);\n      }\n    });\n    logger.info(`${specs.length} agent specifications loaded.`);\n    return specs;\n  }\n\n  private _loadPrompts(promptsDir: string): Record<string, string> {\n    logger.info(`Loading prompts from: ${promptsDir}`);\n    const promptFiles = globSync(join(promptsDir, '*.txt'));\n    const prompts: Record<string, string> = {};\n    promptFiles.forEach(filePath => {\n      try {\n        const content = readFileSync(filePath, 'utf-8');\n        const fileName = basename(filePath);\n        prompts[fileName] = content;\n        logger.debug(`Loaded prompt: ${fileName}`);\n      } catch (error) {\n        logger.error(`Error loading prompt from ${filePath}:`, error);\n      }\n    });\n    logger.info(`${Object.keys(prompts).length} prompts loaded.`);\n    return prompts;\n  }\n}\n\n// Mock implementations for dependencies used in System class for demonstration purposes\n// In a real project, these would be imported from their respective modules.\n\n// Mock AgentSpec and PromptSpec interfaces (should be defined in Agent.ts)\ninterface AgentSpec {\n  name: string;\n  role: string;\n  goal: string;\n  model?: string;\n  systemPrompt?: string;\n  systemPromptPath?: string;\n  team?: PromptSpec[];\n}\n\ninterface PromptSpec {\n  name: string;\n  role?: string;\n  goal?: string;\n}\n\n// Mock necessary imports from 'fs' and 'path' if not using a full Node.js environment setup\n// For example, using 'glob' and 'js-yaml' would require their respective imports and installations.\n\n// Placeholder for glob and yaml imports - in a real project, install and import them:\n// import { globSync } from 'glob';\n// import * as yaml from 'js-yaml';\n// import { readFileSync } from 'fs';\n// import { join, basename, dirname } from 'path';\n\n// Dummy implementations for globSync, yaml.load, readFileSync, join, basename, dirname\nconst globSync = (pattern: string): string[] => {\n  logger.warn('Using dummy globSync implementation. Install "},{"path":"src/agent/Agent.ts","content":"import { LLM } from '../llm/LLM';\nimport { ExecutionContext } from '../core/ExecutionContext';\nimport { Session } from '../core/Session';\nimport { Logger } from '../logger/Logger';\nimport { Plan, Task, Artifact, AgentOutput, File, Team } from '../custom_types';\nimport { readFileSync } from 'fs';\nimport { join } from 'path';\n\nconst logger = Logger.getInstance();\n\nexport interface AgentSpec {\n  name: string;\n  role: string;\n  goal: string;\n  model?: string;\n  systemPrompt?: string;\n  systemPromptPath?: string;\n  team?: PromptSpec[];\n}\n\nexport interface PromptSpec {\n  name: string;\n  role?: string;\n  goal?: string;\n}\n\nexport class Agent {\n  public name: string;\n  public role: string;\n  public goal: string;\n  protected systemPrompt: string;\n  protected llm: LLM;\n  protected model: string;\n  public team: Record<string, Agent> = {}; // For Orchestrator's delegation\n\n  constructor(name: string, role: string, goal: string, model: string, systemPrompt: string) {\n    this.name = name;\n    this.role = role;\n    this.goal = goal;\n    this.model = model;\n    this.systemPrompt = systemPrompt;\n    this.llm = LLM.factory(model);\n    logger.info(`Agent instance created: ${this.name} (Role: ${this.role}, Model: ${this.model})`);\n  }\n\n  updateSystemPrompt(newPrompt: string): void {\n    this.systemPrompt = newPrompt;\n    logger.info(`Agent ${this.name}'s system prompt updated.`);\n  }\n\n  async executeTask(context: ExecutionContext): Promise<AgentOutput | null> {\n    const currentTask = context.currentStep();\n    const previousArtifactsContent = await this._getPreviousArtifacts(context);\n\n    const taskPrompt = [\n      `The overall goal is: '${context.plan.highLevelGoal}'`,\n      `Your role's specific goal is: '${this.goal}'`,\n      `Your specific sub-task is: '${currentTask.description}'`,\n      `The team's roles are:\n${JSON.stringify(context.plan.roles.map((role: Role) => ({ title: role.title, purpose: role.purpose })), null, 2)}`,\n    ].join('\\n\\n');\n\n    let fullPrompt = taskPrompt;\n    if (previousArtifactsContent) {\n      fullPrompt += `\\n\\nPlease use the following outputs from other agents as your input:\\n\\n${previousArtifactsContent}\\n\\n`;\n    }\n    fullPrompt += `Please execute your sub-task, keeping the overall goal and your role's specific goal in mind to ensure your output is relevant to the project. Respond in a JSON format that includes 'output', and optionally 'artifact' and 'team' fields.`\n\n    logger.debug(`Constructed prompt for ${this.name} for task ${currentTask.id}:\n${fullPrompt}`);\n\n    // Record the prompt used for this task\n    context.recordArtifact(`${this.name}_prompt_${currentTask.id}.txt`, fullPrompt);\n\n    try {\n      const response = await this.llm.generateContent({\n        modelName: this.model,\n        contents: fullPrompt,\n        systemInstruction: this.systemPrompt,\n        responseSchema: AgentOutput,\n        responseMimeType: 'application/json',\n      });\n\n      if (!response) {\n        logger.error(`LLM returned no response for task ${currentTask.id} by ${this.name}.`);\n        return null;\n      }\n\n      // Ensure the response is parsed as AgentOutput\n      if (typeof response === 'string') {\n          try {\n              const parsedOutput = AgentOutput.parse(JSON.parse(response));\n              logger.info(`Agent ${this.name} completed task: ${currentTask.description}`);\n              this._processAndRecordArtifacts(context, parsedOutput);\n              return parsedOutput;\n          } catch (parseError) {\n              logger.error(`Failed to parse LLM response as AgentOutput for task ${currentTask.id} by ${this.name}:`, parseError);\n              logger.error(`Raw LLM response: ${response}`);\n              // Attempt to record raw output if it's not a valid JSON\n              context.recordArtifact(`${this.name}_raw_output_${currentTask.id}.txt`, response);\n              return new AgentOutput({ output: `Error processing response: ${response}`, reasoning: 'LLM response was not valid JSON or AgentOutput schema.' });\n          }\n      } else if (response instanceof AgentOutput) {\n          logger.info(`Agent ${this.name} completed task: ${currentTask.description}`);\n          this._processAndRecordArtifacts(context, response);\n          return response;\n      }\n\n      // Fallback for unexpected response types\n      logger.warn(`Unexpected response type from LLM for task ${currentTask.id} by ${this.name}: ${typeof response}`);\n      return new AgentOutput({ output: `Unexpected response type: ${JSON.stringify(response)}`, reasoning: 'LLM returned an unexpected data type.' });\n\n    } catch (error) {\n      logger.error(`Error during LLM interaction for task ${currentTask.id} by ${this.name}:`, error);\n      // Record the error as an artifact\n      context.recordArtifact(`${this.name}_error_${currentTask.id}.txt`, `Error: ${error.message}`);\n      return new AgentOutput({ output: `Error executing task: ${error.message}`, reasoning: 'LLM interaction failed.' });\n    }\n  }\n\n  private async _getPreviousArtifacts(context: ExecutionContext): Promise<string> {\n    const requiredTaskIds = ['initial', ...context.currentStep().requires];\n    const relevantArtifacts: string[] = [];\n\n    // Iterate through all recorded items in the context\n    for (const [key, contextItem] of Object.entries(context.items)) {\n      if (requiredTaskIds.includes(contextItem.step.id)) {\n        let artifactContent = '';\n        if (typeof contextItem.content === 'string') {\n          artifactContent = contextItem.content;\n        } else if (contextItem.content instanceof Artifact) {\n          artifactContent = contextItem.content.files.map(file => `--- File: ${file.path} ---\\n${file.content}`).join('\\n');\n        } else {\n          try {\n            artifactContent = JSON.stringify(contextItem.content, null, 2);\n          } catch (e) {\n            artifactContent = String(contextItem.content); // Fallback to string conversion\n          }\n        }\n        relevantArtifacts.push(`--- Artifact '${key}' from (${contextItem.step.role}) in [${contextItem.step.id}]:\\n${artifactContent}`);\n      }\n    }\n\n    return relevantArtifacts.join('\\n\\n');\n  }\n\n  private _processAndRecordArtifacts(context: ExecutionContext, agentOutput: AgentOutput): void {\n    // Record the main output\n    context.recordArtifact(`${this.name}_output.txt`, agentOutput.output, true);\n\n    // Record artifacts if present\n    if (agentOutput.artifact && agentOutput.artifact.files) {\n      agentOutput.artifact.files.forEach(file => {\n        context.session?.addArtifact(file.path, file.content);\n        console.log(`\\n--- File: ${file.path} ---\\n${file.content}\\n`);\n        // Record file artifact in context if it's meant to be remembered\n        // For simplicity, we'll assume all files in artifact are relevant for context\n        context.recordArtifact(file.path, agentOutput.artifact as Artifact, true); // Record the whole artifact object for context\n      });\n    }\n\n    // Record reasoning if present\n    if (agentOutput.reasoning) {\n      context.recordArtifact(`${this.name}_reasoning.txt`, agentOutput.reasoning, true);\n    }\n\n    // Handle team updates (e.g., new prompts)\n    if (agentOutput.team && agentOutput.team.prompts) {\n      logger.info(`Agent ${this.name} provided ${agentOutput.team.prompts.length} team updates (prompts).`);\n      // The System class will handle applying these updates to the agents\n    }\n  }\n}\n"},{"path":"src/orchestrator/Orchestrator.ts","content":"import { Agent, AgentSpec, PromptSpec } from '../agent/Agent';\nimport { ExecutionContext } from '../core/ExecutionContext';\nimport { Session } from '../core/Session';\nimport { Logger } from '../logger/Logger';\nimport { Plan, Task, File, Role, AgentOutput } from '../custom_types';\nimport { readFileSync } from 'fs';\nimport { join } from 'path';\n\nconst logger = Logger.getInstance();\n\nexport class Orchestrator extends Agent {\n  // Orchestrator might have a more complex team structure or delegation logic\n  // For now, we'll keep it simple and assume 'team' is managed by the System class\n\n  constructor(name: string, role: string, goal: string, model: string, systemPrompt: string) {\n    super(name, role, goal, model, systemPrompt);\n    logger.info(`Orchestrator instance created: ${this.name}`);\n  }\n\n  async generatePlan(session: Session, highLevelGoal: string, initialFiles: File[] = []): Promise<Plan | null> {\n    logger.info(`Orchestrator '${this.name}' is generating a plan for: \"${highLevelGoal}\"`);\n\n    if (!this.llm) {\n      logger.error('LLM client not initialized for Orchestrator.');\n      return null;\n    }\n\n    // Get available agents and their details for the prompt\n    const availableAgents = session.agents.map(agent => ({\n      name: agent.name,\n      role: agent.role,\n      goal: agent.goal,\n    }));\n\n    const agentDescription = availableAgents.map(agent => \n      `- Name: '${agent.name}'\\n  Role: \n${agent.role}\n  Goal: \"${agent.goal}\"`\n    ).join('\\n');\n\n    // Load the planning prompt template\n    // In a real scenario, this path would be relative to the project root or a config dir\n    const promptTemplatePath = join(__dirname, '..', '..', 'prompts', 'general_planning.txt');\n    let promptTemplate: string;\n    try {\n      promptTemplate = readFileSync(promptTemplatePath, 'utf-8');\n    } catch (error) {\n      logger.error(`Failed to load planning prompt template from ${promptTemplatePath}:`, error);\n      return null;\n    }\n\n    const planningPrompt = promptTemplate.format({\n      highLevelGoal: highLevelGoal,\n      teamDescription: agentDescription,\n      initialFiles: initialFiles.map(f => `--- File: ${f.path}\\n```\\n${f.content}\\n````).join('\\n\\n')\n    });\n\n    logger.debug(`Constructed planning prompt for Orchestrator:\n${planningPrompt}`);\n    session.addArtifact('planning_prompt.txt', planningPrompt);\n\n    try {\n      const response = await this.llm.generateContent({\n        modelName: this.model,\n        contents: planningPrompt,\n        systemInstruction: this.systemPrompt,\n        responseSchema: Plan,\n        responseMimeType: 'application/json',\n        temperature: 0.1, // Lower temperature for more deterministic planning\n      });\n\n      if (!response) {\n        logger.error('LLM returned no response for plan generation.');\n        return null;\n      }\n\n      // Ensure the response is parsed as Plan\n      if (typeof response === 'string') {\n        try {\n          const plan = Plan.parse(JSON.parse(response));\n          return plan;\n        } catch (parseError) {\n          logger.error('Failed to parse LLM response as Plan:', parseError);\n          logger.error(`Raw LLM response: ${response}`);\n          session.addArtifact('plan_generation_error.txt', `LLM response was not valid JSON or Plan schema: ${response}`);\n          return null;\n        }\n      } else if (response instanceof Plan) {\n        return response;\n      }\n\n      logger.error(`Unexpected response type from LLM during plan generation: ${typeof response}`);\n      return null;\n\n    } catch (error) {\n      logger.error('Error during plan generation:', error);\n      session.addArtifact('plan_generation_error.txt', `Error: ${error.message}`);\n      return null;\n    }\n  }\n\n  // Override executeTask to potentially handle plan execution logic if needed, or delegate\n  async executeTask(context: ExecutionContext): Promise<AgentOutput | null> {\n    // For the Orchestrator, executeTask might be used to refine the plan or handle meta-tasks.\n    // In this architecture, the System class drives the task execution based on the plan.\n    // If the Orchestrator is assigned a specific task in the plan, it needs to handle it.\n    logger.warn(`Orchestrator '${this.name}' executeTask called directly. This is usually handled by the System. Task: '${context.currentStep().description}'`);\n    \n    // Default behavior: delegate to the base Agent class to process the task prompt\n    // This might be useful if the orchestrator needs to perform a specific task defined in the plan\n    // e.g., \"Refine the plan based on new information\".\n    return super.executeTask(context);\n  }\n}\n"},{"path":"src/core/Session.ts","content":"import { Agent } from '../agent/Agent';\nimport { Logger } from '../logger/Logger';\nimport { Plan, Artifact, File } from '../custom_types';\nimport { join, dirname as getDirname } from 'path';\nimport { existsSync, mkdirSync, writeFileSync, readFileSync } from 'fs';\nimport * as yaml from 'js-yaml';\n\nconst logger = Logger.getInstance();\n\nexport class Session {\n  public readonly sessionId: string;\n  public readonly agents: Agent[];\n  public state: string;\n  public readonly sessionDir: string;\n  public readonly projectRoot: string;\n\n  constructor(agents: Agent[], projectRoot: string, sessionId?: string) {\n    this.sessionId = sessionId || `session_${Date.now().toString()}`;\n    this.agents = agents;\n    this.state = 'initialized';\n    this.projectRoot = projectRoot;\n    this.sessionDir = join(this.projectRoot, 'sessions', this.sessionId);\n\n    if (!existsSync(this.sessionDir)) {\n      mkdirSync(this.sessionDir, { recursive: true });\n    }\n    logger.info(`Session created: ${this.sessionId} (Directory: ${this.sessionDir})`);\n  }\n\n  addArtifact(name: string, content: any): void {\n    const artifactPath = join(this.sessionDir, name);\n    try {\n      const dir = getDirname(artifactPath);\n      if (!existsSync(dir)) {\n        mkdirSync(dir, { recursive: true });\n      }\n      // Determine if content should be saved as JSON or plain text\n      let contentToWrite: string;\n      if (typeof content === 'object' && content !== null && !(content instanceof File) && !(content instanceof Artifact)) {\n        // If it's a plain object (like from AgentOutput.toJSON()), save as JSON\n        contentToWrite = JSON.stringify(content, null, 2);\n      } else if (typeof content === 'string') {\n        contentToWrite = content;\n      } else {\n        // Fallback for other types, convert to string\n        contentToWrite = String(content);\n      }\n\n      writeFileSync(artifactPath, contentToWrite, 'utf-8');\n      logger.info(`Artifact '${name}' saved in session ${this.sessionId}.`);\n    } catch (e) {\n      logger.error(`Error saving artifact '${name}' in session ${this.sessionId}:`, e);\n    }\n  }\n\n  getArtifact(name: string): any {\n    const artifactPath = join(this.sessionDir, name);\n    try {\n      if (existsSync(artifactPath)) {\n        const content = readFileSync(artifactPath, 'utf-8');\n        if (name.endsWith('.json')) {\n          try {\n            return JSON.parse(content);\n          } catch (e) {\n            logger.error(`Error parsing JSON artifact '${name}':`, e);\n            return null;\n          }\n        }\n        return content;\n      } else {\n        logger.warn(`Artifact '${name}' not found in session ${this.sessionId}.`);\n        return null;\n      }\n    } catch (e) {\n      logger.error(`Error retrieving artifact '${name}' from session ${this.sessionId}:`, e);\n      return null;\n    }\n  }\n}\n"},{"path":"src/core/ExecutionContext.ts","content":"import { Session } from './Session';\nimport { Plan, Task, Artifact, File } from '../custom_types';\nimport { Logger } from '../logger/Logger';\n\nconst logger = Logger.getInstance();\n\nexport interface ContextItem {\n  name: string;\n  content: any;\n  step: Task;\n}\n\nexport class ExecutionContext {\n  public session: Session;\n  public plan: Plan;\n  public stepIndex: number;\n  public roundNum: number;\n  public items: Record<string, ContextItem>; // Stores artifacts remembered from previous steps/rounds\n\n  constructor(session: Session, plan: Plan) {\n    this.session = session;\n    this.plan = plan;\n    this.stepIndex = 0;\n    this.roundNum = 1;\n    this.items = {};\n    logger.info('ExecutionContext initialized.');\n  }\n\n  nextStep(): void {\n    this.stepIndex++;\n    logger.debug(`Moved to next step. Current step index: ${this.stepIndex}`);\n  }\n\n  resetStepIndex(): void {\n    this.stepIndex = 0;\n    logger.debug('Step index reset to 0.');\n  }\n\n  currentStep(): Task {\n    if (this.stepIndex >= this.plan.tasks.length) {\n      throw new Error('Step index out of bounds. No more tasks in the plan.');\n    }\n    return this.plan.tasks[this.stepIndex];\n  }\n\n  // Records an artifact for the current step and optionally remembers it for future steps\n  recordArtifact(key: string, value: any, remember: boolean = false): void {\n    const artifactKey = `__${this.roundNum}/__step_${this.stepIndex}_${key}`;\n    this.session.addArtifact(artifactKey, value);\n    if (remember) {\n      this._rememberItem(artifactKey, value, this.currentStep());\n    }\n  }\n\n  // Records initial artifacts provided at the start of the workflow\n  recordInitial(key: string, value: any): void {\n    // Use a special step ID for initial items\n    const initialTask: Task = new Task({\n      id: 'initial',\n      description: 'Initial files provided by the user',\n      role: 'User',\n      agent: 'User',\n      requires: []\n    });\n    this._rememberItem(key, value, initialTask);\n    // Also add to session directly if it's a file artifact\n    if (value instanceof Artifact && value.files) {\n        value.files.forEach(file => this.session.addArtifact(file.path, file.content));\n    }\n    logger.debug(`Recorded initial item '${key}'.`);\n  }\n\n  // Helper to store items in memory (context.items)\n  private _rememberItem(name: string, content: any, step: Task): void {\n    this.items[name] = { name, content, step };\n    logger.debug(`Item '${name}' remembered in context.`);\n  }\n}\n"},{"path":"src/llm/LLM.ts","content":"import { BaseModel } from 'pydantic';\nimport { Logger } from '../logger/Logger';\n\nconst logger = Logger.getInstance();\n\n// Interface for the LLM generation arguments\nexport interface LLMGenerateContentArgs {\n  modelName: string;\n  contents: string;\n  systemInstruction?: string;\n  temperature?: number;\n  responseMimeType?: 'text/plain' | 'application/json' | 'application/json-schema';\n  responseSchema?: typeof BaseModel;\n}\n\nexport abstract class LLM {\n  protected abstract generateContentImpl(args: LLMGenerateContentArgs): Promise<any>;\n\n  /**\n   * Abstract method to generate content using an LLM.\n   * Handles common logic like retries and response parsing.\n   */\n  public async generateContent(args: LLMGenerateContentArgs): Promise<any> {\n    const { modelName, responseSchema, responseMimeType } = args;\n    const maxRetries = 3;\n    let lastError: Error | null = null;\n\n    for (let attempt = 1; attempt <= maxRetries; attempt++) {\n      try {\n        logger.info(`Calling LLM model '${modelName}' (Attempt ${attempt}/${maxRetries})...`);\n        const response = await this.generateContentImpl(args);\n\n        if (!response) {\n          throw new Error('LLM returned an empty response.');\n        }\n\n        // Parse response based on mime type and schema\n        if (responseSchema && responseMimeType === 'application/json') {\n          if (typeof response === 'string') {\n            try {\n              const parsedJson = JSON.parse(response);\n              // Validate against the provided Pydantic schema\n              const validatedData = responseSchema.parse(parsedJson);\n              logger.debug(`LLM response successfully parsed and validated against schema ${responseSchema.name}.`);\n              return validatedData;\n            } catch (e) {\n              lastError = new Error(`Failed to parse or validate LLM JSON response with schema ${responseSchema.name}: ${e.message}`);\n              logger.error(lastError.message);\n              // Do not retry on parsing errors, as the response itself is likely malformed\n              throw lastError;\n            }\n          } else if (response instanceof responseSchema) {\n            logger.debug(`LLM response is already an instance of ${responseSchema.name}.`);\n            return response; // Response is already the correct type\n          } else {\n             lastError = new Error(`LLM response was not a string or expected schema type for JSON request.`);\n             logger.error(lastError.message);\n             throw lastError;\n          }\n        } else if (responseSchema && responseMimeType === 'application/json-schema') {\n            // Handle JSON schema response type if needed\n             if (typeof response === 'string') {\n                try {\n                    // Assuming the schema is directly provided and needs parsing\n                    const parsedSchema = JSON.parse(response);\n                    // Further validation or processing might be needed here based on specific schema requirements\n                    logger.debug('LLM response parsed as JSON Schema.');\n                    return parsedSchema;\n                } catch (e) {\n                     lastError = new Error(`Failed to parse LLM JSON Schema response: ${e.message}`);\n                     logger.error(lastError.message);\n                     throw lastError;\n                }\n            }\n        }\n\n        // Default handling for text or un-schematized JSON\n        logger.debug('LLM response processed.');\n        return response;\n\n      } catch (error) {\n        lastError = error;\n        logger.error(`LLM generation failed (Attempt ${attempt}): ${error.message}`);\n        if (attempt < maxRetries) {\n          const delay = Math.pow(2, attempt) * 1000; // Exponential backoff\n          logger.info(`Waiting for ${delay / 1000} seconds before retrying...`);\n          await new Promise(resolve => setTimeout(resolve, delay));\n        }\n      }\n    }\n\n    logger.error(`LLM generation failed after ${maxRetries} attempts. Last error: ${lastError?.message}`);\n    return null; // Return null if all retries fail\n  }\n\n  /**\n   * Factory method to create an LLM instance based on the species string.\n   * Example species: 'gemini:gemini-pro', 'ollama:llama3', 'openai:gpt-4'.\n   */\n  static factory(species: string): LLM {\n    logger.info(`LLM Factory: Creating LLM instance for species '${species}'`);\n    // TODO: Implement actual factory logic based on species string\n    // This is a placeholder and needs to be replaced with concrete implementations\n    // For now, returning a dummy LLM or a default one.\n    if (species.startsWith('ollama:')) {\n        const modelName = species.split(':')[1];\n        // return new OllamaLLM(modelName);\n        logger.warn('OllamaLLM not implemented. Returning dummy LLM.');\n        return new DummyLLM(modelName); \n    }\n    if (species.startsWith('gemini:') || species === 'gemini-2.5-flash-lite') {\n        const modelName = species.includes(':') ? species.split(':')[1] : species;\n        // return new GeminiLLM(modelName);\n        logger.warn('GeminiLLM not implemented. Returning dummy LLM.');\n        return new DummyLLM(modelName);\n    }\n     if (species.startsWith('openai:') || species.startsWith('gpt:') || species.startsWith('opi:')) {\n        const modelName = species.includes(':') ? species.split(':')[1] : species;\n        // return new OpenAILLM(modelName);\n         logger.warn('OpenAILLM not implemented. Returning dummy LLM.');\n        return new DummyLLM(modelName);\n    }\n    if (species.startsWith('mistral:')) {\n        const modelName = species.split(':')[1];\n        // return new MistralLLM(modelName);\n         logger.warn('MistralLLM not implemented. Returning dummy LLM.');\n        return new DummyLLM(modelName);\n    }\n    // Default or fallback\n    logger.warn(`Unknown LLM species '${species}'. Using DummyLLM as fallback.`);\n    return new DummyLLM(species);\n  }\n}\n\n// Dummy LLM implementation for placeholder purposes\nclass DummyLLM extends LLM {\n  constructor(private modelName: string) {\n    super();\n    logger.warn(`DummyLLM initialized with model: ${this.modelName}. This is a placeholder and will not perform actual LLM calls.`);\n  }\n\n  protected async generateContentImpl(args: LLMGenerateContentArgs): Promise<any> {\n    logger.warn(`DummyLLM: generateContentImpl called for model ${this.modelName}. Returning mock response.`);\n    // Simulate a response based on the schema if provided, otherwise return a generic string\n    if (args.responseSchema) {\n        try {\n            const schemaInstance = args.responseSchema.prototype;\n            const mockResponse = {}; // Create a mock object based on schema properties\n            logger.debug(`Generating mock response for schema: ${args.responseSchema.name}`);\n            // This is a very basic mock, a more sophisticated one would inspect the schema\n            if (args.responseSchema === AgentOutput) {\n                return new AgentOutput({\n                    output: `Mock output for ${this.modelName} task: ${args.contents.substring(0, 50)}...`,\n                    reasoning: 'This is a mock response from DummyLLM.',\n                    artifact: new Artifact({ task: 'mock_task', files: [new File({ path: 'mock_output.txt', content: 'Mock file content.'})]}),\n                    team: new Team({ notes: 'Mock team notes.'})\n                });\n            } else if (args.responseSchema === Plan) {\n                 return new Plan({\n                    highLevelGoal: 'Mock Goal',\n                    reasoning: 'Mock reasoning for plan generation',\n                    roles: [{title: 'Mock Role', purpose: 'Mock Purpose'}],\n                    tasks: [{id: 'T1', description: 'Mock Task', role: 'Mock Role', agent: 'Mock Agent', requires: []}],\n                    team: new Team({ notes: 'Mock team notes.'})\n                });\n            }\n            // Add more schema handlers as needed\n            return schemaInstance;\n        } catch (e) {\n            logger.error(`Error creating mock response for schema ${args.responseSchema.name}:`, e);\n            return `Mock response failed for schema ${args.responseSchema.name}.`;\n        }\n    }\n    \n    return `This is a mock response from DummyLLM for model ${this.modelName}.`;\n  }\n}\n"},{"path":"src/logger/Logger.ts","content":"import winston from 'winston';\nimport { join } from 'path';\nimport fs from 'fs';\n\n// Define log levels\nconst logLevels = {\n  error: 0,\n  warn: 1,\n  info: 2,\n  debug: 3,\n};\n\n// Define log format\nconst logFormat = winston.format.combine(\n  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),\n  winston.format.errors({ stack: true }),\n  winston.format.splat(),\n  winston.format.printf(({ level, message, timestamp, ...metadata }) => {\n    let msg = `${timestamp} [${level.toUpperCase()}]: ${message}`;\n    if (Object.keys(metadata).length > 0) {\n      msg += ` ${JSON.stringify(metadata)}`;\n    }\n    return msg;\n  })\n);\n\nconst jsonLogFormat = winston.format.combine(\n  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),\n  winston.format.errors({ stack: true }),\n  winston.format.splat(),\n  winston.format.json()\n);\n\n// Ensure log directory exists\nconst logDir = process.env.LOG_DIR || 'logs';\nif (!fs.existsSync(logDir)) {\n  fs.mkdirSync(logDir, { recursive: true });\n}\n\nconst logFilePath = join(logDir, 'app.log');\nconst jsonLogFilePath = join(logDir, 'app.jsonl');\n\nexport class Logger {\n  private static instance: winston.Logger;\n\n  public static getInstance(): winston.Logger {\n    if (!Logger.instance) {\n      Logger.instance = winston.createLogger({\n        level: process.env.LOG_LEVEL || 'info',\n        levels: logLevels,\n        format: logFormat, // Default format for console\n        transports: [\n          // Console transport with colorization\n          new winston.transports.Console({\n            format: winston.format.combine(\n              winston.format.colorize({ all: true }),\n              logFormat\n            ),\n          }),\n          // File transport for general logs\n          new winston.transports.File({\n            filename: logFilePath,\n            level: process.env.LOG_LEVEL || 'info',\n            format: logFormat,\n            maxsize: 1024 * 1024 * 5, // 5MB\n            tailable: true,\n          }),\n          // File transport for JSON logs (for easier parsing by other tools)\n          new winston.transports.File({\n            filename: jsonLogFilePath,\n            level: process.env.LOG_LEVEL || 'info',\n            format: jsonLogFormat,\n            maxsize: 1024 * 1024 * 5, // 5MB\n            tailable: true,\n          }),\n        ],\n      });\n      // Add a handler for uncaught exceptions\n      Logger.instance.on('error', (err) => {\n        console.error('Winston logger encountered an error:', err);\n      });\n    }\n    return Logger.instance;\n  }\n}\n"},{"path":"src/config/Config.ts","content":"import { readFileSync } from 'fs';\nimport { join } from 'path';\nimport yaml from 'js-yaml';\nimport { Logger } from '../logger/Logger';\n\nconst logger = Logger.getInstance();\n\nexport interface Config {\n  projectRoot?: string;\n  agentDir?: string;\n  promptDir?: string;\n  logDir?: string;\n  defaultModel?: string;\n  workflowRounds?: number;\n  // Add other configuration properties as needed\n}\n\nexport class Config {\n  public static async load(fileName: string, basePath: string = process.cwd()): Promise<Config> {\n    const configPath = join(basePath, fileName);\n    logger.info(`Attempting to load configuration from: ${configPath}`);\n    try {\n      const fileContents = readFileSync(configPath, 'utf-8');\n      const config = yaml.load(fileContents) as Config;\n      // Set default values if not provided\n      config.projectRoot = config.projectRoot || basePath;\n      config.agentDir = config.agentDir || 'agents';\n      config.promptDir = config.promptDir || 'prompts';\n      config.logDir = config.logDir || 'logs';\n      config.defaultModel = config.defaultModel || 'gemini-2.5-flash-lite';\n      config.workflowRounds = config.workflowRounds || 3;\n\n      logger.info('Configuration loaded successfully.');\n      return config;\n    } catch (error) {\n      logger.error(`Failed to load configuration from ${configPath}:`, error);\n      // Return a default config if file loading fails, or throw an error\n      // For now, returning a minimal default config\n      return {\n        projectRoot: basePath,\n        agentDir: 'agents',\n        promptDir: 'prompts',\n        logDir: 'logs',\n        defaultModel: 'gemini-2.5-flash-lite',\n        workflowRounds: 3,\n      };\n      // Or uncomment below to throw an error and stop execution:\n      // throw new Error(`Failed to load configuration file: ${configPath}`);\n    }\n  }\n}\n"},{"path":"src/custom_types.ts","content":"import { BaseModel, Field, model_validator } from 'pydantic';\nimport { z } from 'zod'; // Using Zod for schema validation demonstration\n\n// --- Task Agnostic Step (TAS) related Types ---\n\nexport class Task extends BaseModel {\n  id: string = Field(..., { description: \"Unique ID for the task (e.g., 'T1', 'T2').\" });\n  description: string = Field(..., { description: \"Detailed description of what to do for this task.\" });\n  role: string = Field(..., { description: \"The role responsible for this task.\" });\n  agent: string = Field(..., { description: \"The agent assigned to this task.\" });\n  requires: string[] = Field([], { description: \"List of tasks (IDs) whose outputs are required (e.g. ['T1', 'T2']).\" });\n}\n\nexport class File extends BaseModel {\n  path: string = Field(..., { description: \"File path or name (e.g., 'src/main.py').\" });\n  content: string = Field(..., { description: \"Full content of the file.\" });\n}\n\nexport class Artifact extends BaseModel {\n  task: string = Field(..., { description: \"ID of the task that produced this artifact (e.g., 'T1').\" });\n  files: File[] = Field([], { description: \"List of files created or modified by the task.\" });\n}\n\nexport class Role extends BaseModel {\n  title: string = Field(..., { description: \"Title of the role (e.g., 'Engineer', 'Reviewer').\" });\n  purpose: string = Field(..., { description: \"The main purpose and goal of this role.\" });\n}\n\nexport class Prompt extends BaseModel {\n  agent: string = Field(..., { description: \"Name of the agent this prompt is for. Must match exactly an existing agent.\" });\n  role: string = Field(..., { description: \"Role context of the agent.\" });\n  systemPrompt: string = Field(..., { description: \"Full text of the system prompt for this agent.\" });\n}\n\nexport class Team extends BaseModel {\n  notes: string = Field('', { description: \"General notes or feedback about the team's performance or the plan.\" });\n  prompts: Prompt[] = Field([], { description: \"A list of new or updated system prompts for any agent in the team.\" });\n}\n\nexport class Plan extends BaseModel {\n  highLevelGoal: string = Field(..., { description: \"The main goal this plan is designed to achieve.\" });\n  reasoning: string = Field(..., { description: \"A brief explanation of the plan's structure and strategy.\" });\n  roles: Role[] = Field([], { description: \"List of all roles required to execute the plan.\" });\n  tasks: Task[] = Field([], { description: \"A step-by-step sequence of tasks to be executed in order.\" });\n  team: Team | null = Field(null, { description: \"Updates to team configuration or system prompts.\" });\n}\n\nexport class AgentOutput extends BaseModel {\n  output: string = Field(..., { description: \"A summary of the work done. Do not include file contents here; use the 'artifact' field instead.\" });\n  artifact: Artifact | null = Field(null, { description: \"Any files created or modified by the agent during the task.\" });\n  team: Team | null = Field(null, { description: \"Updates to team configuration or system prompts.\" });\n  reasoning: string | null = Field(null, { description: \"Explanation of how the agent arrived at this output.\" });\n\n  // Example of adding a custom validator if needed\n  @model_validator(mode='after')\n  def check_output_and_artifact(self) -> 'AgentOutput':\n    if not self.output and not self.artifact:\n      raise ValueError('Agent output must contain either an \"output\" message or an \"artifact\".');\n    return self;\n}\n\n// --- Example Usage & Schema Generation ---\nif (require.main === module) {\n  console.log('--- AgentOutput Schema ---\\n', JSON.stringify(AgentOutput.model_json_schema(), null, 2));\n  console.log('\\n--- Plan Schema ---\\n', JSON.stringify(Plan.model_json_schema(), null, 2));\n}\n"}]},"team":null,"reasoning":null}
{"output":"Project structure, dependencies, and build tools (tsc, esbuild) are set up for the TypeScript Node.js runtime. This includes creating essential directories and configuration files like `package.json`, `tsconfig.json`, and a basic `.eslintrc.js`.","artifact":{"task":"T4","files":[{"path":"package.json","content":"{\n  \"name\": \"typescript-runtime\",\n  \"version\": \"1.0.0\",\n  \"description\": \"A Node.js runtime reimplementation using TypeScript, following SOTA principles.\",\n  \"main\": \"dist/index.js\",\n  \"types\": \"dist/index.d.ts\",\n  \"scripts\": {\n    \"build\": \"tsc && node esbuild.js\",\n    \"dev\": \"tsc -w & node esbuild.js --watch\",\n    \"start\": \"node dist/index.js\",\n    \"lint\": \"eslint . --ext .ts\",\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [\n    \"runtime\",\n    \"typescript\",\n    \"node\",\n    \"agent\",\n    \"llm\"\n  ],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"@types/node\": \"^20.11.19\",\n    \"chalk\": \"^5.3.0\",\n    \"chokidar\": \"^3.5.3\",\n    \"dotenv\": \"^16.4.5\",\n    \"esbuild\": \"^0.20.2\",\n    \"glob\": \"^10.3.10\",\n    \"js-yaml\": \"^4.1.0\",\n    \"pydantic\": \"^2.0.0\",\n    \"winston\": \"^3.11.0\",\n    \"zod\": \"^3.22.7\"\n  },\n  \"devDependencies\": {\n    \"eslint\": \"^8.57.0\",\n    \"eslint-config-prettier\": \"^9.1.0\",\n    \"eslint-plugin-prettier\": \"^5.1.3\",\n    \"prettier\": \"^3.2.5\",\n    \"ts-node\": \"^10.9.2\",\n    \"typescript\": \"^5.3.3\"\n  }\n}\n"},{"path":"tsconfig.json","content":"{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"CommonJS\",\n    \"lib\": [\"ES2020\", \"DOM\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"declaration\": true,\n    \"sourceMap\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"**/*.spec.ts\"]\n}\n"},{"path":"esbuild.js","content":"const esbuild = require('esbuild');\nconst chokidar = require('chokidar');\nconst { join } = require('path');\n\nconst watch = process.argv.includes('--watch');\n\nconst buildOptions = {\n  entryPoints: ['src/index.ts'],\n  bundle: true,\n  outfile: 'dist/index.js',\n  platform: 'node',\n  format: 'cjs',\n  sourcemap: true,\n  target: 'node20',\n  external: ['@types/node', 'fs', 'path', 'os', 'child_process', 'http', 'https', 'crypto'], // Externalize Node.js built-ins and types\n};\n\nasync function build() {\n  try {\n    await esbuild.build(buildOptions);\n    console.log('Build successful!');\n  } catch (err) {\n    console.error('Build failed:', err);\n  }\n}\n\nasync function run() {\n  if (watch) {\n    console.log('Watching for changes...');\n    await build(); // Initial build\n\n    const watcher = chokidar.watch('src/**/*.ts', {\n      ignored: /node_modules/, // Ignore node_modules\n      persistent: true,\n    });\n\n    watcher.on('change', async (filePath) => {\n      console.log(`File changed: ${filePath}`);\n      await build();\n    });\n\n    watcher.on('add', async (filePath) => {\n        console.log(`File added: ${filePath}`);\n        await build();\n    });\n\n    watcher.on('unlink', async (filePath) => {\n        console.log(`File removed: ${filePath}`);\n        await build();\n    });\n\n    // Keep the process running\n    process.stdin.resume();\n\n  } else {\n    await build();\n    process.exit(0); // Exit after build if not watching\n  }\n}\n\nrun().catch(err => {\n  console.error('Error during esbuild process:', err);\n  process.exit(1);\n});\n"},{"path":".eslintrc.js","content":"module.exports = {\n  root: true,\n  parser: '@typescript-eslint/parser',\n  plugins: [\n    '@typescript-eslint',\n    'prettier'\n  ],\n  extends: [\n    'eslint:recommended',\n    'plugin:@typescript-eslint/recommended',\n    'plugin:prettier/recommended'\n  ],\n  parserOptions: {\n    ecmaVersion: 2020,\n    sourceType: 'module',\n    project: './tsconfig.json', // Specify the tsconfig.json file\n  },\n  rules: {\n    // Override rules here if needed\n    '@typescript-eslint/no-explicit-any': 'warn', // Example: Warn about 'any' type\n    '@typescript-eslint/no-unused-vars': 'warn', // Warn about unused variables\n    'prettier/prettier': ['error', {\n      endOfLine: 'lf',\n    }],\n    // Add other rules as per project standards\n  },\n  ignorePatterns: ['node_modules/', 'dist/', '*.d.ts'],\n};\n"},{"path":".prettierrc.js","content":"module.exports = {\n  semi: true,\n  trailingComma: 'es5',\n  singleQuote: true,\n  printWidth: 100,\n  tabWidth: 2,\n  endOfLine: 'lf',\n};\n"},{"path":"src/index.ts","content":"import { System } from './system/System';\nimport { Agent } from './agent/Agent';\nimport { Orchestrator } from './orchestrator/Orchestrator';\nimport { Session } from './core/Session';\nimport { ExecutionContext } from './core/ExecutionContext';\nimport { LLM } from './llm/LLM';\nimport { Logger } from './logger/Logger';\nimport { Config } from './config/Config';\nimport { Plan, Task, Artifact, Role, Prompt, Team, AgentOutput, File } from './custom_types';\n\n// Re-export core components and types for external use\nexport {\n  System,\n  Agent,\n  Orchestrator,\n  Session,\n  ExecutionContext,\n  LLM,\n  Logger,\n  Config,\n  Plan,\n  Task,\n  Artifact,\n  Role,\n  Prompt,\n  Team,\n  AgentOutput,\n  File\n};\n\n// Export default logger instance\nexport const logger = Logger.getInstance();\n\n// Example usage (can be moved to a CLI entry point like sysmain.ts later)\nasync function main() {\n  logger.info('Starting runtime initialization...');\n\n  try {\n    // 1. Load Configuration\n    // Assuming runtime.yaml is in the project root or a config directory\n    const config = await Config.load('runtime.yaml'); \n    logger.info('Configuration loaded successfully.');\n\n    // 2. Initialize System\n    // Use projectRoot from config if available, otherwise default to current directory\n    const system = new System(config.projectRoot || '.', config.defaultModel || 'gemini-2.5-flash-lite');\n    await system.setup(); // Load agents, prompts, etc.\n    logger.info('System setup complete.');\n\n    // 3. Define a high-level goal and initial files (example)\n    // This goal is aligned with the project's objective\n    const highLevelGoal = 'Reimplement runtime using TypeScript in Node.js following SOTA coding principles';\n    const initialFiles: File[] = [\n      // Example: file content could be loaded from actual files during runtime execution\n      // new File({ path: 'docs/runtime.md', content: '...' })\n    ];\n\n    // 4. Start the workflow to generate a plan\n    const plan = await system.start(highLevelGoal, initialFiles);\n    logger.info('Workflow plan generated.');\n    console.log('\\n--- Generated Plan ---');\n    console.log(JSON.stringify(plan.toJSON(), null, 2)); // Use toJSON() for Pydantic models\n    console.log('----------------------\\n');\n\n    // 5. Run the workflow for a specified number of rounds\n    const rounds = config.workflowRounds || 3; // Use rounds from config or default to 3\n    await system.run(plan, rounds, initialFiles);\n    logger.info('Workflow execution finished.');\n\n  } catch (error) {\n    logger.error('Runtime initialization failed:', error);\n  }\n}\n\n// Uncomment the following line to run the example main function when executing this file directly\n// main();\n"},{"path":"src/system/System.ts","content":"import { Agent, AgentSpec, PromptSpec } from '../agent/Agent';\nimport { Orchestrator } from '../orchestrator/Orchestrator';\nimport { Session } from '../core/Session';\nimport { ExecutionContext } from '../core/ExecutionContext';\nimport { LLM } from '../llm/LLM';\nimport { Logger } from '../logger/Logger';\nimport { Config } from '../config/Config';\nimport { Plan, Task, Artifact, Role, Prompt, Team, AgentOutput, File } from '../custom_types';\nimport { readFileSync, existsSync, mkdirSync } from 'fs';\nimport { join, dirname, basename } from 'path';\nimport yaml from 'js-yaml';\nimport { globSync } from 'glob';\n\nconst logger = Logger.getInstance();\n\nexport class System {\n  private config: Config;\n  private agents: Agent[] = [];\n  private session: Session | null = null;\n  private orchestrator: Orchestrator | null = null;\n  private readonly rootDir: string;\n  private readonly defaultModel: string;\n\n  constructor(rootDir: string, defaultModel: string = 'gemini-2.5-flash-lite') {\n    this.rootDir = rootDir;\n    this.defaultModel = defaultModel;\n    logger.info(`System initialized with root directory: ${this.rootDir} and default model: ${this.defaultModel}`);\n  }\n\n  async setup(): Promise<void> {\n    logger.info('--- System Setup ---');\n    this.config = await Config.load('runtime.yaml', this.rootDir);\n    logger.info('Configuration loaded.');\n\n    const agentSpecs = this._loadAgentSpecs(join(this.rootDir, this.config.agentDir || 'agents'));\n    const prompts = this._loadPrompts(join(this.rootDir, this.config.promptDir || 'prompts'));\n\n    const allTeamMembers = new Set<string>();\n    agentSpecs.forEach(spec => {\n      spec.team?.forEach(member => allTeamMembers.add(member.name.toLowerCase()));\n    });\n\n    // Instantiate agents, excluding those already defined as part of another agent's team\n    for (const spec of agentSpecs) {\n      if (!allTeamMembers.has(spec.name.toLowerCase())) {\n        const agent = this._instantiateAgent(spec, prompts, agentSpecs);\n        if (agent) {\n          this.agents.push(agent);\n        }\n      }\n    }\n\n    if (this.agents.length === 0) {\n      throw new Error('No agents could be instantiated. System setup failed.');\n    }\n\n    // Find and set the orchestrator\n    const orchestratorAgentInstance = this.agents.find(\n      agent => agent.role.toLowerCase() === 'orchestrator'\n    );\n    if (!orchestratorAgentInstance) {\n      throw new Error('Orchestrator agent not found. System setup failed.');\n    }\n    // Ensure it's an instance of Orchestrator\n    if (!(orchestratorAgentInstance instanceof Orchestrator)) {\n       throw new Error(`Agent '${orchestratorAgentInstance.name}' is not a valid Orchestrator instance. System setup failed.`);\n    }\n    this.orchestrator = orchestratorAgentInstance;\n    logger.info(`Orchestrator set to: ${this.orchestrator.name}`);\n\n    // Initialize session\n    this.session = new Session(this.agents, this.rootDir);\n    logger.info('Session initialized.');\n\n    logger.info('--- System Setup Complete ---');\n  }\n\n  async start(highLevelGoal: string, initialFiles: File[] = []): Promise<Plan> {\n    if (!this.orchestrator || !this.session) {\n      throw new Error('System is not set up. Please call setup() before start().');\n    }\n\n    logger.info(`Generating plan for goal: \"${highLevelGoal}\"`);\n    // The orchestrator's generatePlan method is called here\n    const plan = await this.orchestrator.generatePlan(this.session, highLevelGoal, initialFiles);\n\n    if (!plan) {\n      throw new Error('Orchestration failed: Could not generate a valid plan.');\n    }\n\n    logger.info('Plan generated successfully.');\n    this.session.addArtifact('initial_plan.json', JSON.stringify(plan.toJSON(), null, 2));\n    logger.debug(`Plan details: ${JSON.stringify(plan.toJSON())}`);\n\n    return plan;\n  }\n\n  async run(plan: Plan, rounds: number = 1, initialFiles: File[] = []): Promise<void> {\n    if (!this.orchestrator || !this.session) {\n      throw new Error('System is not set up. Please call start() before run().');\n    }\n\n    logger.info(`--- Starting Workflow (Rounds: ${rounds}) ---`);\n\n    const context = new ExecutionContext(this.session, plan);\n    // Record initial files as an artifact in the context\n    context.recordInitial('files', new Artifact({ task: 'initial', files: initialFiles }));\n\n    for (let roundNum = 1; roundNum <= rounds; roundNum++) {\n      context.roundNum = roundNum;\n      context.resetStepIndex();\n      logger.info(`Starting workflow round ${roundNum} for goal: \"${plan.highLevelGoal}\"`);\n\n      while (context.stepIndex < plan.tasks.length) {\n        const currentTask = context.currentStep();\n        // Find the agent responsible for the current task\n        let delegateAgent = this.agents.find(agent => agent.name.toLowerCase() === currentTask.agent.toLowerCase());\n\n        if (!delegateAgent) {\n          logger.warn(`Agent '${currentTask.agent}' not found for task '${currentTask.description}'. Falling back to Orchestrator.`);\n          delegateAgent = this.orchestrator;\n        }\n\n        logger.info(`Executing step ${context.stepIndex + 1}/${plan.tasks.length}: '${currentTask.description}' by Agent '${delegateAgent.name}' (Role: ${currentTask.role})`);\n\n        try {\n          // Execute the task using the determined agent\n          const agentOutput = await delegateAgent.executeTask(context);\n          if (agentOutput) {\n            // Record the main output of the agent\n            context.recordArtifact(`${delegateAgent.name}_output_${currentTask.id}.txt`, agentOutput.output, true);\n            \n            // Process and save any artifacts produced by the agent\n            if (agentOutput.artifact && agentOutput.artifact.files) {\n              agentOutput.artifact.files.forEach(file => {\n                this.session?.addArtifact(file.path, file.content);\n                console.log(`\\n--- File: ${file.path} ---\\n${file.content}\\n`);\n                // Optionally record the file artifact in the context for future steps\n                context.recordArtifact(file.path, agentOutput.artifact as Artifact, true); \n              });\n            }\n            // Handle team updates (e.g., new prompts) provided by the agent\n            if (agentOutput.team?.prompts) {\n              logger.info(`Agent '${delegateAgent.name}' provided ${agentOutput.team.prompts.length} team updates (prompts).`);\n              for (const promptData of agentOutput.team.prompts) {\n                this._updateAgentPrompt(promptData.agent, promptData.systemPrompt);\n              }\n            }\n          }\n        } catch (error) {\n          logger.error(`Error executing task '${currentTask.description}' by agent '${delegateAgent.name}':`, error);\n          // Error handling strategy: log and continue to the next task for now\n          context.recordArtifact(`${delegateAgent.name}_error_${currentTask.id}.txt`, `Error: ${error.message}`);\n        }\n        context.nextStep(); // Move to the next task in the plan\n      }\n      logger.info(`Completed workflow round ${roundNum}.`);\n    }\n\n    logger.info('--- Workflow Complete ---');\n  }\n\n  // Updates the system prompt for a specific agent\n  private _updateAgentPrompt(agentName: string, newPrompt: string): void {\n    const targetAgent = this.agents.find(agent => agent.name.toLowerCase() === agentName.toLowerCase());\n    if (targetAgent) {\n      targetAgent.updateSystemPrompt(newPrompt);\n      logger.info(`Updated system prompt for agent '${targetAgent.name}'.`);\n    } else {\n      logger.warn(`Agent '${agentName}' not found for prompt update.`);\n    }\n  }\n\n  // Instantiates an Agent or a specialized subclass like Orchestrator\n  private _instantiateAgent(spec: AgentSpec, prompts: Record<string, string>, allAgentSpecs: AgentSpec[]): Agent | null {\n    const promptKey = `${spec.name.toLowerCase()}_instructions.txt`;\n    // Prioritize systemPrompt from spec, then from loaded prompts file, else empty\n    const systemPrompt = spec.systemPrompt || prompts[promptKey] || '';\n    const model = spec.model || this.defaultModel;\n\n    let agent: Agent;\n\n    if (spec.role.toLowerCase() === 'orchestrator') {\n      agent = new Orchestrator(\n        spec.name,\n        spec.role,\n        spec.goal,\n        model,\n        systemPrompt\n      );\n      // If the orchestrator spec defines a team, build and assign it\n      if (spec.team && spec.team.length > 0) {\n        (agent as Orchestrator).team = this._buildTeam(spec.team, allAgentSpecs, prompts, 0);\n      }\n    } else {\n      agent = new Agent(\n        spec.name,\n        spec.role,\n        spec.goal,\n        model,\n        systemPrompt\n      );\n    }\n\n    logger.info(`Instantiated Agent: ${agent.name} (Role: ${agent.role}, Model: ${agent.model})`);\n    return agent;\n  }\n\n  // Recursively builds the team for an agent (primarily for Orchestrator)\n  private _buildTeam(teamSpecs: PromptSpec[], allAgentSpecs: AgentSpec[], prompts: Record<string, string>, depth: number): Record<string, Agent> {\n    const team: Record<string, Agent> = {};\n    const maxDepth = 5; // Prevent infinite recursion\n\n    if (depth > maxDepth) {\n      logger.error('Maximum team nesting depth reached. Stopping team creation.');\n      return {};\n    }\n\n    for (const teamSpec of teamSpecs) {\n      const memberSpec = allAgentSpecs.find(spec => spec.name.toLowerCase() === teamSpec.name.toLowerCase());\n      if (memberSpec) {\n        // Recursively instantiate the team member\n        const memberAgent = this._instantiateAgent(memberSpec, prompts, allAgentSpecs);\n        if (memberAgent) {\n          team[teamSpec.name] = memberAgent;\n        } else {\n          logger.warn(`Failed to instantiate team member '${teamSpec.name}'. Skipping.`);\n        }\n      } else {\n        logger.warn(`Team member specification for '${teamSpec.name}' not found. Creating a placeholder agent.`);\n        // Create a placeholder agent if spec is not found\n        const placeholderAgent = new Agent(\n          teamSpec.name,\n          teamSpec.role || 'Unknown Role',\n          teamSpec.goal || 'No specific goal defined',\n          this.defaultModel,\n          '' // No prompt for placeholder\n        );\n        team[teamSpec.name] = placeholderAgent;\n      }\n    }\n    return team;\n  }\n\n  // Loads agent specifications from YAML files\n  private _loadAgentSpecs(agentsDir: string): AgentSpec[] {\n    logger.info(`Loading agent specifications from: ${agentsDir}`);\n    if (!existsSync(agentsDir)) {\n        logger.warn(`Agent directory not found: ${agentsDir}. No agents will be loaded.`);\n        return [];\n    }\n    const agentFiles = globSync(join(agentsDir, '*.yaml'));\n    const specs: AgentSpec[] = [];\n    agentFiles.forEach(filePath => {\n      try {\n        const content = readFileSync(filePath, 'utf-8');\n        // Use js-yaml for loading YAML content\n        const spec = yaml.load(content) as AgentSpec;\n        \n        // Resolve system prompt path relative to the agent file's directory\n        if (spec.systemPromptPath) {\n          const baseDir = dirname(filePath);\n          const promptPath = join(baseDir, spec.systemPromptPath);\n          if (existsSync(promptPath)) {\n            spec.systemPrompt = readFileSync(promptPath, 'utf-8');\n          } else {\n            logger.warn(`System prompt file not found for ${spec.name}: ${promptPath}`);\n            spec.systemPrompt = ''; // Ensure systemPrompt is defined\n          }\n        }\n        // Use default model if not specified in the agent spec\n        spec.model = spec.model || this.defaultModel;\n        specs.push(spec);\n        logger.debug(`Loaded agent spec: ${spec.name}`);\n      } catch (error) {\n        logger.error(`Error loading agent spec from ${filePath}:`, error);\n      }\n    });\n    logger.info(`${specs.length} agent specifications loaded.`);\n    return specs;\n  }\n\n  // Loads prompt files from a directory\n  private _loadPrompts(promptsDir: string): Record<string, string> {\n    logger.info(`Loading prompts from: ${promptsDir}`);\n    if (!existsSync(promptsDir)) {\n        logger.warn(`Prompts directory not found: ${promptsDir}. No prompts will be loaded.`);\n        return {};\n    }\n    const promptFiles = globSync(join(promptsDir, '*.txt'));\n    const prompts: Record<string, string> = {};\n    promptFiles.forEach(filePath => {\n      try {\n        const content = readFileSync(filePath, 'utf-8');\n        const fileName = basename(filePath);\n        prompts[fileName] = content;\n        logger.debug(`Loaded prompt: ${fileName}`);\n      } catch (error) {\n        logger.error(`Error loading prompt from ${filePath}:`, error);\n      }\n    });\n    logger.info(`${Object.keys(prompts).length} prompts loaded.`);\n    return prompts;\n  }\n}\n"},{"path":"src/agent/Agent.ts","content":"import { LLM, LLMGenerateContentArgs } from '../llm/LLM';\nimport { ExecutionContext } from '../core/ExecutionContext';\nimport { Session } from '../core/Session';\nimport { Logger } from '../logger/Logger';\nimport { Plan, Task, Artifact, AgentOutput, File, Team, Role } from '../custom_types';\nimport { readFileSync } from 'fs';\nimport { join } from 'path';\n\nconst logger = Logger.getInstance();\n\n// Interface for Agent configuration loaded from YAML\nexport interface AgentSpec {\n  name: string;\n  role: string;\n  goal: string;\n  model?: string;\n  systemPrompt?: string;\n  systemPromptPath?: string; // Path to the system prompt file relative to agent definition\n  team?: PromptSpec[]; // For delegation, specifies members of its team\n}\n\n// Interface for team member specification (used in AgentSpec.team)\nexport interface PromptSpec {\n  name: string;\n  role?: string;\n  goal?: string;\n}\n\nexport class Agent {\n  public name: string;\n  public role: string;\n  public goal: string;\n  protected systemPrompt: string;\n  protected llm: LLM;\n  protected model: string;\n  // Team is primarily for Orchestrator, but can be used by other agents for delegation\n  public team: Record<string, Agent> = {}; \n\n  constructor(name: string, role: string, goal: string, model: string, systemPrompt: string) {\n    this.name = name;\n    this.role = role;\n    this.goal = goal;\n    this.model = model;\n    this.systemPrompt = systemPrompt;\n    this.llm = LLM.factory(model); // Use the factory to get an LLM instance\n    logger.info(`Agent instance created: ${this.name} (Role: ${this.role}, Model: ${this.model})`);\n  }\n\n  /**\n   * Updates the agent's system prompt.\n   * @param newPrompt The new system prompt content.\n   */\n  updateSystemPrompt(newPrompt: string): void {\n    this.systemPrompt = newPrompt;\n    logger.info(`Agent ${this.name}'s system prompt updated.`);\n  }\n\n  /**\n   * Executes a task assigned to this agent within the given context.\n   * @param context The execution context containing plan, session, and previous artifacts.\n   * @returns A Promise resolving to an AgentOutput object or null if execution fails.\n   */\n  async executeTask(context: ExecutionContext): Promise<AgentOutput | null> {\n    const currentTask = context.currentStep();\n    const previousArtifactsContent = await this._getPreviousArtifacts(context);\n\n    // Construct the prompt for the LLM\n    const taskPrompt = [\n      `The overall goal is: '${context.plan.highLevelGoal}'`,\n      `Your role's specific goal is: '${this.goal}'`,\n      `Your specific sub-task is: '${currentTask.description}'`,\n      // Include team roles for context\n      `The team's roles are:\n${JSON.stringify(context.plan.roles.map((role: Role) => ({ title: role.title, purpose: role.purpose })), null, 2)}`,\n    ].join('\\n\\n');\n\n    let fullPrompt = taskPrompt;\n    if (previousArtifactsContent) {\n      fullPrompt += `\\n\\nPlease use the following outputs from other agents as your input:\\n\\n${previousArtifactsContent}\\n\\n`;\n    }\n    // Add instruction for structured output\n    fullPrompt += `Please execute your sub-task, keeping the overall goal and your role's specific goal in mind to ensure your output is relevant to the project. Respond in a JSON format that includes 'output', and optionally 'artifact' and 'team' fields.`\n\n    logger.debug(`Constructed prompt for ${this.name} for task ${currentTask.id}:\n${fullPrompt}`);\n\n    // Record the prompt used for this task for debugging and auditing\n    context.recordArtifact(`${this.name}_prompt_${currentTask.id}.txt`, fullPrompt);\n\n    try {\n      // Define arguments for LLM content generation\n      const llmArgs: LLMGenerateContentArgs = {\n        modelName: this.model,\n        contents: fullPrompt,\n        systemInstruction: this.systemPrompt,\n        responseSchema: AgentOutput, // Expecting AgentOutput schema\n        responseMimeType: 'application/json',\n        temperature: 0.7, // Default temperature, can be overridden\n      };\n\n      // Call the LLM to generate content\n      const response = await this.llm.generateContent(llmArgs);\n\n      if (!response) {\n        logger.error(`LLM returned no response for task ${currentTask.id} by ${this.name}.`);\n        return null;\n      }\n\n      // Ensure the response is parsed as AgentOutput\n      if (typeof response === 'string') {\n          try {\n              // Attempt to parse the string response as JSON and validate against AgentOutput schema\n              const parsedOutput = AgentOutput.parse(JSON.parse(response));\n              logger.info(`Agent ${this.name} completed task: ${currentTask.description}`);\n              this._processAndRecordArtifacts(context, parsedOutput);\n              return parsedOutput;\n          } catch (parseError) {\n              logger.error(`Failed to parse LLM response as AgentOutput for task ${currentTask.id} by ${this.name}:`, parseError);\n              logger.error(`Raw LLM response: ${response}`);\n              // Record the raw, unparseable response as an artifact\n              context.recordArtifact(`${this.name}_raw_output_${currentTask.id}.txt`, response);\n              // Return an AgentOutput indicating the error\n              return new AgentOutput({ output: `Error processing response: LLM returned invalid JSON or schema.`, reasoning: 'LLM response was not valid JSON or AgentOutput schema.' });\n          }\n      } else if (response instanceof AgentOutput) {\n          // If the response is already an AgentOutput instance, use it directly\n          logger.info(`Agent ${this.name} completed task: ${currentTask.description}`);\n          this._processAndRecordArtifacts(context, response);\n          return response;\n      }\n\n      // Handle unexpected response types from the LLM\n      logger.warn(`Unexpected response type from LLM for task ${currentTask.id} by ${this.name}: ${typeof response}`);\n      return new AgentOutput({ output: `Unexpected response type received from LLM.`, reasoning: 'LLM returned an unexpected data type.' });\n\n    } catch (error) {\n      logger.error(`Error during LLM interaction for task ${currentTask.id} by ${this.name}:`, error);\n      // Record the error as an artifact for debugging\n      context.recordArtifact(`${this.name}_error_${currentTask.id}.txt`, `Error executing task: ${error.message}`);\n      // Return an AgentOutput indicating the failure\n      return new AgentOutput({ output: `Failed to execute task due to an error.`, reasoning: 'LLM interaction failed.' });\n    }\n  }\n\n  /**\n   * Retrieves and formats artifacts required by the current task from the execution context.\n   * @param context The execution context.\n   * @returns A formatted string of required artifacts, or an empty string if none are found.\n   */\n  private async _getPreviousArtifacts(context: ExecutionContext): Promise<string> {\n    // Get the IDs of tasks whose outputs are required for the current step\n    const requiredTaskIds = ['initial', ...context.currentStep().requires];\n    const relevantArtifacts: string[] = [];\n\n    // Iterate through all items remembered in the context\n    for (const [key, contextItem] of Object.entries(context.items)) {\n      // Check if the artifact's source task ID is in the required list\n      if (requiredTaskIds.includes(contextItem.step.id)) {\n        let artifactContent = '';\n        // Format the artifact content based on its type\n        if (contextItem.content instanceof Artifact) {\n          // If it's an Artifact object, format its files\n          artifactContent = contextItem.content.files.map(file => \n            `--- File: ${file.path}\\n${file.content}`\n          ).join('\\n');\n        } else if (typeof contextItem.content === 'string') {\n          artifactContent = contextItem.content;\n        } else {\n          try {\n            // Attempt to stringify if it's a JSON-serializable object\n            artifactContent = JSON.stringify(contextItem.content, null, 2);\n          } catch (e) {\n            // Fallback to simple string conversion\n            artifactContent = String(contextItem.content);\n          }\n        }\n        // Add the formatted artifact to the list\n        relevantArtifacts.push(`--- Artifact '${key}' from (${contextItem.step.role}) in [${contextItem.step.id}]:\\n${artifactContent}`);\n      }\n    }\n\n    return relevantArtifacts.join('\\n\\n');\n  }\n\n  /**\n   * Processes the AgentOutput, records artifacts and reasoning, and handles potential team updates.\n   * @param context The execution context.\n   * @param agentOutput The output received from the agent.\n   */\n  private _processAndRecordArtifacts(context: ExecutionContext, agentOutput: AgentOutput): void {\n    // Record the main output message\n    context.recordArtifact(`${this.name}_output.txt`, agentOutput.output, true);\n\n    // Process and save any artifacts generated by the agent\n    if (agentOutput.artifact && agentOutput.artifact.files) {\n      agentOutput.artifact.files.forEach(file => {\n        // Save the file to the session directory\n        this.session?.addArtifact(file.path, file.content);\n        console.log(`\\n--- File: ${file.path} ---\\n${file.content}\\n`);\n        // Record the file artifact in the context's memory for potential future use\n        // We record the entire Artifact object here for simplicity, assuming it contains relevant context\n        context.recordArtifact(file.path, agentOutput.artifact as Artifact, true); \n      });\n    }\n\n    // Record the agent's reasoning if provided\n    if (agentOutput.reasoning) {\n      context.recordArtifact(`${this.name}_reasoning.txt`, agentOutput.reasoning, true);\n    }\n\n    // Handle team updates (e.g., new prompts) - the System class will manage applying these\n    if (agentOutput.team && agentOutput.team.prompts) {\n      logger.info(`Agent ${this.name} provided ${agentOutput.team.prompts.length} team updates (prompts).`);\n      // The System class is responsible for applying these prompt updates to other agents.\n    }\n  }\n}\n"},{"path":"src/orchestrator/Orchestrator.ts","content":"import { Agent, AgentSpec, PromptSpec } from '../agent/Agent';\nimport { ExecutionContext } from '../core/ExecutionContext';\nimport { Session } from '../core/Session';\nimport { Logger } from '../logger/Logger';\nimport { Plan, Task, File, Role, AgentOutput } from '../custom_types';\nimport { readFileSync } from 'fs';\nimport { join } from 'path';\n\nconst logger = Logger.getInstance();\n\nexport class Orchestrator extends Agent {\n  // Orchestrator might have a more complex team structure or delegation logic\n  // For now, we'll keep it simple and assume 'team' is managed by the System class\n\n  constructor(name: string, role: string, goal: string, model: string, systemPrompt: string) {\n    super(name, role, goal, model, systemPrompt);\n    logger.info(`Orchestrator instance created: ${this.name}`);\n  }\n\n  /**\n   * Generates a plan for the given high-level goal using the LLM.\n   * @param session The current session object.\n   * @param highLevelGoal The overall objective for the plan.\n   * @param initialFiles Any initial files provided to the system.\n   * @returns A Promise resolving to the generated Plan object, or null if generation fails.\n   */\n  async generatePlan(session: Session, highLevelGoal: string, initialFiles: File[] = []): Promise<Plan | null> {\n    logger.info(`Orchestrator '${this.name}' is generating a plan for: \"${highLevelGoal}\"`);\n\n    if (!this.llm) {\n      logger.error('LLM client not initialized for Orchestrator.');\n      return null;\n    }\n\n    // Get available agents and their details to include in the prompt for context\n    const availableAgents = session.agents.map(agent => ({\n      name: agent.name,\n      role: agent.role,\n      goal: agent.goal,\n    }));\n\n    // Format agent information for the prompt\n    const agentDescription = availableAgents.map(agent => \n      `- Name: '${agent.name}'\\n  Role: ${agent.role}\\n  Goal: \"${agent.goal}\"`\n    ).join('\\n');\n\n    // Load the planning prompt template from a file\n    // The path is relative to the project root, adjust as necessary\n    const promptTemplatePath = join(this.rootDir, 'prompts', 'general_planning.txt');\n    let promptTemplate: string;\n    try {\n      promptTemplate = readFileSync(promptTemplatePath, 'utf-8');\n    } catch (error) {\n      logger.error(`Failed to load planning prompt template from ${promptTemplatePath}:`, error);\n      return null;\n    }\n\n    // Format the prompt with dynamic information\n    const planningPrompt = promptTemplate.replace('{{high_level_goal}}', highLevelGoal)\n                                      .replace('{{team_description}}', agentDescription)\n                                      .replace('{{initial_files}}', initialFiles.map(f => `--- File: ${f.path}\\n```\\n${f.content}\\n```).join('\\n\\n'));\n\n    logger.debug(`Constructed planning prompt for Orchestrator:\n${planningPrompt}`);\n    // Save the prompt used for planning as an artifact\n    session.addArtifact('planning_prompt.txt', planningPrompt);\n\n    try {\n      // Prepare arguments for LLM content generation\n      const llmArgs: LLMGenerateContentArgs = {\n        modelName: this.model,\n        contents: planningPrompt,\n        systemInstruction: this.systemPrompt,\n        responseSchema: Plan, // Expecting a Plan object\n        responseMimeType: 'application/json',\n        temperature: 0.1, // Lower temperature for more deterministic planning\n      };\n      \n      // Call the LLM to generate the plan\n      const response = await this.llm.generateContent(llmArgs);\n\n      if (!response) {\n        logger.error('LLM returned no response for plan generation.');\n        return null;\n      }\n\n      // Ensure the response is parsed as a Plan object\n      if (typeof response === 'string') {\n        try {\n          const plan = Plan.parse(JSON.parse(response));\n          return plan;\n        } catch (parseError) {\n          logger.error('Failed to parse LLM response as Plan:', parseError);\n          logger.error(`Raw LLM response: ${response}`);\n          session.addArtifact('plan_generation_error.txt', `LLM response was not valid JSON or Plan schema: ${response}`);\n          return null;\n        }\n      } else if (response instanceof Plan) {\n        return response; // Response is already a Plan instance\n      }\n\n      logger.error(`Unexpected response type from LLM during plan generation: ${typeof response}`);\n      return null;\n\n    } catch (error) {\n      logger.error('Error during plan generation:', error);\n      session.addArtifact('plan_generation_error.txt', `Error: ${error.message}`);\n      return null;\n    }\n  }\n\n  /**\n   * Overrides the base Agent's executeTask. Orchestrator's primary role is planning,\n   * but it might be assigned specific tasks by the plan itself (e.g., plan refinement).\n   * @param context The execution context.\n   * @returns AgentOutput or null.\n   */\n  async executeTask(context: ExecutionContext): Promise<AgentOutput | null> {\n    logger.warn(`Orchestrator '${this.name}' executeTask called directly. Task: '${context.currentStep().description}'. Falling back to default agent behavior.`);\n    // Delegate to the base Agent's executeTask to process the prompt as a standard task.\n    // This allows the orchestrator to perform tasks defined within the plan it generated.\n    return super.executeTask(context);\n  }\n}\n"},{"path":"src/core/Session.ts","content":"import { Agent } from '../agent/Agent';\nimport { Logger } from '../logger/Logger';\nimport { Plan, Artifact, File } from '../custom_types';\nimport { join, dirname as getDirname } from 'path';\nimport { existsSync, mkdirSync, writeFileSync, readFileSync } from 'fs';\n\nconst logger = Logger.getInstance();\n\nexport class Session {\n  public readonly sessionId: string;\n  public readonly agents: Agent[];\n  public state: string;\n  public readonly sessionDir: string;\n  public readonly projectRoot: string;\n\n  constructor(agents: Agent[], projectRoot: string, sessionId?: string) {\n    this.sessionId = sessionId || `session_${Date.now().toString()}`;\n    this.agents = agents;\n    this.state = 'initialized';\n    this.projectRoot = projectRoot;\n    this.sessionDir = join(this.projectRoot, 'sessions', this.sessionId);\n\n    // Ensure the session directory exists\n    if (!existsSync(this.sessionDir)) {\n      mkdirSync(this.sessionDir, { recursive: true });\n    }\n    logger.info(`Session created: ${this.sessionId} (Directory: ${this.sessionDir})`);\n  }\n\n  /**\n   * Saves an artifact to the session directory.\n   * @param name The name of the artifact file.\n   * @param content The content to write. Can be an object, string, etc.\n   */\n  addArtifact(name: string, content: any): void {\n    const artifactPath = join(this.sessionDir, name);\n    try {\n      const dir = getDirname(artifactPath);\n      // Ensure the directory for the artifact exists\n      if (!existsSync(dir)) {\n        mkdirSync(dir, { recursive: true });\n      }\n      \n      let contentToWrite: string;\n      // Determine if content should be saved as JSON or plain text\n      if (typeof content === 'object' && content !== null && !(content instanceof File) && !(content instanceof Artifact)) {\n        // If it's a plain object (like from AgentOutput.toJSON()), save as JSON\n        contentToWrite = JSON.stringify(content, null, 2);\n      } else if (typeof content === 'string') {\n        contentToWrite = content;\n      } else {\n        // Fallback for other types, convert to string\n        contentToWrite = String(content);\n      }\n\n      writeFileSync(artifactPath, contentToWrite, 'utf-8');\n      logger.info(`Artifact '${name}' saved in session ${this.sessionId}.`);\n    } catch (e) {\n      logger.error(`Error saving artifact '${name}' in session ${this.sessionId}:`, e);\n    }\n  }\n\n  /**\n   * Retrieves an artifact from the session directory.\n   * @param name The name of the artifact file to load.\n   * @returns The content of the artifact, or null if not found or an error occurs.\n   */\n  getArtifact(name: string): any {\n    const artifactPath = join(this.sessionDir, name);\n    try {\n      if (existsSync(artifactPath)) {\n        const content = readFileSync(artifactPath, 'utf-8');\n        // Attempt to parse as JSON if the filename suggests it\n        if (name.endsWith('.json')) {\n          try {\n            return JSON.parse(content);\n          } catch (e) {\n            logger.error(`Error parsing JSON artifact '${name}':`, e);\n            return null; // Return null if JSON parsing fails\n          }\n        }\n        return content; // Return as plain text\n      } else {\n        logger.warn(`Artifact '${name}' not found in session ${this.sessionId}.`);\n        return null;\n      }\n    } catch (e) {\n      logger.error(`Error retrieving artifact '${name}' from session ${this.sessionId}:`, e);\n      return null;\n    }\n  }\n}\n"},{"path":"src/core/ExecutionContext.ts","content":"import { Session } from './Session';\nimport { Plan, Task, Artifact, File } from '../custom_types';\nimport { Logger } from '../logger/Logger';\n\nconst logger = Logger.getInstance();\n\nexport interface ContextItem {\n  name: string;\n  content: any;\n  step: Task;\n}\n\nexport class ExecutionContext {\n  public session: Session;\n  public plan: Plan;\n  public stepIndex: number;\n  public roundNum: number;\n  public items: Record<string, ContextItem>; // Stores artifacts remembered from previous steps/rounds\n\n  constructor(session: Session, plan: Plan) {\n    this.session = session;\n    this.plan = plan;\n    this.stepIndex = 0;\n    this.roundNum = 1;\n    this.items = {};\n    logger.info('ExecutionContext initialized.');\n  }\n\n  /** Advances to the next step in the plan. */\n  nextStep(): void {\n    this.stepIndex++;\n    logger.debug(`Moved to next step. Current step index: ${this.stepIndex}`);\n  }\n\n  /** Resets the step index to the beginning of the plan. */\n  resetStepIndex(): void {\n    this.stepIndex = 0;\n    logger.debug('Step index reset to 0.');\n  }\n\n  /**\n   * Returns the current task based on the step index.\n   * @returns The current Task object.\n   * @throws Error if the step index is out of bounds.\n   */\n  currentStep(): Task {\n    if (this.stepIndex >= this.plan.tasks.length) {\n      throw new Error('Step index out of bounds. No more tasks in the plan.');\n    }\n    return this.plan.tasks[this.stepIndex];\n  }\n\n  /**\n   * Records an artifact generated by a task and optionally remembers it in the context's memory.\n   * @param key The key identifier for the artifact.\n   * @param value The artifact content.\n   * @param remember If true, the artifact is stored in context.items for future steps.\n   */\n  recordArtifact(key: string, value: any, remember: boolean = false): void {\n    // Construct a unique artifact key including round and step number\n    const artifactKey = `__${this.roundNum}/__step_${this.stepIndex}_${key}`;\n    this.session.addArtifact(artifactKey, value);\n    // If 'remember' is true, store the artifact in the context's memory\n    if (remember) {\n      this._rememberItem(artifactKey, value, this.currentStep());\n    }\n  }\n\n  /**\n   * Records initial artifacts provided at the beginning of the workflow.\n   * @param key The key identifier for the initial artifact.\n   * @param value The artifact content.\n   */\n  recordInitial(key: string, value: any): void {\n    // Use a special task ID 'initial' for items provided at the start\n    const initialTask: Task = new Task({\n      id: 'initial',\n      description: 'Initial files provided by the user',\n      role: 'User',\n      agent: 'User',\n      requires: []\n    });\n    this._rememberItem(key, value, initialTask);\n    // If the initial item is an Artifact containing files, add them to the session as well\n    if (value instanceof Artifact && value.files) {\n        value.files.forEach(file => this.session.addArtifact(file.path, file.content));\n    }\n    logger.debug(`Recorded initial item '${key}'.`);\n  }\n\n  /**\n   * Helper method to store an item in the context's memory (items dictionary).\n   * @param name The name/key for the item.\n   * @param content The content of the item.\n   * @param step The Task associated with this item.\n   */\n  private _rememberItem(name: string, content: any, step: Task): void {\n    this.items[name] = { name, content, step };\n    logger.debug(`Item '${name}' remembered in context.`);\n  }\n}\n"},{"path":"src/llm/LLM.ts","content":"import { BaseModel, model_validator } from 'pydantic';\nimport { Logger } from '../logger/Logger';\n\nconst logger = Logger.getInstance();\n\n// Interface for the LLM generation arguments, providing a structured way to pass parameters\nexport interface LLMGenerateContentArgs {\n  modelName: string;\n  contents: string;\n  systemInstruction?: string;\n  temperature?: number;\n  responseMimeType?: 'text/plain' | 'application/json' | 'application/json-schema';\n  responseSchema?: typeof BaseModel; // Expecting a Pydantic BaseModel class\n}\n\nexport abstract class LLM {\n  /**\n   * Abstract method to be implemented by concrete LLM providers.\n   * This method performs the actual call to the LLM API.\n   * @param args - The arguments for content generation.\n   * @returns A Promise resolving to the LLM's response (can be string, object, or parsed schema instance).\n   */\n  protected abstract generateContentImpl(args: LLMGenerateContentArgs): Promise<any>;\n\n  /**\n   * Public method to generate content using an LLM. Handles common logic like:\n   * - Retries with exponential backoff\n   * - Response parsing based on mime type and schema\n   * @param args - The arguments for content generation.\n   * @returns A Promise resolving to the processed LLM response, or null if all retries fail.\n   */\n  public async generateContent(args: LLMGenerateContentArgs): Promise<any> {\n    const { modelName, responseSchema, responseMimeType } = args;\n    const maxRetries = 3; // Number of times to retry the LLM call\n    let lastError: Error | null = null;\n\n    for (let attempt = 1; attempt <= maxRetries; attempt++) {\n      try {\n        logger.info(`Calling LLM model '${modelName}' (Attempt ${attempt}/${maxRetries})...`);\n        const response = await this.generateContentImpl(args);\n\n        if (!response) {\n          throw new Error('LLM returned an empty response.');\n        }\n\n        // Process the response based on the requested schema and mime type\n        if (responseSchema && responseMimeType === 'application/json') {\n          if (typeof response === 'string') {\n            try {\n              const parsedJson = JSON.parse(response);\n              // Validate the parsed JSON against the provided Pydantic schema\n              const validatedData = responseSchema.parse(parsedJson);\n              logger.debug(`LLM response successfully parsed and validated against schema ${responseSchema.name}.`);\n              return validatedData;\n            } catch (e) {\n              // Catch JSON parsing or Pydantic validation errors\n              lastError = new Error(`Failed to parse or validate LLM JSON response with schema ${responseSchema.name}: ${e.message}`);\n              logger.error(lastError.message);\n              // Do not retry on parsing/validation errors, as the response itself is likely malformed\n              throw lastError;\n            }\n          } else if (response instanceof responseSchema) {\n            // If the response is already an instance of the expected schema, return it directly\n            logger.debug(`LLM response is already an instance of ${responseSchema.name}.`);\n            return response;\n          } else {\n             // Handle cases where the response is neither a string nor the expected schema type\n             lastError = new Error(`LLM response was not a string or expected schema type for JSON request.`);\n             logger.error(lastError.message);\n             throw lastError;\n          }\n        } else if (responseSchema && responseMimeType === 'application/json-schema') {\n            // Specific handling for JSON schema responses if needed\n             if (typeof response === 'string') {\n                try {\n                    const parsedSchema = JSON.parse(response);\n                    // Further validation or processing might be needed here\n                    logger.debug('LLM response parsed as JSON Schema.');\n                    return parsedSchema;\n                } catch (e) {\n                     lastError = new Error(`Failed to parse LLM JSON Schema response: ${e.message}`);\n                     logger.error(lastError.message);\n                     throw lastError;\n                }\n            }\n        }\n\n        // Default handling for text responses or un-schematized JSON\n        logger.debug('LLM response processed.');\n        return response;\n\n      } catch (error) {\n        // Capture the error and prepare for retry or final failure\n        lastError = error;\n        logger.error(`LLM generation failed (Attempt ${attempt}): ${error.message}`);\n        // Implement exponential backoff for retries\n        if (attempt < maxRetries) {\n          const delay = Math.pow(2, attempt) * 1000; // Delay in ms (1s, 2s, 4s)\n          logger.info(`Waiting for ${delay / 1000} seconds before retrying...`);\n          await new Promise(resolve => setTimeout(resolve, delay));\n        }\n      }\n    }\n\n    // If all retries fail, log the last error and return null\n    logger.error(`LLM generation failed after ${maxRetries} attempts. Last error: ${lastError?.message}`);\n    return null;\n  }\n\n  /**\n   * Factory method to create an LLM instance based on a species string.\n   * This allows for dynamic instantiation of different LLM providers.\n   * @param species - A string identifying the LLM species (e.g., 'gemini:gemini-pro', 'ollama:llama3').\n   * @returns An instance of a concrete LLM class.\n   */\n  static factory(species: string): LLM {\n    logger.info(`LLM Factory: Creating LLM instance for species '${species}'`);\n    \n    // TODO: Replace dummy implementations with actual LLM provider classes\n    // Example: Implement OllamaLLM, GeminiLLM, OpenAILLM, MistralLLM classes\n    // and instantiate them here based on the 'species' string.\n\n    if (species.startsWith('ollama:')) {\n        const modelName = species.split(':')[1];\n        // return new OllamaLLM(modelName);\n        logger.warn('OllamaLLM not implemented. Returning DummyLLM.');\n        return new DummyLLM(modelName);\n    }\n    if (species.startsWith('gemini:') || species === 'gemini-2.5-flash-lite') {\n        const modelName = species.includes(':') ? species.split(':')[1] : species;\n        // return new GeminiLLM(modelName);\n        logger.warn('GeminiLLM not implemented. Returning DummyLLM.');\n        return new DummyLLM(modelName);\n    }\n     if (species.startsWith('openai:') || species.startsWith('gpt:') || species.startsWith('opi:')) {\n        const modelName = species.includes(':') ? species.split(':')[1] : species;\n        // return new OpenAILLM(modelName);\n         logger.warn('OpenAILLM not implemented. Returning DummyLLM.');\n        return new DummyLLM(modelName);\n    }\n    if (species.startsWith('mistral:')) {\n        const modelName = species.split(':')[1];\n        // return new MistralLLM(modelName);\n         logger.warn('MistralLLM not implemented. Returning DummyLLM.');\n        return new DummyLLM(modelName);\n    }\n\n    // Fallback to DummyLLM if the species is unknown\n    logger.warn(`Unknown LLM species '${species}'. Using DummyLLM as fallback.`);\n    return new DummyLLM(species);\n  }\n}\n\n/**\n * A dummy LLM implementation used as a placeholder.\n * It simulates LLM responses without making actual API calls.\n */\nclass DummyLLM extends LLM {\n  constructor(private modelName: string) {\n    super();\n    logger.warn(`DummyLLM initialized with model: ${this.modelName}. This is a placeholder.`);\n  }\n\n  protected async generateContentImpl(args: LLMGenerateContentArgs): Promise<any> {\n    logger.warn(`DummyLLM: generateContentImpl called for model ${this.modelName}. Returning mock response.`);\n    \n    // Simulate response based on schema if provided\n    if (args.responseSchema) {\n        try {\n            // Create a mock response adhering to the schema\n            if (args.responseSchema === AgentOutput) {\n                return new AgentOutput({\n                    output: `Mock output for ${this.modelName} task: ${args.contents.substring(0, 50)}...`,\n                    reasoning: 'This is a mock response from DummyLLM.',\n                    artifact: new Artifact({ task: 'mock_task', files: [new File({ path: 'mock_output.txt', content: 'Mock file content.'})]}),\n                    team: new Team({ notes: 'Mock team notes.'})\n                });\n            } else if (args.responseSchema === Plan) {\n                 return new Plan({\n                    highLevelGoal: 'Mock Goal',\n                    reasoning: 'Mock reasoning for plan generation',\n                    roles: [{title: 'Mock Role', purpose: 'Mock Purpose'}],\n                    tasks: [{id: 'T1', description: 'Mock Task', role: 'Mock Role', agent: 'Mock Agent', requires: []}],\n                    team: new Team({ notes: 'Mock team notes.'})\n                });\n            }\n            // Add handlers for other schemas as needed\n        } catch (e) {\n            logger.error(`Error creating mock response for schema ${args.responseSchema.name}:`, e);\n            return `Mock response failed for schema ${args.responseSchema.name}.`;\n        }\n    }\n    \n    // Default mock response if no schema is provided or handled\n    return `This is a mock response from DummyLLM for model ${this.modelName}.`;\n  }\n}\n"},{"path":"src/logger/Logger.ts","content":"import winston from 'winston';\nimport { join } from 'path';\nimport fs from 'fs';\n\n// Define log levels with priorities\nconst logLevels = {\n  error: 0,\n  warn: 1,\n  info: 2,\n  debug: 3,\n};\n\n// Define the format for log messages\nconst logFormat = winston.format.combine(\n  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),\n  winston.format.errors({ stack: true }), // Include stack trace for errors\n  winston.format.splat(), // Support for string interpolation like printf\n  winston.format.printf(({ level, message, timestamp, ...metadata }) => {\n    // Construct the log message string\n    let msg = `${timestamp} [${level.toUpperCase()}]: ${message}`;\n    // Append any additional metadata (e.g., agent name, task ID)\n    if (Object.keys(metadata).length > 0) {\n      msg += ` ${JSON.stringify(metadata)}`;\n    }\n    return msg;\n  })\n);\n\n// Define a format for JSON line logs (useful for log aggregation)\nconst jsonLogFormat = winston.format.combine(\n  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),\n  winston.format.errors({ stack: true }),\n  winston.format.splat(),\n  winston.format.json() // Output logs as JSON objects on separate lines\n);\n\n// Ensure the log directory exists\nconst logDir = process.env.LOG_DIR || 'logs'; // Use LOG_DIR environment variable or default to 'logs'\nif (!fs.existsSync(logDir)) {\n  fs.mkdirSync(logDir, { recursive: true });\n}\n\nconst logFilePath = join(logDir, 'app.log');\nconst jsonLogFilePath = join(logDir, 'app.jsonl');\n\nexport class Logger {\n  private static instance: winston.Logger;\n\n  /**\n   * Gets the singleton Winston logger instance.\n   * Configures transports for console, file (plain text), and file (JSONL).\n   * @returns The configured Winston logger instance.\n   */\n  public static getInstance(): winston.Logger {\n    if (!Logger.instance) {\n      Logger.instance = winston.createLogger({\n        level: process.env.LOG_LEVEL || 'info', // Set log level from environment or default to 'info'\n        levels: logLevels,\n        format: logFormat, // Default format for transports unless overridden\n        transports: [\n          // Console transport: Outputs logs to the console with colorization\n          new winston.transports.Console({\n            format: winston.format.combine(\n              winston.format.colorize({ all: true }), // Apply colors to all levels\n              logFormat\n            ),\n          }),\n          // File transport: Logs to 'app.log' in plain text format\n          new winston.transports.File({\n            filename: logFilePath,\n            level: process.env.LOG_LEVEL || 'info',\n            format: logFormat,\n            maxsize: 1024 * 1024 * 5, // Max log file size: 5MB\n            tailable: true, // Allows log rotation\n          }),\n          // JSONL File transport: Logs to 'app.jsonl' in JSON format\n          new winston.transports.File({\n            filename: jsonLogFilePath,\n            level: process.env.LOG_LEVEL || 'info',\n            format: jsonLogFormat,\n            maxsize: 1024 * 1024 * 5, // Max log file size: 5MB\n            tailable: true,\n          }),\n        ],\n        // Handle uncaught exceptions\n        exceptionHandlers: [\n          new winston.transports.Console({\n             format: winston.format.combine(winston.format.colorize({ all: true }), logFormat)\n          }),\n          new winston.transports.File({\n            filename: logFilePath,\n            format: logFormat,\n          }),\n          new winston.transports.File({\n            filename: jsonLogFilePath,\n            format: jsonLogFormat,\n          }),\n        ]\n      });\n\n      // Optional: Add a listener for logger errors\n      Logger.instance.on('error', (err) => {\n        console.error('Winston logger encountered an error:', err);\n      });\n    }\n    return Logger.instance;\n  }\n}\n"},{"path":"src/config/Config.ts","content":"import { readFileSync } from 'fs';\nimport { join } from 'path';\nimport yaml from 'js-yaml';\nimport { Logger } from '../logger/Logger';\n\nconst logger = Logger.getInstance();\n\n// Interface defining the structure of the configuration object\nexport interface Config {\n  projectRoot?: string;       // Root directory of the project\n  agentDir?: string;          // Directory containing agent configurations\n  promptDir?: string;         // Directory containing prompt templates\n  logDir?: string;            // Directory for log files\n  defaultModel?: string;      // Default LLM model to use if not specified\n  workflowRounds?: number;    // Default number of workflow rounds\n  // Add other configuration properties as needed\n}\n\nexport class Config {\n  /**\n   * Loads configuration from a YAML file.\n   * @param fileName The name of the configuration file (e.g., 'runtime.yaml').\n   * @param basePath The base path to search for the config file (defaults to current working directory).\n   * @returns A Promise resolving to the loaded Config object with defaults applied.\n   */\n  public static async load(fileName: string, basePath: string = process.cwd()): Promise<Config> {\n    const configPath = join(basePath, fileName);\n    logger.info(`Attempting to load configuration from: ${configPath}`);\n    try {\n      // Read the file content\n      const fileContents = readFileSync(configPath, 'utf-8');\n      // Parse the YAML content\n      const config = yaml.load(fileContents) as Config;\n\n      // Apply default values if properties are missing\n      config.projectRoot = config.projectRoot || basePath;\n      config.agentDir = config.agentDir || 'agents';\n      config.promptDir = config.promptDir || 'prompts';\n      config.logDir = config.logDir || 'logs';\n      config.defaultModel = config.defaultModel || 'gemini-2.5-flash-lite';\n      config.workflowRounds = config.workflowRounds || 3;\n\n      logger.info('Configuration loaded successfully.');\n      return config;\n    } catch (error) {\n      logger.error(`Failed to load configuration from ${configPath}:`, error);\n      // In case of failure, return a default configuration to allow the system to start\n      // Alternatively, you might want to throw an error to halt execution\n      return {\n        projectRoot: basePath,\n        agentDir: 'agents',\n        promptDir: 'prompts',\n        logDir: 'logs',\n        defaultModel: 'gemini-2.5-flash-lite',\n        workflowRounds: 3,\n      };\n    }\n  }\n}\n"},{"path":"src/custom_types.ts","content":"import { BaseModel, Field, model_validator } from 'pydantic';\nimport { z } from 'zod'; // Import Zod for potential schema definition or validation demonstration\n\n// --- Core Types representing Task Agnostic Steps (TAS) ---\n\n/** Represents a single actionable step within a plan. */\nexport class Task extends BaseModel {\n  id: string = Field(..., { description: \"Unique ID for the task (e.g., 'T1', 'T2').\" });\n  description: string = Field(..., { description: \"Detailed description of what to do for this task.\" });\n  role: string = Field(..., { description: \"The role responsible for performing this task.\" });\n  agent: string = Field(..., { description: \"The specific agent assigned to execute this task.\" });\n  requires: string[] = Field([], { description: \"List of task IDs whose outputs are required as prerequisites (e.g., ['T1', 'T2']).\" });\n}\n\n/** Represents a file generated or used within the system. */\nexport class File extends BaseModel {\n  path: string = Field(..., { description: \"File path or name (e.g., 'src/main.py').\" });\n  content: string = Field(..., { description: \"Full content of the file.\" });\n}\n\n/** Represents the output artifact of a completed task. */\nexport class Artifact extends BaseModel {\n  task: string = Field(..., { description: \"ID of the task that produced this artifact (e.g., 'T1').\" });\n  files: File[] = Field([], { description: \"List of files created or modified by the task.\" });\n}\n\n/** Defines a role within the system or team. */\nexport class Role extends BaseModel {\n  title: string = Field(..., { description: \"Title of the role (e.g., 'Engineer', 'Reviewer').\" });\n  purpose: string = Field(..., { description: \"The main purpose and high-level responsibilities of this role.\" });\n}\n\n/** Represents a system prompt configuration for an agent. */\nexport class Prompt extends BaseModel {\n  agent: string = Field(..., { description: \"Name of the agent this prompt is for. Must match exactly an existing agent.\" });\n  role: string = Field(..., { description: \"Role context of the agent.\" });\n  systemPrompt: string = Field(..., { description: \"Full text of the system prompt for this agent.\" });\n}\n\n/** Contains metadata and coordination information for the team, including prompt updates. */\nexport class Team extends BaseModel {\n  notes: string = Field('', { description: \"General notes or feedback about the team's performance or the plan.\" });\n  prompts: Prompt[] = Field([], { description: \"A list of new or updated system prompts for agents in the team.\" });\n}\n\n/** Defines the overall plan for a workflow, including goal, roles, and tasks. */\nexport class Plan extends BaseModel {\n  highLevelGoal: string = Field(..., { description: \"The main goal this plan is designed to achieve.\" });\n  reasoning: string = Field(..., { description: \"A brief explanation of the plan's structure and strategy.\" });\n  roles: Role[] = Field([], { description: \"List of all roles required to execute the plan.\" });\n  tasks: Task[] = Field([], { description: \"A step-by-step sequence of tasks to be executed in order.\" });\n  team: Team | null = Field(null, { description: \"Optional updates to team configuration or system prompts.\" });\n}\n\n/**\n * Represents the structured output returned by an agent after executing a task.\n * Adheres to the JSON output format expected by the runtime.\n */\nexport class AgentOutput extends BaseModel {\n  output: string = Field(..., { description: \"A summary of the work done. Do not include file contents here; use the 'artifact' field instead.\" });\n  artifact: Artifact | null = Field(null, { description: \"Optional artifact containing files created or modified by the agent.\" });\n  team: Team | null = Field(null, { description: \"Optional updates to team configuration or system prompts.\" });\n  reasoning: string | null = Field(null, { description: \"Explanation of how the agent arrived at this output.\" });\n\n  /**\n   * Custom validator to ensure that an AgentOutput contains either an 'output' message or an 'artifact'.\n   */\n  @model_validator(mode='after')\n  validateOutputAndArtifact(): this {\n    if (!this.output && !this.artifact) {\n      throw new Error('Agent output must contain either an \"output\" message or an \"artifact\".');\n    }\n    return this;\n  }\n}\n\n// --- Example Usage & Schema Generation ---\n// This block executes only when the script is run directly\nif (require.main === module) {\n  console.log('--- AgentOutput Schema ---\\n', JSON.stringify(AgentOutput.model_json_schema(), null, 2));\n  console.log('\\n--- Plan Schema ---\\n', JSON.stringify(Plan.model_json_schema(), null, 2));\n}\n"}]},"team":null,"reasoning":null}
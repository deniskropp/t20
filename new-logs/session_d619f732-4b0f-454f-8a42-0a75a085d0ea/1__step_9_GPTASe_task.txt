The overall goal is: 'Python Script that loads itself and respawns services'

Your role's specific goal is: 'Identify and extract each 'Task Agnostic Step' (TAS) towards the high-level goal.'
Your specific sub-task is: 'Extract Task-Agnostic Steps (TAS) from the prompt engineering strategy.'

The team's roles are:
    {'reasoning': 'The goal is to create a Python script that can load itself and respawn services. This requires a systematic approach, starting with understanding the core requirements, designing the system architecture, implementing the script, and ensuring its reliability through testing and refinement. The roles provided are diverse, and their tasks should reflect a logical progression from conceptualization to execution and maintenance. The plan is structured to first define the problem and requirements, then design the solution, followed by implementation, and finally, testing and iteration. Prompt engineering is integrated to refine agent instructions at each stage.', 'roles': [{'title': 'System Architect', 'description': 'Designs the overall structure and components of the system.'}, {'title': 'Requirements Analyst', 'description': 'Gathers and analyzes the functional and non-functional requirements of the system.'}, {'title': 'Technical Expert', 'description': 'Provides in-depth knowledge on specific technologies and implementation details.'}, {'title': 'Conceptual Analyst', 'description': 'Analyzes and refines the core concepts and logic of the system.'}, {'title': 'Researcher', 'description': 'Investigates existing solutions, libraries, and best practices.'}, {'title': 'Linguistic Mapper', 'description': 'Ensures clear and consistent communication and terminology within the project.'}, {'title': 'Lexicographer', 'description': 'Defines and standardizes the vocabulary used in the project.'}, {'title': 'Theoretical Liaison', 'description': 'Bridges theoretical concepts with practical implementation.'}, {'title': 'Relevance Assessor', 'description': 'Evaluates the relevance and applicability of proposed solutions and ideas.'}, {'title': 'Contextual Analyst', 'description': 'Analyzes the operational context and constraints of the system.'}, {'title': 'System Integrator', 'description': 'Oversees the integration of different system components.'}, {'title': 'Metrics Designer', 'description': 'Defines metrics for evaluating system performance and success.'}, {'title': 'Quality Assurance Specialist', 'description': 'Develops and executes test plans to ensure system quality.'}, {'title': 'Theoretical Advisor', 'description': 'Provides guidance on theoretical underpinnings and advanced concepts.'}, {'title': 'Feedback System', 'description': 'Designs and manages mechanisms for collecting and processing feedback.'}, {'title': 'Data Engineer', 'description': 'Handles data-related aspects, if any, in the system.'}, {'title': 'UX Researcher', 'description': "Focuses on user experience, if applicable to the script's interaction."}, {'title': 'Ingestion Specialist', 'description': 'Manages the process of bringing in necessary resources or data.'}, {'title': 'Data Validator', 'description': 'Ensures the integrity and correctness of data.'}, {'title': 'Source Integrator', 'description': 'Integrates with external data sources or services.'}, {'title': 'Theoretical Analyst', 'description': 'Analyzes theoretical aspects relevant to the project.'}, {'title': 'Pattern Recognizer', 'description': 'Identifies patterns in data or behavior for optimization.'}, {'title': 'Insight Extractor', 'description': 'Derives actionable insights from analysis.'}, {'title': 'Response Generator', 'description': 'Formulates responses or outputs based on analysis.'}, {'title': 'Theoretical Content Curator', 'description': 'Manages and organizes theoretical knowledge relevant to the project.'}, {'title': 'Context Synthesizer', 'description': 'Synthesizes information from various contexts.'}, {'title': 'Feedback Processor', 'description': 'Processes and categorizes feedback received.'}, {'title': 'Theoretical Evaluator', 'description': 'Evaluates theoretical models and approaches.'}, {'title': 'Improvement Analyst', 'description': 'Analyzes areas for improvement in the system or process.'}, {'title': 'Refinement Strategist', 'description': 'Develops strategies for refining the system.'}, {'title': 'Model Tuner', 'description': 'Adjusts parameters for optimal performance.'}, {'title': 'Workflow Designer', 'description': 'Designs and optimizes the workflow for development and execution.'}, {'title': 'Configuration Manager', 'description': 'Manages system configurations and settings.'}, {'title': 'Prompt Engineer', 'description': 'Structures workflows and ensures clarity in agent instructions, system prompt engineering.'}, {'title': 'Task-Agnostic Step Extractor', 'description': "Identifies and extracts each 'Task Agnostic Step' (TAS) towards the high-level goal."}], 'tasks': [{'task_id': 'T1', 'task': 'Define the core requirements for a Python script that can load itself and respawn services. This includes identifying essential functionalities, potential challenges, and desired outcomes.', 'role': 'Requirements Analyst', 'name': 'LaReqAnalyst', 'requires': []}, {'task_id': 'T2', 'task': 'Research existing Python libraries and techniques for self-loading scripts and service management (e.g., `importlib`, `subprocess`, systemd, supervisor).', 'role': 'Researcher', 'name': 'LaResearcher', 'requires': []}, {'task_id': 'T3', 'task': 'Analyze the theoretical underpinnings of self-modifying code and dynamic service management to ensure a robust and secure approach.', 'role': 'Theoretical Analyst', 'name': 'LaTheolAna', 'requires': []}, {'task_id': 'T4', 'task': 'Based on requirements and research, propose a high-level system architecture for the Python script, outlining key components and their interactions.', 'role': 'System Architect', 'name': 'LaSysDesigner', 'requires': ['T1', 'T2']}, {'task_id': 'T5', 'task': 'Refine the system architecture and conceptual design, ensuring logical consistency and feasibility.', 'role': 'Conceptual Analyst', 'name': 'LaConceptAna', 'requires': ['T4']}, {'task_id': 'T6', 'task': "Develop a detailed plan for the Python script's implementation, including module breakdown, data structures, and control flow.", 'role': 'Workflow Designer', 'name': 'LaWorkflowDes', 'requires': ['T5']}, {'task_id': 'T7', 'task': 'Define the prompt engineering strategy for guiding the development of the Python script, focusing on clarity and effectiveness for AI agents.', 'role': 'Prompt Engineer', 'name': 'Lyra', 'requires': ['T6']}, {'task_id': 'T8', 'task': 'Extract Task-Agnostic Steps (TAS) from the refined requirements and conceptual design to guide the implementation.', 'role': 'Task-Agnostic Step Extractor', 'name': 'TASe', 'requires': ['T5']}, {'task_id': 'T9', 'task': 'Extract Task-Agnostic Steps (TAS) from the detailed implementation plan.', 'role': 'Task-Agnostic Step Extractor', 'name': 'uTASe', 'requires': ['T6']}, {'task_id': 'T10', 'task': 'Extract Task-Agnostic Steps (TAS) from the prompt engineering strategy.', 'role': 'Task-Agnostic Step Extractor', 'name': 'GPTASe', 'requires': ['T7']}, {'task_id': 'T11', 'task': 'Implement the core logic for the Python script to load itself, potentially using dynamic import mechanisms.', 'role': 'System Integrator', 'name': 'LaSysIntegrator', 'requires': ['T8', 'T9']}, {'task_id': 'T12', 'task': 'Implement the service respawning functionality within the Python script, considering different service management approaches.', 'role': 'Technical Expert', 'name': 'LaTheoExpert', 'requires': ['T8', 'T9']}, {'task_id': 'T13', 'task': 'Integrate the self-loading and service respawning components, ensuring seamless operation.', 'role': 'System Integrator', 'name': 'LaSysIntegrator', 'requires': ['T11', 'T12']}, {'task_id': 'T14', 'task': 'Develop a configuration management strategy for the script, allowing for flexible service definitions and respawn parameters.', 'role': 'Configuration Manager', 'name': 'LaConfigMgr', 'requires': ['T13']}, {'task_id': 'T15', 'task': "Define metrics for evaluating the script's performance, reliability, and resource usage.", 'role': 'Metrics Designer', 'name': 'LaMetricsDes', 'requires': ['T1']}, {'task_id': 'T16', 'task': 'Create a comprehensive test plan, including unit tests, integration tests, and stress tests for the script.', 'role': 'Quality Assurance Specialist', 'name': 'LaQASpecialist', 'requires': ['T13', 'T15']}, {'task_id': 'T17', 'task': 'Execute the test plan and document any bugs or performance issues.', 'role': 'Quality Assurance Specialist', 'name': 'LaQASpecialist', 'requires': ['T16']}, {'task_id': 'T18', 'task': "Analyze test results and identify areas for improvement in the script's logic, efficiency, or robustness.", 'role': 'Improvement Analyst', 'name': 'LaImproveAna', 'requires': ['T17']}, {'task_id': 'T19', 'task': 'Refine the script based on feedback from testing and analysis, iterating on the implementation.', 'role': 'Refinement Strategist', 'name': 'LaRefineStrat', 'requires': ['T18']}, {'task_id': 'T20', 'task': 'Document the Python script, including its functionality, usage, configuration, and maintenance procedures.', 'role': 'Linguistic Mapper', 'name': 'LaLingMapper', 'requires': ['T19']}, {'task_id': 'T21', 'task': 'Establish a feedback loop for ongoing monitoring and improvement of the script.', 'role': 'Feedback System', 'name': 'LaFeedbackSys', 'requires': ['T20']}, {'task_id': 'T22', 'task': 'Review and refine the prompt engineering strategy based on the development process and outcomes.', 'role': 'Prompt Engineer', 'name': 'Lyra', 'requires': ['T19', 'T21']}]}

Please use the following outputs from the other agents as your input:

Artifact from 1__step_6_Lyra_result.txt (Prompt Engineer)[T7]:
{
  "reasoning": "The user's request is to define the prompt engineering strategy for guiding the development of the Python script. My role is Prompt Engineer, and my specific sub-task is to define this strategy, focusing on clarity and effectiveness for AI agents. I have received the implementation plan (T6) as input. My strategy needs to ensure that future AI agents working on this project receive clear, actionable instructions. This involves defining the persona, goals, constraints, and expected outputs for prompts related to this project. I will structure the prompt strategy to cover different phases of development, ensuring consistency and alignment with the overall goal.",
  "output": "## Prompt Engineering Strategy for Python Service Orchestrator\n\n**Overall Goal:** Develop a Python script that can load itself and respawn services.\n\n**Role:** Prompt Engineer (Lyra)\n\n**Sub-Task:** Define the prompt engineering strategy for guiding the development of the Python script, focusing on clarity and effectiveness for AI agents.\n\n**Input:** Detailed Implementation Plan (from T6 - Workflow Designer)\n\n**Strategy Overview:**\n\nThis strategy aims to provide clear, concise, and effective prompts for AI agents involved in developing the Python Service Orchestrator. It emphasizes breaking down complex tasks into manageable steps, specifying required inputs, defining expected outputs, and setting constraints. The strategy will be iterative, allowing for refinement as the project progresses.\n\n**Core Principles:**\n\n1.  **Clarity and Specificity:** Prompts must be unambiguous, leaving no room for misinterpretation. Use precise language and avoid jargon where possible, or define it clearly.\n2.  **Contextual Relevance:** Each prompt should provide sufficient context, referencing previous decisions, design documents, or requirements.\n3.  **Actionability:** Prompts should clearly state the desired action or outcome.\n4.  **Modularity:** Break down complex tasks into smaller, well-defined sub-tasks, each addressed by a specific prompt.\n5.  **Iterative Refinement:** The prompts and this strategy will be reviewed and updated based on agent performance and project evolution.\n\n**Prompt Structure Template:**\n\n```\n[Agent Persona/Role]\n**Goal:** [Specific, concise goal for this prompt]\n**Context:** [Relevant background information, e.g., links to design docs, previous task outputs]\n**Input:** [Specific files, data, or information the agent should use]\n**Task:** [Detailed, step-by-step instructions for the agent]\n**Constraints:** [Limitations, e.g., Python version, allowed libraries, performance requirements, security considerations]\n**Output Format:** [Expected structure and content of the agent's response, e.g., code, documentation, report, JSON]\n**Evaluation Criteria:** [How the output will be assessed for correctness and completeness]\n```\n\n**Phased Prompt Application:**\n\n**Phase 1: Design & Planning (Completed/In Progress)**\n\n*   **Focus:** Defining requirements, architecture, and implementation plan.\n*   **Example Prompt (Conceptual):**\n    ```\n    System Architect\n    **Goal:** Propose a high-level system architecture for the Python script.\n    **Context:** Based on requirements (T1) and research (T2).\n    **Input:** T1 output (Requirements), T2 output (Research findings).\n    **Task:** Outline key modules, their responsibilities, and interactions. Consider modularity, scalability, and maintainability.\n    **Constraints:** Must support self-loading and service respawning.\n    **Output Format:** Markdown document detailing the architecture.\n    ```\n\n**Phase 2: Implementation**\n\n*   **Focus:** Writing, integrating, and testing code modules.\n*   **Prompt Strategy:** Generate prompts for specific modules or functionalities defined in the implementation plan (T6). Each prompt will target a specific agent (e.g., Python Developer Agent).\n*   **Example Prompt (for `service_manager.py`):**\n    ```\n    Python Developer Agent\n    **Goal:** Implement the `service_manager.py` module.\n    **Context:** Refer to the Detailed Implementation Plan (T6), specifically Section 1 (Module Breakdown) and Section 2 (Data Structures) for `service_manager.py`. The module should manage individual service processes using `subprocess.Popen`.\n    **Input:** `implementation_plan.md`.\n    **Task:** \n    1. Implement the `ServiceManager` class.\n    2. Implement `start_service(service_config)`: Launch service via `subprocess.Popen`, capture Popen object, update state registry. Handle `working_dir`, `environment`.\n    3. Implement `stop_service(service_name)`: Send SIGTERM, wait for `timeout_stop`.\n    4. Implement `restart_service(service_name)`: Calls stop then start.\n    5. Implement `get_service_status(service_name)`: Use `Popen.poll()`.\n    6. Implement internal state registry to track Popen objects and status.\n    **Constraints:** \n    *   Use standard Python libraries (`subprocess`, `os`, `signal`).\n    *   Handle potential exceptions during process management.\n    *   Adhere to the data structures defined in the plan.\n    **Output Format:** Python code for `service_manager.py`.\n    **Evaluation Criteria:** Code is functional, includes error handling, follows the implementation plan, and passes basic unit tests.\n    ```\n\n**Phase 3: Testing & Refinement**\n\n*   **Focus:** Quality assurance, bug fixing, performance optimization.\n*   **Prompt Strategy:** Generate prompts for QA agents and refinement specialists. Prompts will focus on test case generation, execution, bug analysis, and implementing improvements.\n*   **Example Prompt (for QA Specialist):**\n    ```\n    Quality Assurance Specialist Agent\n    **Goal:** Develop and execute a test plan for the `service_manager.py` module.\n    **Context:** Based on the implementation of `service_manager.py` (from Phase 2) and the overall project goals.\n    **Input:** Implemented `service_manager.py` code.\n    **Task:** \n    1.  Write unit tests covering `start_service`, `stop_service`, `restart_service`, and `get_service_status` under various conditions (success, failure, timeouts).\n    2.  Write integration tests to verify interaction with `config_manager` and `monitor` (once implemented).\n    3.  Execute all tests and report results, including any failures or unexpected behavior.\n    **Constraints:** Tests should be written using a standard Python testing framework (e.g., `unittest`, `pytest`).\n    **Output Format:** Test suite code (e.g., `test_service_manager.py`) and a test execution report.\n    **Evaluation Criteria:** Test coverage is adequate, tests correctly identify expected and actual behavior, and the report is clear.\n    ```\n\n**Phase 4: Documentation & Deployment**\n\n*   **Focus:** Creating user guides, API documentation, and deployment instructions.\n*   **Prompt Strategy:** Generate prompts for documentation specialists, ensuring all aspects of the script are clearly explained.\n\n**Vocabulary and Terminology:**\n\n*   **Orchestrator:** The main Python script itself.\n*   **Service:** An individual process managed by the Orchestrator.\n*   **Self-Loading:** The script's ability to dynamically load or reload its own code/modules.\n*   **Respawning:** The process of restarting a terminated service based on its policy.\n*   **Service Configuration:** The external definition (e.g., JSON file) specifying how a service should be run and managed.\n*   **State Registry:** Internal data structure tracking the status and process information of managed services.\n*   **Restart Policy:** Rules defining when and how a service should be respawned.\n\n**Feedback and Iteration:**\n\n*   Monitor the performance of AI agents when executing prompts based on this strategy.\n*   Collect feedback on prompt clarity, completeness, and effectiveness.\n*   Refine prompts and this strategy document (T22) regularly based on feedback and project evolution.\n",
      "files": [
        {
          "name": "prompt_engineering_strategy.md",
          "content": "## Prompt Engineering Strategy for Python Service Orchestrator\n\n**Overall Goal:** Develop a Python script that can load itself and respawn services.\n\n**Role:** Prompt Engineer (Lyra)\n\n**Sub-Task:** Define the prompt engineering strategy for guiding the development of the Python script, focusing on clarity and effectiveness for AI agents.\n\n**Input:** Detailed Implementation Plan (from T6 - Workflow Designer)\n\n**Strategy Overview:**\n\nThis strategy aims to provide clear, concise, and effective prompts for AI agents involved in developing the Python Service Orchestrator. It emphasizes breaking down complex tasks into manageable steps, specifying required inputs, defining expected outputs, and setting constraints. The strategy will be iterative, allowing for refinement as the project progresses.\n\n**Core Principles:**\n\n1.  **Clarity and Specificity:** Prompts must be unambiguous, leaving no room for misinterpretation. Use precise language and avoid jargon where possible, or define it clearly.\n2.  **Contextual Relevance:** Each prompt should provide sufficient context, referencing previous decisions, design documents, or requirements.\n3.  **Actionability:** Prompts should clearly state the desired action or outcome.\n4.  **Modularity:** Break down complex tasks into smaller, well-defined sub-tasks, each addressed by a specific prompt.\n5.  **Iterative Refinement:** The prompts and this strategy will be reviewed and updated based on agent performance and project evolution.\n\n**Prompt Structure Template:**\n\n```\n[Agent Persona/Role]\n**Goal:** [Specific, concise goal for this prompt]\n**Context:** [Relevant background information, e.g., links to design docs, previous task outputs]\n**Input:** [Specific files, data, or information the agent should use]\n**Task:** [Detailed, step-by-step instructions for the agent]\n**Constraints:** [Limitations, e.g., Python version, allowed libraries, performance requirements, security considerations]\n**Output Format:** [Expected structure and content of the agent's response, e.g., code, documentation, report, JSON]\n**Evaluation Criteria:** [How the output will be assessed for correctness and completeness]\n```\n\n**Phased Prompt Application:**\n\n**Phase 1: Design & Planning (Completed/In Progress)**\n\n*   **Focus:** Defining requirements, architecture, and implementation plan.\n*   **Example Prompt (Conceptual):**\n    ```\n    System Architect\n    **Goal:** Propose a high-level system architecture for the Python script.\n    **Context:** Based on requirements (T1) and research (T2).\n    **Input:** T1 output (Requirements), T2 output (Research findings).\n    **Task:** Outline key modules, their responsibilities, and interactions. Consider modularity, scalability, and maintainability.\n    **Constraints:** Must support self-loading and service respawning.\n    **Output Format:** Markdown document detailing the architecture.\n    ```\n\n**Phase 2: Implementation**\n\n*   **Focus:** Writing, integrating, and testing code modules.\n*   **Prompt Strategy:** Generate prompts for specific modules or functionalities defined in the implementation plan (T6). Each prompt will target a specific agent (e.g., Python Developer Agent).\n*   **Example Prompt (for `service_manager.py`):**\n    ```\n    Python Developer Agent\n    **Goal:** Implement the `service_manager.py` module.\n    **Context:** Refer to the Detailed Implementation Plan (T6), specifically Section 1 (Module Breakdown) and Section 2 (Data Structures) for `service_manager.py`. The module should manage individual service processes using `subprocess.Popen`.\n    **Input:** `implementation_plan.md`.\n    **Task:** \n    1. Implement the `ServiceManager` class.\n    2. Implement `start_service(service_config)`: Launch service via `subprocess.Popen`, capture Popen object, update state registry. Handle `working_dir`, `environment`.\n    3. Implement `stop_service(service_name)`: Send SIGTERM, wait for `timeout_stop`.\n    4. Implement `restart_service(service_name)`: Calls stop then start.\n    5. Implement `get_service_status(service_name)`: Use `Popen.poll()`.\n    6. Implement internal state registry to track Popen objects and status.\n    **Constraints:** \n    *   Use standard Python libraries (`subprocess`, `os`, `signal`).\n    *   Handle potential exceptions during process management.\n    *   Adhere to the data structures defined in the plan.\n    **Output Format:** Python code for `service_manager.py`.\n    **Evaluation Criteria:** Code is functional, includes error handling, follows the implementation plan, and passes basic unit tests.\n    ```\n\n**Phase 3: Testing & Refinement**\n\n*   **Focus:** Quality assurance, bug fixing, performance optimization.\n*   **Prompt Strategy:** Generate prompts for QA agents and refinement specialists. Prompts will focus on test case generation, execution, bug analysis, and implementing improvements.\n*   **Example Prompt (for QA Specialist):**\n    ```\n    Quality Assurance Specialist Agent\n    **Goal:** Develop and execute a test plan for the `service_manager.py` module.\n    **Context:** Based on the implementation of `service_manager.py` (from Phase 2) and the overall project goals.\n    **Input:** Implemented `service_manager.py` code.\n    **Task:** \n    1.  Write unit tests covering `start_service`, `stop_service`, `restart_service`, and `get_service_status` under various conditions (success, failure, timeouts).\n    2.  Write integration tests to verify interaction with `config_manager` and `monitor` (once implemented).\n    3.  Execute all tests and report results, including any failures or unexpected behavior.\n    **Constraints:** Tests should be written using a standard Python testing framework (e.g., `unittest`, `pytest`).\n    **Output Format:** Test suite code (e.g., `test_service_manager.py`) and a test execution report.\n    **Evaluation Criteria:** Test coverage is adequate, tests correctly identify expected and actual behavior, and the report is clear.\n    ```\n\n**Phase 4: Documentation & Deployment**\n\n*   **Focus:** Creating user guides, API documentation, and deployment instructions.\n*   **Prompt Strategy:** Generate prompts for documentation specialists, ensuring all aspects of the script are clearly explained.\n\n**Vocabulary and Terminology:**\n\n*   **Orchestrator:** The main Python script itself.\n*   **Service:** An individual process managed by the Orchestrator.\n*   **Self-Loading:** The script's ability to dynamically load or reload its own code/modules.\n*   **Respawning:** The process of restarting a terminated service based on its policy.\n*   **Service Configuration:** The external definition (e.g., JSON file) specifying how a service should be run and managed.\n*   **State Registry:** Internal data structure tracking the status and process information of managed services.\n*   **Restart Policy:** Rules defining when and how a service should be respawned.\n\n**Feedback and Iteration:**\n\n*   Monitor the performance of AI agents when executing prompts based on this strategy.\n*   Collect feedback on prompt clarity, completeness, and effectiveness.\n*   Refine prompts and this strategy document (T22) regularly based on feedback and project evolution.\n"
        }
      ]
    }



Please execute your sub-task, keeping the overall goal and your role's specific goal in mind to ensure your output is relevant to the project.
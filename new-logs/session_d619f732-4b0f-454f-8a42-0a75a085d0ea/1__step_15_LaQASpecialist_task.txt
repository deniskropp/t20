The overall goal is: 'Python Script that loads itself and respawns services'

Your role's specific goal is: ''
Your specific sub-task is: 'Create a comprehensive test plan, including unit tests, integration tests, and stress tests for the script.'

The team's roles are:
    {'reasoning': 'The goal is to create a Python script that can load itself and respawn services. This requires a systematic approach, starting with understanding the core requirements, designing the system architecture, implementing the script, and ensuring its reliability through testing and refinement. The roles provided are diverse, and their tasks should reflect a logical progression from conceptualization to execution and maintenance. The plan is structured to first define the problem and requirements, then design the solution, followed by implementation, and finally, testing and iteration. Prompt engineering is integrated to refine agent instructions at each stage.', 'roles': [{'title': 'System Architect', 'description': 'Designs the overall structure and components of the system.'}, {'title': 'Requirements Analyst', 'description': 'Gathers and analyzes the functional and non-functional requirements of the system.'}, {'title': 'Technical Expert', 'description': 'Provides in-depth knowledge on specific technologies and implementation details.'}, {'title': 'Conceptual Analyst', 'description': 'Analyzes and refines the core concepts and logic of the system.'}, {'title': 'Researcher', 'description': 'Investigates existing solutions, libraries, and best practices.'}, {'title': 'Linguistic Mapper', 'description': 'Ensures clear and consistent communication and terminology within the project.'}, {'title': 'Lexicographer', 'description': 'Defines and standardizes the vocabulary used in the project.'}, {'title': 'Theoretical Liaison', 'description': 'Bridges theoretical concepts with practical implementation.'}, {'title': 'Relevance Assessor', 'description': 'Evaluates the relevance and applicability of proposed solutions and ideas.'}, {'title': 'Contextual Analyst', 'description': 'Analyzes the operational context and constraints of the system.'}, {'title': 'System Integrator', 'description': 'Oversees the integration of different system components.'}, {'title': 'Metrics Designer', 'description': 'Defines metrics for evaluating system performance and success.'}, {'title': 'Quality Assurance Specialist', 'description': 'Develops and executes test plans to ensure system quality.'}, {'title': 'Theoretical Advisor', 'description': 'Provides guidance on theoretical underpinnings and advanced concepts.'}, {'title': 'Feedback System', 'description': 'Designs and manages mechanisms for collecting and processing feedback.'}, {'title': 'Data Engineer', 'description': 'Handles data-related aspects, if any, in the system.'}, {'title': 'UX Researcher', 'description': "Focuses on user experience, if applicable to the script's interaction."}, {'title': 'Ingestion Specialist', 'description': 'Manages the process of bringing in necessary resources or data.'}, {'title': 'Data Validator', 'description': 'Ensures the integrity and correctness of data.'}, {'title': 'Source Integrator', 'description': 'Integrates with external data sources or services.'}, {'title': 'Theoretical Analyst', 'description': 'Analyzes theoretical aspects relevant to the project.'}, {'title': 'Pattern Recognizer', 'description': 'Identifies patterns in data or behavior for optimization.'}, {'title': 'Insight Extractor', 'description': 'Derives actionable insights from analysis.'}, {'title': 'Response Generator', 'description': 'Formulates responses or outputs based on analysis.'}, {'title': 'Theoretical Content Curator', 'description': 'Manages and organizes theoretical knowledge relevant to the project.'}, {'title': 'Context Synthesizer', 'description': 'Synthesizes information from various contexts.'}, {'title': 'Feedback Processor', 'description': 'Processes and categorizes feedback received.'}, {'title': 'Theoretical Evaluator', 'description': 'Evaluates theoretical models and approaches.'}, {'title': 'Improvement Analyst', 'description': 'Analyzes areas for improvement in the system or process.'}, {'title': 'Refinement Strategist', 'description': 'Develops strategies for refining the system.'}, {'title': 'Model Tuner', 'description': 'Adjusts parameters for optimal performance.'}, {'title': 'Workflow Designer', 'description': 'Designs and optimizes the workflow for development and execution.'}, {'title': 'Configuration Manager', 'description': 'Manages system configurations and settings.'}, {'title': 'Prompt Engineer', 'description': 'Structures workflows and ensures clarity in agent instructions, system prompt engineering.'}, {'title': 'Task-Agnostic Step Extractor', 'description': "Identifies and extracts each 'Task Agnostic Step' (TAS) towards the high-level goal."}], 'tasks': [{'task_id': 'T1', 'task': 'Define the core requirements for a Python script that can load itself and respawn services. This includes identifying essential functionalities, potential challenges, and desired outcomes.', 'role': 'Requirements Analyst', 'name': 'LaReqAnalyst', 'requires': []}, {'task_id': 'T2', 'task': 'Research existing Python libraries and techniques for self-loading scripts and service management (e.g., `importlib`, `subprocess`, systemd, supervisor).', 'role': 'Researcher', 'name': 'LaResearcher', 'requires': []}, {'task_id': 'T3', 'task': 'Analyze the theoretical underpinnings of self-modifying code and dynamic service management to ensure a robust and secure approach.', 'role': 'Theoretical Analyst', 'name': 'LaTheolAna', 'requires': []}, {'task_id': 'T4', 'task': 'Based on requirements and research, propose a high-level system architecture for the Python script, outlining key components and their interactions.', 'role': 'System Architect', 'name': 'LaSysDesigner', 'requires': ['T1', 'T2']}, {'task_id': 'T5', 'task': 'Refine the system architecture and conceptual design, ensuring logical consistency and feasibility.', 'role': 'Conceptual Analyst', 'name': 'LaConceptAna', 'requires': ['T4']}, {'task_id': 'T6', 'task': "Develop a detailed plan for the Python script's implementation, including module breakdown, data structures, and control flow.", 'role': 'Workflow Designer', 'name': 'LaWorkflowDes', 'requires': ['T5']}, {'task_id': 'T7', 'task': 'Define the prompt engineering strategy for guiding the development of the Python script, focusing on clarity and effectiveness for AI agents.', 'role': 'Prompt Engineer', 'name': 'Lyra', 'requires': ['T6']}, {'task_id': 'T8', 'task': 'Extract Task-Agnostic Steps (TAS) from the refined requirements and conceptual design to guide the implementation.', 'role': 'Task-Agnostic Step Extractor', 'name': 'TASe', 'requires': ['T5']}, {'task_id': 'T9', 'task': 'Extract Task-Agnostic Steps (TAS) from the detailed implementation plan.', 'role': 'Task-Agnostic Step Extractor', 'name': 'uTASe', 'requires': ['T6']}, {'task_id': 'T10', 'task': 'Extract Task-Agnostic Steps (TAS) from the prompt engineering strategy.', 'role': 'Task-Agnostic Step Extractor', 'name': 'GPTASe', 'requires': ['T7']}, {'task_id': 'T11', 'task': 'Implement the core logic for the Python script to load itself, potentially using dynamic import mechanisms.', 'role': 'System Integrator', 'name': 'LaSysIntegrator', 'requires': ['T8', 'T9']}, {'task_id': 'T12', 'task': 'Implement the service respawning functionality within the Python script, considering different service management approaches.', 'role': 'Technical Expert', 'name': 'LaTheoExpert', 'requires': ['T8', 'T9']}, {'task_id': 'T13', 'task': 'Integrate the self-loading and service respawning components, ensuring seamless operation.', 'role': 'System Integrator', 'name': 'LaSysIntegrator', 'requires': ['T11', 'T12']}, {'task_id': 'T14', 'task': 'Develop a configuration management strategy for the script, allowing for flexible service definitions and respawn parameters.', 'role': 'Configuration Manager', 'name': 'LaConfigMgr', 'requires': ['T13']}, {'task_id': 'T15', 'task': "Define metrics for evaluating the script's performance, reliability, and resource usage.", 'role': 'Metrics Designer', 'name': 'LaMetricsDes', 'requires': ['T1']}, {'task_id': 'T16', 'task': 'Create a comprehensive test plan, including unit tests, integration tests, and stress tests for the script.', 'role': 'Quality Assurance Specialist', 'name': 'LaQASpecialist', 'requires': ['T13', 'T15']}, {'task_id': 'T17', 'task': 'Execute the test plan and document any bugs or performance issues.', 'role': 'Quality Assurance Specialist', 'name': 'LaQASpecialist', 'requires': ['T16']}, {'task_id': 'T18', 'task': "Analyze test results and identify areas for improvement in the script's logic, efficiency, or robustness.", 'role': 'Improvement Analyst', 'name': 'LaImproveAna', 'requires': ['T17']}, {'task_id': 'T19', 'task': 'Refine the script based on feedback from testing and analysis, iterating on the implementation.', 'role': 'Refinement Strategist', 'name': 'LaRefineStrat', 'requires': ['T18']}, {'task_id': 'T20', 'task': 'Document the Python script, including its functionality, usage, configuration, and maintenance procedures.', 'role': 'Linguistic Mapper', 'name': 'LaLingMapper', 'requires': ['T19']}, {'task_id': 'T21', 'task': 'Establish a feedback loop for ongoing monitoring and improvement of the script.', 'role': 'Feedback System', 'name': 'LaFeedbackSys', 'requires': ['T20']}, {'task_id': 'T22', 'task': 'Review and refine the prompt engineering strategy based on the development process and outcomes.', 'role': 'Prompt Engineer', 'name': 'Lyra', 'requires': ['T19', 'T21']}]}

Please use the following outputs from the other agents as your input:

Artifact from 1__step_12_LaSysIntegrator_result.txt (System Integrator)[T13]:
{
  "reasoning": "The specific sub-task is to 'Integrate the self-loading and service respawning components, ensuring seamless operation.' I have received outputs from the 'System Integrator' (T11) which implemented the self-loading logic in `self_loader.py`, and from the 'Technical Expert' (T12) which provided a `ServiceManager` class in `service_manager.py` for handling service respawning. My role as 'System Integrator' is to combine these two pieces of functionality. This will involve modifying `self_loader.py` to incorporate or utilize the `ServiceManager` class to manage the services that it dynamically loads. The goal is to have a single script that can both load itself (potentially reloading or restarting) and manage the lifecycle of other services it's responsible for, including respawning them if they fail. I will modify `self_loader.py` to instantiate and use the `ServiceManager` class, passing it the service configurations that should be loaded and managed. This integration will ensure that the self-loading mechanism and the service respawning mechanism work together harmoniously, fulfilling the sub-task requirement of seamless operation.",
  "output": "The Python script `integrated_script.py` now combines the self-loading capabilities with robust service respawning. It dynamically imports service modules and then uses a `ServiceManager` to oversee their lifecycle, including automatic respawning on failure. This integration ensures that the script can manage its own execution flow while also reliably maintaining the operational status of its dependent services, achieving seamless operation as required by the sub-task.",
  "files": [
    {
      "name": "integrated_script.py",
      "content": "import importlib\nimport sys\nimport os\nimport time\nimport subprocess\nimport signal\n\n# --- Service Manager Class (from Technical Expert's output) ---\nclass ServiceManager:\n    def __init__(self, service_configs):\n        self.service_configs = service_configs\n        self.processes = {}\n        self.running = True\n\n    def start_service(self, service_name):\n        config = self.service_configs[service_name]\n        command = config['command']\n        restart_policy = config.get('restart_policy', 'on-failure')\n        max_retries = config.get('max_retries', 5)\n        retry_delay = config.get('retry_delay', 5)\n\n        if service_name in self.processes and self.processes[service_name]['process'].poll() is None:\n            log(f\"Service {service_name} is already running.\")\n            return\n\n        try:\n            log(f\"Starting service: {service_name} with command: {command}\")\n            # Use Popen for non-blocking execution, create new process group for easier termination\n            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, preexec_fn=os.setsid) \n            self.processes[service_name] = {\n                'process': process,\n                'command': command,\n                'restart_policy': restart_policy,\n                'max_retries': max_retries,\n                'retry_delay': retry_delay,\n                'retries': 0,\n                'start_time': time.time()\n            }\n        except Exception as e:\n            log(f\"Error starting service {service_name}: {e}\")\n            # Handle initial start failure based on policy\n            if restart_policy != 'no' and self.processes[service_name]['retries'] < max_retries:\n                self.processes[service_name]['retries'] += 1\n                log(f\"Retrying service {service_name} in {retry_delay} seconds...\")\n                time.sleep(retry_delay)\n                self.start_service(service_name) # Recursive call for retry\n            else:\n                log(f\"Failed to start service {service_name} after {max_retries} retries.\")\n\n    def stop_service(self, service_name):\n        if service_name in self.processes:\n            process_info = self.processes[service_name]\n            process = process_info['process']\n            if process.poll() is None:  # If process is running\n                log(f\"Stopping service: {service_name}\")\n                try:\n                    # Send SIGTERM to the process group\n                    os.killpg(os.getpgid(process.pid), signal.SIGTERM)\n                    process.wait(timeout=5) # Wait for termination\n                    log(f\"Service {service_name} stopped.\")\n                except subprocess.TimeoutExpired:\n                    log(f\"Service {service_name} did not terminate gracefully, killing process group.\")\n                    os.killpg(os.getpgid(process.pid), signal.SIGKILL) # Send SIGKILL to the process group\n                    process.wait()\n                except ProcessLookupError:\n                    log(f\"Service {service_name} process already terminated.\")\n                except Exception as e:\n                    log(f\"Error stopping service {service_name}: {e}\")\n            del self.processes[service_name]\n\n    def monitor_services(self):\n        for service_name, process_info in list(self.processes.items()): # Use list to allow modification during iteration\n            process = process_info['process']\n            exit_code = process.poll() # Check if process has exited\n\n            if exit_code is not None: # Process has terminated\n                log(f\"Service {service_name} terminated with exit code: {exit_code}\")\n                process_info['retries'] += 1\n                restart_policy = process_info['restart_policy']\n                max_retries = process_info['max_retries']\n                retry_delay = process_info['retry_delay']\n\n                should_restart = False\n                if restart_policy == 'always':\n                    should_restart = True\n                elif restart_policy == 'on-failure' and exit_code != 0:\n                    should_restart = True\n                elif restart_policy == 'on-abnormal-exit' and exit_code not in [0, 1]: # Example: 0 is success, 1 might be controlled exit\n                    should_restart = True\n\n                if should_restart and process_info['retries'] <= max_retries:\n                    log(f\"Restarting service {service_name} (Attempt {process_info['retries']}/{max_retries}) in {retry_delay} seconds...\")\n                    time.sleep(retry_delay)\n                    self.start_service(service_name) # Restart the service\n                else:\n                    log(f\"Service {service_name} will not be restarted (Max retries reached or policy forbids).\")\n                    del self.processes[service_name] # Remove from monitoring if not restarting\n\n    def run_monitoring(self):\n        # Monitoring loop\n        while self.running:\n            self.monitor_services()\n            time.sleep(2) # Check every 2 seconds\n\n    def shutdown(self):\n        log(\"Initiating shutdown...\")\n        self.running = False\n        for service_name in list(self.processes.keys()):\n            self.stop_service(service_name)\n        log(\"All services stopped. Exiting.\")\n\n# --- Logging Utility (from self_loader.py) ---\ndef log(message):\n    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n    print(f\"[{timestamp}] {message}\")\n\n# --- Self-Loading and Respawning Logic (integrated from self_loader.py) ---\n\n# --- TAS: Define Orchestration Strategy (from T8)\n# Using ServiceManager for orchestration and os.execv for self-respawn.\n\n# --- TAS: Load Service Configurations (from T9)\n# In a real application, this would parse a config file.\n# For this example, we define the modules/commands to be loaded directly.\n# These commands will be executed by the ServiceManager.\nSERVICE_COMMANDS = {\n    \"example_service_1\": {\n        \"command\": f\"{sys.executable} example_service_1.py\",\n        \"restart_policy\": \"always\",\n        \"max_retries\": 10,\n        \"retry_delay\": 5\n    },\n    \"example_service_2\": {\n        \"command\": f\"{sys.executable} example_service_2.py\",\n        \"restart_policy\": \"on-failure\",\n        \"max_retries\": 5,\n        \"retry_delay\": 10\n    },\n    \"failing_service_demo\": {\n        \"command\": f\"{sys.executable} failing_script.py\",\n        \"restart_policy\": \"on-failure\",\n        \"max_retries\": 3,\n        \"retry_delay\": 3\n    }\n}\n\n# --- TAS: Implement Respawn Policy (from T9)\ndef respawn_self(reason=\"\"): \n    log(f\"Initiating self-respawn. Reason: {reason}\")\n    log(f\"Current script: {sys.argv[0]}\")\n    log(f\"Arguments: {sys.argv[1:]}\")\n    \n    new_args = [sys.executable, os.path.abspath(__file__)]\n    new_args.append(\"--respawned\") \n    \n    log(f\"Executing: {' '.join(new_args)}\")\n    \n    try:\n        os.execv(sys.executable, new_args)\n    except OSError as e:\n        log(f\"Failed to respawn script: {e}\")\n        sys.exit(1)\n\n# --- TAS: Implement Graceful Shutdown (from T8 & T9) ---\ndef graceful_shutdown(service_manager=None):\n    log(\"Initiating graceful shutdown...\")\n    if service_manager:\n        service_manager.shutdown()\n    log(\"Main process shutting down.\")\n\n# --- Main Execution Logic ---\ndef main():\n    log(\"Script started.\")\n    \n    service_manager = None\n    \n    # Check if this is a respawned instance (optional, for demonstration)\n    if \"--respawned\" in sys.argv:\n        log(\"This is a respawned instance.\")\n        # Potentially adjust behavior for respawned instance\n\n    # --- Dynamic Loading and Service Management --- \n    # We use ServiceManager to manage the services defined in SERVICE_COMMANDS.\n    # The 'self-loading' aspect is now about the script's ability to restart itself\n    # and re-initialize its service management.\n    \n    service_manager = ServiceManager(SERVICE_COMMANDS)\n    \n    # Start the service monitoring in a separate thread or process if needed for complex scenarios.\n    # For this example, we'll run it sequentially or manage its lifecycle.\n    # A common pattern is to fork or thread the monitoring loop.\n    # Here, we'll run it in the main thread after initial service starts.\n    \n    # Initial start of all services managed by ServiceManager\n    for service_name in SERVICE_COMMANDS:\n        service_manager.start_service(service_name)\n\n    # --- Handling Signals for Graceful Shutdown ---\n    def signal_handler(sig, frame):\n        graceful_shutdown(service_manager)\n        sys.exit(0)\n\n    signal.signal(signal.SIGINT, signal_handler) # Handle Ctrl+C\n    signal.signal(signal.SIGTERM, signal_handler) # Handle termination signal\n\n    # --- Main Loop: Keep script alive and monitor services ---\n    try:\n        # TAS: Manage Service Lifecycle (through start_service and monitor_services)\n        # TAS: Monitor Service Status (within monitor_services)\n        # TAS: Implement Respawn Policy (within monitor_services)\n        # TAS: Handle Process Errors (implicitly via subprocess and try-except blocks)\n        # TAS: Implement Graceful Shutdown (via signal_handler and manager.shutdown())\n        service_manager.run_monitoring()\n        \n    except Exception as e:\n        log(f\"An unexpected error occurred in the main loop: {e}\")\n        graceful_shutdown(service_manager)\n        # Optionally, trigger a self-respawn on critical errors\n        respawn_self(f\"Critical error in main loop: {e}\")\n\nif __name__ == \"__main__\":\n    # --- Create dummy service files for demonstration if they don't exist ---\n    if not os.path.exists(\"example_service_1.py\"):\n        with open(\"example_service_1.py\", \"w\") as f:\n            f.write(\"import time\\nimport sys\\nimport os\\n\\ndef run():\\n    print('[Service 1] Running...')\\n    # Simulate a process that might fail randomly\\n    fail_chance = 0.1 # 10% chance of failure\\n    counter = 0\\n    while True:\\n        print(f'[Service 1] Heartbeat... (counter: {counter})')\\n        time.sleep(2)\\n        counter += 1\\n        if os.environ.get('FAIL_SERVICE_1') == 'true' and counter % 5 == 0: # Example condition to fail\\n             print('[Service 1] Simulating failure!')\\n             sys.exit(1)\\n\\ndef stop():\\n    print('[Service 1] Stopping gracefully...')\\n\")\n\n    if not os.path.exists(\"example_service_2.py\"):\n        with open(\"example_service_2.py\", \"w\") as f:\n            f.write(\"import time\\n\\ndef run():\\n    print('[Service 2] Running...')\\n    while True:\\n        print('[Service 2] Working...')\\n        time.sleep(3)\\n\\ndef stop():\\n    print('[Service 2] Stopping gracefully...')\\n\")\n\n    if not os.path.exists(\"failing_script.py\"):\n        with open(\"failing_script.py\", \"w\") as f:\n            f.write(\"import time\\nimport sys\\n\\nprint('[Failing Script] Starting up...')\\ntime.sleep(1)\\nprint('[Failing Script] Exiting with error code 1...')\\nsys.exit(1)\\n\")\n\n    main()\n"
    }
  ]
}

---

Artifact from 1__step_14_LaMetricsDes_result.txt (Metrics Designer)[T15]:
{
  "reasoning": "The user wants me to define metrics for evaluating the script's performance, reliability, and resource usage, acting as a Metrics Designer. I have reviewed the requirements defined by the Requirements Analyst (T1) which provide a good foundation for what the script should achieve. I will now define relevant metrics based on these requirements.",
  "output": "### Metrics for Evaluating the Python Script\n\nTo effectively evaluate the performance, reliability, and resource usage of the self-loading and service-respawning Python script, the following metrics are proposed:\n\n**1. Performance Metrics:**\n\n*   **Respawn Latency:** The time taken from detecting a service failure to successfully respawning the service. This measures the script's responsiveness.\n    *   *Measurement:* Average, median, and maximum time (in seconds) for respawn operations.\n*   **Script Startup Time:** The time it takes for the main Python script to initialize and begin monitoring services.\n    *   *Measurement:* Average and maximum startup time (in seconds).\n*   **Monitoring Overhead:** The computational resources consumed by the script for actively monitoring services.\n    *   *Measurement:* CPU and memory usage of the script process itself during idle and active monitoring states.\n*   **Configuration Load Time:** The time required to load and parse the service configuration.\n    *   *Measurement:* Average and maximum time (in milliseconds) for configuration loading.\n\n**2. Reliability Metrics:**\n\n*   **Uptime of Managed Services:** The percentage of time that the services managed by the script are operational.\n    *   *Measurement:* (Total Uptime / Total Time) * 100% for each managed service.\n*   **Respawn Success Rate:** The percentage of successful service respawn attempts out of all detected failures.\n    *   *Measurement:* (Successful Respawns / Total Respawn Attempts) * 100%.\n*   **Failure Detection Rate:** The accuracy with which the script detects actual service failures.\n    *   *Measurement:* Percentage of actual failures correctly identified.\n*   **False Positive Rate:** The rate at which the script incorrectly identifies a healthy service as failed.\n    *   *Measurement:* (False Positives / Total Checks) * 100%.\n*   **Infinite Loop Prevention Effectiveness:** Measures how often the script avoids getting stuck in restart loops for problematic services.\n    *   *Measurement:* Number of instances where restart limits were hit and the service was correctly marked as non-recoverable, preventing further attempts.\n*   **Graceful Shutdown Success Rate:** The percentage of successful graceful shutdowns of the script and its managed services.\n    *   *Measurement:* (Successful Graceful Shutdowns / Total Shutdown Initiations) * 100%.\n\n**3. Resource Usage Metrics:**\n\n*   **CPU Utilization:** The percentage of CPU consumed by the Python script process.\n    *   *Measurement:* Average, peak, and steady-state CPU usage (%).\n*   **Memory Footprint:** The amount of RAM utilized by the Python script process.\n    *   *Measurement:* Resident Set Size (RSS) and Virtual Memory Size (VMS) in MB/GB.\n*   **I/O Operations:** The number of read/write operations performed by the script, particularly related to logging and service interaction.\n    *   *Measurement:* Disk read/write operations per second.\n*   **Network Usage:** If services involve network communication, monitor the script's network activity (though likely minimal for the core logic).\n    *   *Measurement:* Network bandwidth consumed (if applicable).\n\n**4. Logging and Auditing Metrics:**\n\n*   **Log Volume:** The amount of data generated by the script's logging.\n    *   *Measurement:* Size of log files (MB/GB) over a period, number of log entries per hour/day.\n*   **Log Completeness:** Ensuring all critical events (starts, stops, failures, respawns) are logged.\n    *   *Measurement:* Manual audit or automated checks against expected event logs.\n\nThese metrics will provide a quantitative basis for understanding the script's effectiveness, identifying bottlenecks, and ensuring it meets the desired outcomes of high availability and automated recovery without negatively impacting system resources.",
  "files": [
    {
      "name": "metrics_definition.md",
      "content": "# Metrics for Evaluating the Python Script\n\nTo effectively evaluate the performance, reliability, and resource usage of the self-loading and service-respawning Python script, the following metrics are proposed:\n\n## 1. Performance Metrics:\n\n*   **Respawn Latency:** The time taken from detecting a service failure to successfully respawning the service. This measures the script's responsiveness.\n    *   *Measurement:* Average, median, and maximum time (in seconds) for respawn operations.\n*   **Script Startup Time:** The time it takes for the main Python script to initialize and begin monitoring services.\n    *   *Measurement:* Average and maximum startup time (in seconds).\n*   **Monitoring Overhead:** The computational resources consumed by the script for actively monitoring services.\n    *   *Measurement:* CPU and memory usage of the script process itself during idle and active monitoring states.\n*   **Configuration Load Time:** The time required to load and parse the service configuration.\n    *   *Measurement:* Average and maximum time (in milliseconds) for configuration loading.\n\n## 2. Reliability Metrics:\n\n*   **Uptime of Managed Services:** The percentage of time that the services managed by the script are operational.\n    *   *Measurement:* (Total Uptime / Total Time) * 100% for each managed service.\n*   **Respawn Success Rate:** The percentage of successful service respawn attempts out of all detected failures.\n    *   *Measurement:* (Successful Respawns / Total Respawn Attempts) * 100%.\n*   **Failure Detection Rate:** The accuracy with which the script detects actual service failures.\n    *   *Measurement:* Percentage of actual failures correctly identified.\n*   **False Positive Rate:** The rate at which the script incorrectly identifies a healthy service as failed.\n    *   *Measurement:* (False Positives / Total Checks) * 100%.\n*   **Infinite Loop Prevention Effectiveness:** Measures how often the script avoids getting stuck in restart loops for problematic services.\n    *   *Measurement:* Number of instances where restart limits were hit and the service was correctly marked as non-recoverable, preventing further attempts.\n*   **Graceful Shutdown Success Rate:** The percentage of successful graceful shutdowns of the script and its managed services.\n    *   *Measurement:* (Successful Graceful Shutdowns / Total Shutdown Initiations) * 100%.\n\n## 3. Resource Usage Metrics:\n\n*   **CPU Utilization:** The percentage of CPU consumed by the Python script process.\n    *   *Measurement:* Average, peak, and steady-state CPU usage (%).\n*   **Memory Footprint:** The amount of RAM utilized by the Python script process.\n    *   *Measurement:* Resident Set Size (RSS) and Virtual Memory Size (VMS) in MB/GB.\n*   **I/O Operations:** The number of read/write operations performed by the script, particularly related to logging and service interaction.\n    *   *Measurement:* Disk read/write operations per second.\n*   **Network Usage:** If services involve network communication, monitor the script's network activity (though likely minimal for the core logic).\n    *   *Measurement:* Network bandwidth consumed (if applicable).\n\n## 4. Logging and Auditing Metrics:\n\n*   **Log Volume:** The amount of data generated by the script's logging.\n    *   *Measurement:* Size of log files (MB/GB) over a period, number of log entries per hour/day.\n*   **Log Completeness:** Ensuring all critical events (starts, stops, failures, respawns) are logged.\n    *   *Measurement:* Manual audit or automated checks against expected event logs.\n\nThese metrics will provide a quantitative basis for understanding the script's effectiveness, identifying bottlenecks, and ensuring it meets the desired outcomes of high availability and automated recovery without negatively impacting system resources."
    }
  ]
}



Please execute your sub-task, keeping the overall goal and your role's specific goal in mind to ensure your output is relevant to the project.
{
  "task": "Implement the logic to connect the frontend to the AI system's API, managing application state (e.g., loading, data, errors) effectively.",
  "sub_task_execution": {
    "goal": "Integrate the React frontend with the AI system's API using Axios and Zustand, managing loading states, API responses, and errors for a seamless user experience.",
    "plan": [
      {
        "step": 1,
        "action": "Define API Service Module",
        "description": "Create a dedicated module (`src/lib/api.ts`) to house API interaction logic. This will include setting up an Axios instance with base URL and interceptors for authentication and error handling.",
        "details": "Configure Axios instance with `baseURL` from Lyra's contract. Implement an interceptor to add the 'Authorization' header with a placeholder token. Implement a response interceptor to handle common error structures defined in Lyra's `error_response_format` and potentially re-throw them for component-level handling."
      },
      {
        "step": 2,
        "action": "Create Zustand Store for AI State",
        "description": "Develop a Zustand store (`src/store/aiStore.ts`) to manage the application state related to AI interactions. This includes managing the current prompt, AI responses, conversation history, loading status, and any errors.",
        "details": "Define state slices for: `currentPrompt`, `aiResponse` (text, type, and potentially metadata), `conversationId`, `messages` (for history in the current interaction), `isLoading`, `error`. Implement actions for: `setPrompt`, `fetchAiResponse` (which will call the API service), `setResponse`, `setError`, `clearError`, `addMessageToHistory`, `loadConversationHistory`, `setConversationId`."
      },
      {
        "step": 3,
        "action": "Implement `fetchAiResponse` action",
        "description": "Implement the core `fetchAiResponse` action in the Zustand store to handle API calls to the `/generate` endpoint.",
        "details": "This action will: \n1. Set `isLoading` to true and clear any previous `error`.\n2. Construct the `messages` array based on the current conversation state (potentially including a system message and previous turns).\n3. Make a POST request using the Axios instance to `/generate`, passing the `user_id` (placeholder for now), `conversation_id` (if available), and the `messages` array.\n4. Handle both standard responses and streaming responses (if `stream: true` is implemented later).\n5. On success: parse the response, update `aiResponse` and `conversationId` (if new), and add the assistant's message to the `messages` history.\n6. On error: catch the error, set the `error` state with details from Lyra's format, and set `isLoading` to false."
      },
      {
        "step": 4,
        "action": "Implement `HomePage` integration",
        "description": "Connect the `HomePage` component to the `aiStore` and the API service to enable user interaction.",
        "details": "Use Zustand's `useStore` hook to access and update state. Bind the `Input` component's value to `currentPrompt` and its `onChange` handler to `setPrompt`. Wire up the `Primary Button`'s `onClick` event to call `fetchAiResponse`. Conditionally render the `LoadingIndicator` based on `isLoading` state. Display the `aiResponse` within the `ResponseCard`. Show error messages if `error` state is present."
      },
      {
        "step": 5,
        "action": "Implement `HistoryPage` integration",
        "description": "Connect the `HistoryPage` component to fetch and display conversation history from the `/history` endpoint.",
        "details": "Create a new Zustand slice or expand `aiStore` for `historyState` (e.g., `conversations`, `historyIsLoading`, `historyError`). Implement actions like `fetchConversationHistory` which calls the `/history` endpoint using Axios. Display the list of conversations in the `HistoryPage`, potentially using a map over the `conversations` array and rendering summary items. Each item should be clickable to load a specific conversation (e.g., by calling `fetchSpecificConversationHistory` and updating `messages`, `conversationId`, etc.)."
      },
      {
        "step": 6,
        "action": "Implement Feedback Mechanism",
        "description": "Integrate the `FeedbackButton` component to send feedback to the `/feedback` endpoint.",
        "details": "Add `onFeedbackClick` handlers to the `HomePage` that call a new Zustand action `submitFeedback`. This action will make a POST request to `/feedback` with `response_id` and `feedback_type`. Update UI to reflect feedback state if necessary (e.g., visually marking a liked response)."
      },
      {
        "step": 7,
        "action": "Refine Error Handling and Loading States",
        "description": "Ensure all API interactions have appropriate loading indicators and user-friendly error messages.",
        "details": "Use the `isLoading` state from Zustand to show/hide `LoadingIndicator` components. Implement robust error display using `error` state, potentially showing a toast notification or an inline error message near the relevant UI element."
      }
    ],
    "code_implementation_details": {
      "api_service": {
        "file_path": "src/lib/api.ts",
        "code_snippet": "import axios from 'axios';\n\nconst API_BASE_URL = 'https://api.auraflow.ai/v1'; // As per Lyra's contract\n\nconst api = axios.create({\n  baseURL: API_BASE_URL,\n  headers: {\n    'Content-Type': 'application/json',\n  },\n});\n\n// Add a request interceptor for authentication\napi.interceptors.request.use(\n  (config) => {\n    // TODO: Get token from auth context/store\n    const token = localStorage.getItem('authToken') || 'YOUR_PLACEHOLDER_TOKEN';\n    if (token) {\n      config.headers.Authorization = `Bearer ${token}`;\n    }\n    return config;\n  },\n  (error) => {\n    return Promise.reject(error);\n  }\n);\n\n// Add a response interceptor for error handling\napi.interceptors.response.use(\n  (response) => response,\n  (error) => {\n    let errorMessage = 'An unexpected error occurred. Please try again.';\n    let errorCode = 'UNKNOWN_ERROR';\n\n    if (error.response) {\n      // The request was made and the server responded with a status code\n      // that falls out of the range of 2xx\n      const errorData = error.response.data;\n      errorCode = errorData.code || error.response.statusText;\n      errorMessage = errorData.message || `Server responded with status: ${error.response.status}`;\n\n      // Handle specific API error structures if defined\n      if (errorData && errorData.details) {\n        console.error('API Error Details:', errorData.details);\n        // Potentially map details to more user-friendly messages\n      }\n    } else if (error.request) {\n      // The request was made but no response was received\n      errorMessage = 'Network error: No response from server. Please check your connection.';\n      errorCode = 'NETWORK_ERROR';\n    } else {\n      // Something happened in setting up the request that triggered an Error\n      errorMessage = error.message;\n      errorCode = 'REQUEST_SETUP_ERROR';\n    }\n\n    // Re-throw a structured error object for components to catch\n    return Promise.reject({\n      code: errorCode,\n      message: errorMessage,\n      status: error.response?.status,\n    });\n  }\n);\n\nexport default api;\n"
      },
      "zustand_store": {
        "file_path": "src/store/aiStore.ts",
        "code_snippet": "import { create } from 'zustand';\nimport api from '../lib/api';\n\n// Define types based on Lyra's contract\ninterface SystemMessage {\n  role: 'system';\n  content: string;\n}\n\ninterface UserMessage {\n  role: 'user';\n  content: string;\n}\n\ninterface AssistantMessage {\n  role: 'assistant';\n  content: string;\n  id?: string; // response_id\n}\n\ntype Message = SystemMessage | UserMessage | AssistantMessage;\n\ninterface AIResponse {\n  id: string;\n  conversation_id: string;\n  output: {\n    type: 'text' | 'image_url' | 'structured_json';\n    content: string;\n  };\n  metadata?: {\n    model: string;\n    prompt_tokens: number;\n    completion_tokens: number;\n    total_tokens: number;\n    timestamp: string;\n  };\n}\n\ninterface ConversationSummary {\n  id: string;\n  title: string;\n  last_updated: string;\n  preview_messages: {\n    role: 'user' | 'assistant';\n    content_snippet: string;\n  }[];\n}\n\ninterface AIState {\n  // Interaction State\n  currentPrompt: string;\n  messages: Message[]; // Current conversation history\n  conversationId: string | null;\n  aiResponse: AIResponse | null;\n  isLoading: boolean;\n  error: { code: string; message: string } | null;\n\n  // History State\n  conversations: ConversationSummary[];\n  historyIsLoading: boolean;\n  historyError: { code: string; message: string } | null;\n\n  // Actions\n  setPrompt: (prompt: string) => void;\n  fetchAiResponse: (userId: string) => Promise<void>;\n  setResponse: (response: AIResponse | null) => void;\n  setError: (error: { code: string; message: string } | null) => void;\n  clearError: () => void;\n  addMessage: (message: Message) => void;\n  loadConversationHistory: (userId: string, limit?: number, offset?: number) => Promise<void>;\n  loadSpecificConversation: (userId: string, conversationId: string) => Promise<void>;\n  submitFeedback: (userId: string, responseId: string, feedbackType: 'like' | 'dislike', comment?: string) => Promise<void>;\n  clearInteractionState: () => void;\n}\n\nconst SYSTEM_PROMPT = 'You are a helpful and concise AI assistant named AuraFlow. Provide direct answers.';\n\nexport const useAIStore = create<AIState>((set, get) => ({\n  // Initial State\n  currentPrompt: '',\n  messages: [{ role: 'system', content: SYSTEM_PROMPT }],\n  conversationId: null,\n  aiResponse: null,\n  isLoading: false,\n  error: null,\n  conversations: [],\n  historyIsLoading: false,\n  historyError: null,\n\n  // Actions\n  setPrompt: (prompt) => set({ currentPrompt: prompt }),\n\n  fetchAiResponse: async (userId) => {\n    const { currentPrompt, messages, conversationId } = get();\n    if (!currentPrompt.trim()) return;\n\n    set({ isLoading: true, error: null });\n\n    const userMessage: UserMessage = { role: 'user', content: currentPrompt };\n    const updatedMessages = [...messages, userMessage];\n\n    try {\n      const response = await api.post<AIResponse>('/generate', {\n        user_id: userId,\n        conversation_id: conversationId,\n        messages: updatedMessages,\n        // TODO: Add model_parameters and stream options if needed\n        stream: false, // For simplicity initially, implement streaming later\n      });\n\n      const aiResponseData = response.data;\n      set({\n        aiResponse: aiResponseData,\n        conversationId: aiResponseData.conversation_id,\n        messages: [...updatedMessages, { role: 'assistant', content: aiResponseData.output.content, id: aiResponseData.id }],\n        isLoading: false,\n      });\n      // Clear current prompt after successful response\n      set({ currentPrompt: '' });\n\n    } catch (error: any) {\n      console.error('Error fetching AI response:', error);\n      set({\n        error: { code: error.code || 'FETCH_ERROR', message: error.message || 'Failed to get response from AI.' },\n        isLoading: false,\n      });\n    }\n  },\n\n  setResponse: (response) => set({ aiResponse: response }),\n  setError: (error) => set({ error }),\n  clearError: () => set({ error: null }),\n\n  addMessage: (message) => set((state) => ({ messages: [...state.messages, message] })),\n\n  loadConversationHistory: async (userId, limit = 20, offset = 0) => {\n    set({ historyIsLoading: true, historyError: null });\n    try {\n      const response = await api.get<{\n        conversations: ConversationSummary[];\n        total_count: number;\n      }>('/history', {\n        params: { user_id: userId, limit, offset },\n      });\n      set({\n        conversations: response.data.conversations,\n        historyIsLoading: false,\n      });\n    } catch (error: any) {\n      console.error('Error loading conversation history:', error);\n      set({\n        historyError: { code: error.code || 'HISTORY_LOAD_ERROR', message: error.message || 'Failed to load history.' },\n        historyIsLoading: false,\n      });\n    }\n  },\n\n  loadSpecificConversation: async (userId, conversationId) => {\n    set({ isLoading: true, error: null, messages: [{ role: 'system', content: SYSTEM_PROMPT }] }); // Reset messages with system prompt\n    try {\n      const response = await api.get<{\n        id: string;\n        title: string;\n        messages: Message[];\n      }>(\`/history/${conversationId}\`, {\n        params: { user_id: userId },\n      });\n      \n      // Filter out system messages from loaded history if they are not needed in the context\n      const conversationMessages = response.data.messages.filter(msg => msg.role !== 'system');\n\n      set({\n        conversationId: response.data.id,\n        messages: [{ role: 'system', content: SYSTEM_PROMPT }, ...conversationMessages],\n        aiResponse: null, // Clear previous response\n        currentPrompt: '', // Clear prompt\n        isLoading: false,\n      });\n    } catch (error: any) {\n      console.error('Error loading specific conversation:', error);\n      set({\n        error: { code: error.code || 'CONV_LOAD_ERROR', message: error.message || 'Failed to load conversation.' },\n        isLoading: false,\n      });\n    }\n  },\n\n  submitFeedback: async (userId, responseId, feedbackType, comment) => {\n    try {\n      await api.post('/feedback', {\n        user_id: userId,\n        response_id: responseId,\n        feedback_type: feedbackType,\n        comment: comment,\n      });\n      // Optionally update UI to show feedback was submitted\n      console.log(`Feedback (${feedbackType}) submitted for response ${responseId}`);\n    } catch (error: any) {\n      console.error('Error submitting feedback:', error);\n      // Handle feedback submission error, maybe show a toast\n    }\n  },\n\n  clearInteractionState: () => {\n    set({\n      currentPrompt: '',\n      messages: [{ role: 'system', content: SYSTEM_PROMPT }],\n      conversationId: null,\n      aiResponse: null,\n      isLoading: false,\n      error: null,\n    });\n  }\n}));\n"
      },
      "homepage_integration_notes": "In `HomePage.tsx`, use `useAIStore` to get `currentPrompt`, `messages`, `isLoading`, `error`, `aiResponse`, `conversationId`. Use `setPrompt`, `fetchAiResponse`, `clearError` from the store. Bind input value and onChange. Call `fetchAiResponse` on button click. Conditionally render `LoadingIndicator` and `ResponseCard`. Display error messages.",
      "historypage_integration_notes": "In `HistoryPage.tsx`, use `useAIStore` to get `conversations`, `historyIsLoading`, `historyError`. Use `loadConversationHistory`, `loadSpecificConversation`. Fetch history on component mount using `useEffect`. Render conversations in a list. Each item links to `loadSpecificConversation`.",
      "feedback_integration_notes": "In `HomePage.tsx`'s `ResponseCard` or action area, implement `FeedbackButton` components. Their `onClick` handlers will call `submitFeedback` from the store, passing the necessary `responseId` (from `aiResponse.id`) and `feedbackType`."
    },
    "next_steps_for_kodax": [
      "Implement the `HomePage.tsx` component, integrating the `Input`, `Button`, `ResponseCard`, `FeedbackButton`, and `LoadingIndicator` components with the `useAIStore` hooks and actions.",
      "Implement the `HistoryPage.tsx` component, fetching and displaying conversation summaries using the `useAIStore` hooks and actions.",
      "Implement routing to navigate between `HomePage` and `HistoryPage` using `react-router-dom`.",
      "Add placeholder for user ID (e.g., `const userId = 'user-123';`) and pass it to store actions. A real implementation would fetch this from an authentication context.",
      "Consider implementing streaming for the `/generate` endpoint for a more interactive experience, which would involve modifications to `fetchAiResponse` and the `ResponseCard` display logic."
    ]
  }
}
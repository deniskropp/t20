{
  "feedback_loop_architecture": {
    "overall_flow": "User submits feedback -> Raw data stored -> Scheduled analysis job processes data (quant. & qual.) -> Actionable insights generated -> Insights used for prompt modification.",
    "data_ingestion": {
      "source": "User feedback via '/api/feedback' endpoint (as per Kodax's API design).",
      "storage": "Dedicated 'feedback' table in the database (as per Kodax's schema), linked to 'jokes' table via 'joke_id'."
    },
    "quantitative_analysis": {
      "purpose": "To derive statistical metrics from structured multi-axis ratings, identifying overall performance, trends, and specific areas of strength or weakness against the 'genuinely fresh' humor criteria.",
      "input_data": [
        "joke_id",
        "originality_rating",
        "cleverness_rating",
        "surprise_rating",
        "relatability_rating",
        "submitted_at"
      ],
      "analysis_methods": [
        {
          "method": "Average Rating Calculation",
          "description": "Calculate mean rating for each axis (Originality, Cleverness, Surprise, Relatability) per individual joke, per batch of jokes, and as an overall average across all jokes. This directly reflects performance against the 'genuinely fresh' rules (Originality, Subvert Expectations, Juxtapose Disparate Ideas, Observational Depth).",
          "metrics_generated": [
            "Avg_Rating_Per_Joke (for each axis)",
            "Overall_Avg_Rating (for each axis)",
            "Avg_Rating_by_Prompt_Version (requires linking joke to prompt version)"
          ]
        },
        {
          "method": "Rating Distribution Analysis",
          "description": "Analyze the frequency distribution of ratings (e.g., percentage of 1-star vs. 5-star ratings for each axis) to identify consistent patterns of user satisfaction or dissatisfaction.",
          "metrics_generated": [
            "Percentage_of_Low_Ratings (<3) per axis",
            "Percentage_of_High_Ratings (>3) per axis"
          ]
        },
        {
          "method": "Performance Thresholding",
          "description": "Establish predefined thresholds (e.g., an average rating below 3.0 for 'Originality' signifies a critical issue) to automatically flag jokes or prompt versions for review.",
          "metrics_generated": [
            "Flagged_Low_Performing_Jokes",
            "Flagged_Underperforming_Prompt_Versions"
          ]
        },
        {
          "method": "Trend Analysis",
          "description": "Monitor changes in average ratings over time to observe the impact of iterative prompt modifications and identify long-term performance shifts.",
          "metrics_generated": [
            "Time-series_Avg_Ratings_per_axis"
          ]
        }
      ],
      "output_format": "Structured JSON reports, statistical summaries, and visual dashboards."
    },
    "qualitative_analysis": {
      "purpose": "To extract nuanced insights, specific user sentiments, and thematic feedback from open-ended comments, providing context to quantitative data and identifying issues not captured by numerical ratings (e.g., adherence to persona, specific failures in 'no offensive content').",
      "input_data": "text_feedback from 'feedback' table (as per Kodax's schema).",
      "analysis_methods": [
        {
          "method": "Sentiment Analysis",
          "description": "Determine the emotional tone (positive, negative, neutral) of each text feedback comment to quickly gauge overall user reaction.",
          "metrics_generated": [
            "Sentiment_Score_Per_Comment",
            "Overall_Sentiment_Distribution"
          ]
        },
        {
          "method": "Keyword and Phrase Extraction",
          "description": "Identify frequently used keywords or phrases, particularly those associated with positive or negative sentiment. Focus on terms directly related to the humor rules and persona (e.g., 'absurd', 'clever', 'dry', 'unexpected', 'predictable', 'offensive', 'recycled', 'too long', 'confusing').",
          "metrics_generated": [
            "Top_Positive_Keywords/Phrases",
            "Top_Negative_Keywords/Phrases",
            "Frequency_of_Persona_Related_Terms"
          ]
        },
        {
          "method": "Topic Modeling / Clustering",
          "description": "Group similar text feedback comments into thematic clusters to identify recurring feedback patterns, such as 'too verbose,' 'not relatable,' or 'excellent twist,' which inform specific prompt adjustments.",
          "metrics_generated": [
            "Identified_Feedback_Themes",
            "Dominant_Topics_and_Their_Associated_Sentiment"
          ]
        },
        {
          "method": "Offensive Content Detection & Flagging",
          "description": "Implement automated detection for inappropriate, discriminatory, or offensive language as per the 'No Offensive Content' rule. Flag such comments for immediate human review and prompt adjustment.",
          "metrics_generated": [
            "Flagged_Offensive_Comments_Count",
            "Severity_Score_of_Offensive_Content"
          ]
        }
      ],
      "output_format": "Summarized themes, keyword clouds, sentiment scores, and flagged comments for review."
    },
    "actionable_insights_generation": {
      "purpose": "To synthesize quantitative and qualitative analyses into concrete, prioritized suggestions for modifying the core humor generation prompt, directly addressing identified performance gaps and aligning with the 'genuinely fresh artificial intelligence humor' goal.",
      "process": [
        "**1. Performance Gap Identification:** Compare current quantitative metrics (e.g., average originality rating) against desired benchmarks or the performance of previous prompt versions.",
        "**2. Root Cause Analysis & Correlation:** Correlate quantitative underperformance with specific qualitative feedback. For example, if 'Originality' is low, check if text feedback frequently contains phrases like 'heard this before' or 'lacks novelty'.",
        "**3. Mapping to Prompt Rules:** Directly map identified issues and their root causes to specific rules or parameters within the 'Cogito' system prompt (e.g., 'Originality First', 'Subvert Expectations', 'Juxtapose Disparate Ideas', 'Observational Depth', 'Avoid Clich√©s', 'Conciseness', 'No Offensive Content').",
        "**4. Prioritization:** Rank insights based on severity (e.g., offensive content is critical and requires immediate action) and potential impact on humor quality and freshness.",
        "**5. Suggestion Formulation:** Formulate specific, actionable recommendations for prompt modification. These suggestions should be phrased as clear directives that can be programmatically integrated into the strategic adjustment system.",
        "**Example Insight Generation Flow:**",
        "    *   **Problem Area:** 'Jokes are perceived as predictable and lack genuine surprise.'",
        "    *   **Evidence (Quantitative):** 'Average Surprise Rating: 2.1/5 (target: 4.0).'",
        "    *   **Evidence (Qualitative):** 'Common text feedback includes 'saw that coming', 'obvious punchline', 'not surprising'.'",
        "    *   **Relevant Prompt Rule:** 'Subvert Expectations'.",
        "    *   **Actionable Prompt Modification Suggestion:** 'Refine the 'Subvert Expectations' rule to include: 'Explicitly generate 2-3 common, predictable twists for the given setup internally, then ensure your final joke's punchline is fundamentally different and more unexpected than all of them. Consider introducing a surreal or illogical element that defies initial setup expectations.''",
        "    *   **Priority:** 'High'"
      ],
      "insight_structure": {
        "problem_area": "A concise description of the identified performance issue (e.g., 'Lack of Originality', 'Offensive Content Detected').",
        "evidence_quantitative": "Key metrics supporting the problem (e.g., 'Avg. originality rating: 2.8/5').",
        "evidence_qualitative": "Summarized qualitative findings (e.g., 'Common keywords: 'generic', 'recycled', 'seen this before'; or 'Flagged comment: 'that's offensive'').",
        "relevant_prompt_rule": "The specific rule(s) in the core AI prompt that need adjustment (e.g., 'Originality First', 'No Offensive Content').",
        "actionable_prompt_modification_suggestion": "A clear, specific instruction or modification to be applied to the core AI prompt.",
        "priority": "Indicates the urgency of the modification ('Critical', 'High', 'Medium', 'Low')."
      },
      "feedback_loop_integration_point": "These generated actionable insights will serve as the primary input for Lyra's subsequent task: creating the 'strategic adjustment' meta-prompting system, ensuring continuous refinement of the AI's humor generation."
    }
  }
}
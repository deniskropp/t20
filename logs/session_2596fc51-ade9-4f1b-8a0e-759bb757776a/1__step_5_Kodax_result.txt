{
  "task_id": "e5f6a7b8-c9d0-1234-5678-90abcdef1234",
  "task_name": "Implement the back-end logic, including API endpoints, database integration, and the core image recognition service that utilizes Lyra's prompt workflow.",
  "role": "Engineer (Kodax)",
  "dependencies": [
    "Artifact from 1__step_1_Lyra_result.txt (Prompt Engineer)",
    "Artifact from 1__step_3_Kodax_result.txt (Engineer - System Architecture and Tooling)",
    "Artifact from 1__step_4_Kodax_result.txt (Engineer - Frontend)"
  ],
  "output_description": "Backend API service implementation, including endpoints for image submission and feedback, orchestration of Lyra's prompt workflow, and integration with the database.",
  "implementation_plan": [
    {
      "step": 1,
      "action": "Set up Backend Project",
      "details": "Initialize a Node.js project using Express.js. Set up basic server structure, middleware (like CORS, body-parser), and project dependencies.",
      "tools": ["Node.js", "Express.js", "npm/yarn", "cors", "body-parser"]
    },
    {
      "step": 2,
      "action": "Database Integration",
      "details": "Implement database connection logic using a PostgreSQL client (e.g., `pg`) and the `pgvector` extension. Define models or classes for interacting with the `images` and `feedback` tables.",
      "deliverables": ["db.js (connection module)", "models/Image.js", "models/Feedback.js"],
      "tools": ["pg", "dotenv (for credentials)"]
    },
    {
      "step": 3,
      "action": "Implement Image Upload and Processing",
      "details": "Create an API endpoint (e.g., `/api/recognize`) that accepts multipart/form-data for image uploads. Use a library like `multer` to handle file uploads and convert the image to a format suitable for the recognition engine (e.g., base64 string).",
      "deliverables": ["routes/recognitionRoutes.js", "controllers/recognitionController.js"],
      "tools": ["Express.js", "multer"]
    },
    {
      "step": 4,
      "action": "Orchestrate Lyra's Prompt Workflow",
      "details": "Develop a service or module that manages the sequence of calls to the image recognition engine, following Lyra's defined prompt workflow (steps 1-4). This involves: \n1. Sending the image to the engine for analysis (Step 1).\n2. Receiving analysis results and generating a database query (Step 2).\n3. Querying the database to retrieve candidate images.\n4. Sending candidates and live image analysis to the engine for scoring (Step 3).\n5. Receiving scores and making a final decision (Step 4).\n6. Returning the structured recognition result to the frontend.",
      "deliverables": ["services/recognitionService.js", "utils/promptExecutor.js"],
      "tools": ["Node.js", "Python script execution (if ML engine is separate)", "HTTP client for inter-service communication"]
    },
    {
      "step": 5,
      "action": "Integrate with Image Recognition Engine",
      "details": "Establish communication with the actual image recognition engine. This could involve: \n- If Python-based: Executing Python scripts that use the defined prompts.\n- If a separate microservice: Making HTTP requests to its API.\n- If using a managed AI service: Interfacing with its SDK.",
      "deliverables": ["clients/mlEngineClient.js"],
      "tools": ["child_process (for script execution)", "axios (for API calls)"]
    },
    {
      "step": 6,
      "action": "Implement Database Query Logic",
      "details": "Write functions within the `recognitionService` to query the database based on keywords and/or vector embeddings generated by Lyra's workflow. This includes fetching candidate images for comparison.",
      "deliverables": ["repositories/imageRepository.js"],
      "tools": ["pg", "pgvector query syntax"]
    },
    {
      "step": 7,
      "action": "Implement Feedback Endpoint",
      "details": "Create an API endpoint (e.g., `/api/feedback`) to receive user feedback data from the frontend. Store this data in the `feedback` table in the database.",
      "deliverables": ["routes/feedbackRoutes.js", "controllers/feedbackController.js", "repositories/feedbackRepository.js"],
      "tools": ["Express.js", "pg"]
    },
    {
      "step": 8,
      "action": "Error Handling and Logging",
      "details": "Implement robust error handling for API requests, database operations, and recognition engine interactions. Use a logging library (e.g., Winston) to record important events and errors.",
      "deliverables": ["middleware/errorHandler.js", "utils/logger.js"],
      "tools": ["Winston", "Express error handling middleware"]
    },
    {
      "step": 9,
      "action": "Configuration Management",
      "details": "Manage environment-specific configurations (database credentials, API keys, ML engine endpoints) using environment variables and a library like `dotenv`.",
      "deliverables": [".env file template", "config/index.js"],
      "tools": ["dotenv"]
    },
    {
      "step": 10,
      "action": "Testing",
      "details": "Write unit and integration tests for backend services, API endpoints, and database interactions.",
      "deliverables": ["Backend test suite"],
      "tools": ["Jest", "Supertest"]
    }
  ],
  "code_snippets": {
    "server.js": "require('dotenv').config();\nconst express = require('express');\nconst cors = require('cors');\nconst recognitionRoutes = require('./routes/recognitionRoutes');\nconst feedbackRoutes = require('./routes/feedbackRoutes');\nconst errorHandler = require('./middleware/errorHandler');\nconst logger = require('./utils/logger');\n\nconst app = express();\nconst PORT = process.env.PORT || 5000;\n\n// Middleware\napp.use(cors()); // Enable CORS for all origins, configure as needed\napp.use(express.json({ limit: '50mb' })); // Increased limit for image data\napp.use(express.urlencoded({ extended: true, limit: '50mb' })); // For form data\n\n// Logging middleware\napp.use((req, res, next) => {\n  logger.info(`${req.method} ${req.url}`);\n  next();\n});\n\n// API Routes\napp.use('/api/recognize', recognitionRoutes);\napp.use('/api/feedback', feedbackRoutes);\n\n// Health check endpoint\napp.get('/', (req, res) => {\n  res.status(200).json({ message: 'Image Recognition API is running' });\n});\n\n// Error handling middleware (should be the last middleware)\napp.use(errorHandler);\n\napp.listen(PORT, () => {\n  logger.info(`Server is running on port ${PORT}`);\n});\n",
    "routes/recognitionRoutes.js": "const express = require('express');\nconst router = express.Router();\nconst multer = require('multer');\nconst recognitionController = require('../controllers/recognitionController');\n\n// Configure Multer for in-memory storage\nconst storage = multer.memoryStorage();\nconst upload = multer({ \n  storage: storage,\n  limits: { fileSize: 10 * 1024 * 1024 } // 10MB file size limit\n});\n\n// POST /api/recognize - Handles image upload and recognition request\nrouter.post('/', upload.single('image'), recognitionController.recognizeImage);\n\nmodule.exports = router;\n",
    "controllers/recognitionController.js": "const recognitionService = require('../services/recognitionService');\nconst logger = require('../utils/logger');\n\nexports.recognizeImage = async (req, res, next) => {\n  if (!req.file) {\n    return res.status(400).json({ message: 'No image file uploaded.' });\n  }\n\n  // Convert buffer to base64 string for the AI model\n  const imageBase64 = req.file.buffer.toString('base64');\n  const mimeType = req.file.mimetype;\n\n  try {\n    logger.info(`Received image for recognition: ${req.file.originalname} (${req.file.size} bytes)`);\n    const result = await recognitionService.processImageForRecognition(imageBase64, mimeType);\n    res.status(200).json(result);\n  } catch (error) {\n    logger.error(`Error during image recognition: ${error.message}`, error);\n    // Pass error to the global error handler\n    next(error);\n  }\n};\n",
    "services/recognitionService.js": "const logger = require('../utils/logger');\nconst db = require('../db'); // Assuming db.js handles DB connection\nconst mlEngineClient = require('../clients/mlEngineClient');\nconst imageRepository = require('../repositories/imageRepository');\n\n// Placeholder for Lyra's prompt workflow logic\nasync function executeLyraWorkflow(imageBase64, mimeType) {\n  logger.info('Executing Lyra workflow...');\n\n  // Step 1: Live Image Feature Extraction and Description\n  logger.debug('Step 1: Live Image Analysis');\n  const analysisResult = await mlEngineClient.analyzeImage(imageBase64, mimeType);\n  if (!analysisResult || !analysisResult.extracted_keywords) {\n      throw new Error('Image analysis failed.');\n  }\n  logger.debug('Analysis result:', analysisResult);\n\n  // Step 2: Database Query Generation\n  logger.debug('Step 2: Database Query Generation');\n  const queryParams = await mlEngineClient.generateQuery(analysisResult);\n  logger.debug('Query parameters:', queryParams);\n\n  // Step 3: Candidate Image Comparison and Similarity Scoring\n  logger.debug('Step 3: Candidate Image Comparison');\n  // Fetch candidates from DB using queryParams (keyword_query, semantic_query_vector)\n  const candidateImages = await imageRepository.findCandidates(queryParams);\n  if (candidateImages.length === 0) {\n      logger.warn('No candidate images found in the database.');\n      // Return a default 'no match' if no candidates are found early\n      return {\n          recognition_status: 'no_confident_match',\n          explanation: 'No similar images found in the database.',\n          closest_matches: []\n      };\n  }\n  logger.debug(`Found ${candidateImages.length} candidates.`);\n\n  const similarityScores = await mlEngineClient.assessSimilarity(analysisResult, candidateImages);\n  if (!similarityScores || similarityScores.length === 0) {\n      throw new Error('Similarity assessment failed.');\n  }\n  logger.debug('Similarity scores:', similarityScores);\n\n  // Step 4: Final Recognition Decision\n  logger.debug('Step 4: Final Recognition Decision');\n  const recognitionDecision = await mlEngineClient.makeDecision(similarityScores);\n  logger.debug('Recognition decision:', recognitionDecision);\n\n  // Augment results with actual image URLs from the database if available\n  if (recognitionDecision.recognized_image) {\n      const matchedImage = await imageRepository.findById(recognitionDecision.recognized_image.image_id);\n      if (matchedImage) {\n          recognitionDecision.recognized_image.image_url = matchedImage.image_url;\n          recognitionDecision.recognized_image.caption = matchedImage.caption;\n      }\n  }\n  if (recognitionDecision.closest_matches) {\n      for (let i = 0; i < recognitionDecision.closest_matches.length; i++) {\n          const matchedImage = await imageRepository.findById(recognitionDecision.closest_matches[i].image_id);\n          if (matchedImage) {\n              recognitionDecision.closest_matches[i].image_url = matchedImage.image_url;\n              recognitionDecision.closest_matches[i].caption = matchedImage.caption;\n          }\n      }\n  }\n\n  return recognitionDecision;\n}\n\nexports.processImageForRecognition = async (imageBase64, mimeType) => {\n  try {\n    const recognitionResult = await executeLyraWorkflow(imageBase64, mimeType);\n    return recognitionResult;\n  } catch (error) {\n    logger.error(`Service error in processImageForRecognition: ${error.message}`, error);\n    // Re-throw to be caught by the controller's error handler\n    throw error;\n  }\n};\n",
    "clients/mlEngineClient.js": "// This client acts as an interface to the ML engine.\n// It could be calling a Python script, another microservice, or a cloud AI API.\n// For demonstration, we'll use mock functions that simulate responses.\n\nconst logger = require('../utils/logger');\n\n// Mock function to simulate image analysis\nconst analyzeImage = async (imageBase64, mimeType) => {\n  logger.debug('ML Engine: Analyzing image...');\n  // Simulate API call to ML model for analysis\n  // In a real scenario, this would involve sending imageBase64 to the model\n  // and receiving a structured response.\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      resolve({\n        textual_description: \"A red car parked on a street.\",\n        extracted_keywords: [\"red car\", \"street\", \"vehicle\"],\n        image_embedding_vector: [0.1, 0.2, 0.3, /* ... */] // Mock vector\n      });\n    }, 500);\n  });\n};\n\n// Mock function to simulate query generation\nconst generateQuery = async (analysisResult) => {\n  logger.debug('ML Engine: Generating query...');\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      resolve({\n        keyword_query: `Find images related to: ${analysisResult.extracted_keywords.join(', ')}`,\n        semantic_query_vector: analysisResult.image_embedding_vector // Use embedding for vector search\n      });\n    }, 300);\n  });\n};\n\n// Mock function to simulate similarity assessment\nconst assessSimilarity = async (liveImageAnalysis, candidateImages) => {\n  logger.debug('ML Engine: Assessing similarity...');\n  // candidateImages would be an array of objects like: { image_id, caption, keywords, embedding }\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      const scores = candidateImages.map((candidate, index) => ({\n        image_id: candidate.image_id,\n        caption: candidate.caption,\n        similarity_score: Math.max(0, 1 - index * 0.15) - Math.random() * 0.1, // Simulate varying scores\n        justification: `Visual match for '${candidate.caption}' with keywords: ${candidate.keywords.join(', ')}`\n      }));\n      // Sort by score descending\n      scores.sort((a, b) => b.similarity_score - a.similarity_score);\n      resolve(scores);\n    }, 600);\n  });\n};\n\n// Mock function to simulate final decision making\nconst makeDecision = async (similarityScores) => {\n  logger.debug('ML Engine: Making decision...');\n  const recognition_threshold = 0.8;\n  const delta_threshold = 0.1;\n\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      if (similarityScores.length > 0 && similarityScores[0].similarity_score >= recognition_threshold) {\n        const topScore = similarityScores[0].similarity_score;\n        const secondScore = similarityScores.length > 1 ? similarityScores[1].similarity_score : 0;\n\n        if (topScore - secondScore >= delta_threshold) {\n          // Confident match\n          resolve({\n            recognition_status: 'recognized',\n            recognized_image: {\n              image_id: similarityScores[0].image_id,\n              confidence_score: similarityScores[0].similarity_score,\n              // image_url and caption will be added by the service layer after DB lookup\n            },\n            explanation: `Confident match found with score ${topScore.toFixed(2)}.`\n          });\n        } else {\n          // High score but close to second, no confident match\n          resolve({\n            recognition_status: 'no_confident_match',\n            closest_matches: similarityScores.slice(0, 3),\n            explanation: `Top score ${topScore.toFixed(2)} is too close to the next best score (${secondScore.toFixed(2)}).`\n          });\n        }\n      } else {\n        // No confident match based on threshold\n        resolve({\n          recognition_status: 'no_confident_match',\n          closest_matches: similarityScores.slice(0, 3),\n          explanation: `Top score ${similarityScores.length > 0 ? similarityScores[0].similarity_score.toFixed(2) : 'N/A'} is below the recognition threshold.`\n        });\n      }\n    }, 400);\n  });\n};\n\nmodule.exports = {\n  analyzeImage,\n  generateQuery,\n  assessSimilarity,\n  makeDecision\n};\n",
    "repositories/imageRepository.js": "const logger = require('../utils/logger');\nconst pool = require('../db'); // Assuming db.js provides a pool\n\n// Mock data for demonstration purposes\nconst mockImages = [\n  { image_id: 'img-001', image_url: '/path/to/img1.jpg', caption: 'A red sports car', keywords: ['car', 'red', 'sports car', 'vehicle'], embedding: [0.1, 0.2, 0.3, /*...*/] },\n  { image_id: 'img-002', image_url: '/path/to/img2.jpg', caption: 'A blue sedan', keywords: ['car', 'blue', 'sedan', 'vehicle'], embedding: [0.4, 0.5, 0.6, /*...*/] },\n  { image_id: 'img-003', image_url: '/path/to/img3.jpg', caption: 'A mountain landscape', keywords: ['mountain', 'landscape', 'nature', 'scenic'], embedding: [0.7, 0.8, 0.9, /*...*/] },\n];\n\n// Function to find candidate images based on query parameters\nconst findCandidates = async (queryParams) => {\n  logger.debug('Image Repository: Finding candidates...');\n  // In a real implementation, this would query PostgreSQL with pgvector\n  // Example using keyword search:\n  // const keywordQuery = queryParams.keyword_query;\n  // Example using vector search:\n  // const vectorQuery = queryParams.semantic_query_vector;\n\n  // For this mock, we'll just return a subset based on keywords if available\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      if (queryParams.keyword_query) {\n        const searchTerms = queryParams.keyword_query.toLowerCase().split(/[, ]+/);\n        const candidates = mockImages.filter(img => \n          searchTerms.some(term => img.caption.toLowerCase().includes(term) || img.keywords.includes(term))\n        );\n        resolve(candidates.slice(0, 5)); // Return top 5 matches\n      } else {\n        resolve(mockImages.slice(0, 5)); // Default to some images if no keywords\n      }\n    }, 300);\n  });\n};\n\n// Function to find an image by its ID\nconst findById = async (imageId) => {\n  logger.debug(`Image Repository: Finding image by ID: ${imageId}`);\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      const image = mockImages.find(img => img.image_id === imageId);\n      resolve(image || null);\n    }, 100);\n  });\n};\n\nmodule.exports = {\n  findCandidates,\n  findById\n};\n",
    "routes/feedbackRoutes.js": "const express = require('express');\nconst router = express.Router();\nconst feedbackController = require('../controllers/feedbackController');\n\n// POST /api/feedback - Handles user feedback submission\nrouter.post('/', feedbackController.submitFeedback);\n\nmodule.exports = router;\n",
    "controllers/feedbackController.js": "const feedbackService = require('../services/feedbackService');\nconst logger = require('../utils/logger');\n\nexports.submitFeedback = async (req, res, next) => {\n  const { image_id, is_correct, user_correction } = req.body;\n\n  if (!image_id || typeof is_correct === 'undefined') {\n    return res.status(400).json({ message: 'Missing required feedback fields: image_id and is_correct.' });\n  }\n\n  try {\n    logger.info(`Received feedback for image_id: ${image_id}, Correct: ${is_correct}`);\n    await feedbackService.saveFeedback(image_id, is_correct, user_correction);\n    res.status(200).json({ message: 'Feedback received successfully.' });\n  } catch (error) {\n    logger.error(`Error submitting feedback: ${error.message}`, error);\n    next(error);\n  }\n};\n",
    "services/feedbackService.js": "const logger = require('../utils/logger');\nconst feedbackRepository = require('../repositories/feedbackRepository');\n\nexports.saveFeedback = async (imageId, isCorrect, userCorrection) => {\n  try {\n    await feedbackRepository.create(imageId, isCorrect, userCorrection);\n    logger.info(`Feedback saved for image ${imageId}`);\n  } catch (error) {\n    logger.error(`Failed to save feedback in service: ${error.message}`, error);\n    throw error;\n  }\n};\n",
    "repositories/feedbackRepository.js": "const logger = require('../utils/logger');\nconst pool = require('../db');\nconst { v4: uuidv4 } = require('uuid');\n\nconst create = async (imageId, isCorrect, userCorrection) => {\n  logger.debug(`Feedback Repository: Creating feedback for image ${imageId}`);\n  const feedbackId = uuidv4();\n  const query = {\n    text: 'INSERT INTO feedback(feedback_id, image_id, user_submission_timestamp, is_correct, user_correction) VALUES($1, $2, NOW(), $3, $4) RETURNING feedback_id',\n    values: [feedbackId, imageId, isCorrect, userCorrection || null],\n  };\n\n  try {\n    const result = await pool.query(query);\n    logger.info(`Feedback created with ID: ${result.rows[0].feedback_id}`);\n    return result.rows[0];\n  } catch (err) {\n    logger.error(`Error executing feedback insert query: ${err.message}`, err);\n    throw err;\n  }\n};\n\nmodule.exports = {\n  create\n};\n",
    "db.js": "const { Pool } = require('pg');\nconst logger = require('./utils/logger');\n\n// Configure the PostgreSQL client\nconst pool = new Pool({\n  user: process.env.DB_USER || 'postgres',\n  host: process.env.DB_HOST || 'localhost',\n  database: process.env.DB_NAME || 'imagedb',\n  password: process.env.DB_PASSWORD || 'password',\n  port: parseInt(process.env.DB_PORT || '5432', 10),\n  // Ensure pgvector is enabled if using managed services or custom setup\n});\n\n// Test the connection on startup\npool.connect((err, client, release) => {\n  if (err) {\n    logger.error('Database connection error:', err.stack);\n    // Consider exiting the process if DB is critical\n    // process.exit(1);\n  } else {\n    logger.info('Connected to PostgreSQL database.');\n    client.query('SELECT version()', (err, res) => {\n      release(); // Release the client back to the pool\n      if (err) {\n        logger.error('Error executing version query:', err.stack);\n      } else {\n        logger.info(`Database version: ${res.rows[0].version}`);\n      }\n    });\n  }\n});\n\n// Optional: Add event listeners for pool errors\npool.on('error', (err, client) => {\n  logger.error('Unexpected error on idle client:', err);\n  // Consider reconnect logic or process restart\n});\n\nmodule.exports = pool;\n",
    "middleware/errorHandler.js": "const logger = require('../utils/logger');\n\nmodule.exports = (err, req, res, next) => {\n  logger.error(`Unhandled error: ${err.message}`, err);\n\n  const statusCode = err.statusCode || 500;\n  const message = err.message || 'Internal Server Error';\n\n  // Respond with a JSON error object\n  res.status(statusCode).json({\n    message: message,\n    // Optionally include stack trace in development environments\n    stack: process.env.NODE_ENV === 'development' ? err.stack : undefined,\n  });\n};\n",
    "utils/logger.js": "// Basic logger setup using console for simplicity.\n// For production, consider libraries like Winston or Pino.\n\nconst logger = {\n  info: (...params) => {\n    console.log('[INFO]', ...params);\n  },\n  warn: (...params) => {\n    console.warn('[WARN]', ...params);\n  },\n  error: (...params) => {\n    console.error('[ERROR]', ...params);\n  },\n  debug: (...params) => {\n    // Only log debug messages if in development environment\n    if (process.env.NODE_ENV === 'development') {\n      console.log('[DEBUG]', ...params);\n    }\n  },\n};\n\nmodule.exports = logger;\n",
    "package.json": "{\n  \"name\": \"image-recognition-backend\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Backend for the living example image recognition service.\",\n  \"main\": \"server.js\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"cross-env NODE_ENV=development nodemon server.js\",\n    \"test\": \"jest\"\n  },\n  \"keywords\": [],\n  \"author\": \"Kodax\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"axios\": \"^1.6.8\",\n    \"body-parser\": \"^1.20.2\",\n    \"cors\": \"^2.8.5\",\n    \"dotenv\": \"^16.4.5\",\n    \"express\": \"^4.19.2\",\n    \"multer\": \"^1.4.5-lts.1\",\n    \"pg\": \"^8.11.5\",\n    \"pgvector\": \"^0.2.8\",\n    \"uuid\": \"^9.0.1\"\n  },\n  \"devDependencies\": {\n    \"cross-env\": \"^7.0.3\",\n    \"jest\": \"^29.7.0\",\n    \"nodemon\": \"^3.1.0\",\n    \"supertest\": \"^7.0.0\"\n  }\n}\n"
  }
}
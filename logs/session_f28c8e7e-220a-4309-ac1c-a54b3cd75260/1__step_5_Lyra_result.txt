{
  "finalized_prompts": {
    "joke_generation_prompt": {
      "name": "Joke Generation Prompt",
      "description": "Crafted to generate a concise, original, and family-friendly joke, formatted as a JSON object. Designed to be passed as the 'prompt' string to the LLM API endpoint.",
      "prompt_string": "You are a professional comedian and humorist. Generate a short, original, and family-friendly joke. The joke should be concise and appropriate for a general audience. Provide the joke as a JSON object with a single key 'joke'. Example: {\"joke\": \"Why did the scarecrow win an award? Because he was outstanding in his field!\"}",
      "api_payload_example": {
        "endpoint": "/jokes",
        "method": "POST",
        "body": {
          "prompt": "You are a professional comedian and humorist. Generate a short, original, and family-friendly joke. The joke should be concise and appropriate for a general audience. Provide the joke as a JSON object with a single key 'joke'. Example: {\"joke\": \"Why did the scarecrow win an award? Because he was outstanding in his field!\"}",
          "options": {
            "temperature": 0.7,
            "max_tokens": 100
          }
        }
      },
      "expected_response_schema": {
        "type": "object",
        "properties": {
          "joke": {
            "type": "string",
            "description": "The generated joke."
          },
          "model_info": {
            "type": "object",
            "description": "Details about the model used."
          }
        },
        "required": [
          "joke"
        ]
      }
    },
    "feedback_analysis_prompt": {
      "name": "Feedback Analysis Prompt",
      "description": "Designed to analyze user feedback on a joke, extracting sentiment, key points, and actionable recommendations. The joke, feedback, and rating are expected as separate input fields in the API request, with the prompt guiding the LLM's processing.",
      "prompt_string": "You are an expert humor analyst. Your task is to analyze a joke, its user feedback, and a numerical rating. Based on these inputs, determine the overall sentiment (positive, neutral, negative) of the feedback, extract specific key points (both positive and negative aspects mentioned), and formulate actionable recommendations for improving the joke if the feedback indicates areas for refinement. Output your analysis as a JSON object. Keys should be 'sentiment', 'key_points' (a list of strings summarizing aspects like 'clever wordplay', 'too long', 'offensive', 'originality', etc.), and 'recommendations' (a list of concise improvement suggestions, or an empty list if none). Example JSON output: {\"sentiment\": \"neutral\", \"key_points\": [\"cheesy\", \"clever pun\", \"unoriginal\"], \"recommendations\": [\"Suggest a less common setup.\"]}",
      "api_payload_example": {
        "endpoint": "/feedback/analyze",
        "method": "POST",
        "body": {
          "joke": "Why did the scarecrow win an award? Because he was outstanding in his field!",
          "feedback": "It's a bit cheesy, but I chuckled. The pun is clever, but I've heard it before. Maybe try a less common setup?",
          "rating": 3,
          "prompt": "You are an expert humor analyst. Your task is to analyze a joke, its user feedback, and a numerical rating. Based on these inputs, determine the overall sentiment (positive, neutral, negative) of the feedback, extract specific key points (both positive and negative aspects mentioned), and formulate actionable recommendations for improving the joke if the feedback indicates areas for refinement. Output your analysis as a JSON object. Keys should be 'sentiment', 'key_points' (a list of strings summarizing aspects like 'clever wordplay', 'too long', 'offensive', 'originality', etc.), and 'recommendations' (a list of concise improvement suggestions, or an empty list if none). Example JSON output: {\"sentiment\": \"neutral\", \"key_points\": [\"cheesy\", \"clever pun\", \"unoriginal\"], \"recommendations\": [\"Suggest a less common setup.\"]}",
          "options": {
            "temperature": 0.5,
            "max_tokens": 200
          }
        }
      },
      "expected_response_schema": {
        "type": "object",
        "properties": {
          "sentiment": {
            "type": "string",
            "enum": [
              "positive",
              "neutral",
              "negative"
            ]
          },
          "key_points": {
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "recommendations": {
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "sentiment",
          "key_points",
          "recommendations"
        ]
      }
    },
    "recommendations_generation_prompt": {
      "name": "Recommendations Generation Prompt",
      "description": "A prompt for generating personalized joke recommendations based on a user's profile and preferences. This prompt assumes an LLM endpoint that accepts a 'prompt' string, where user context is dynamically inserted. Note: Kodax's 'get_recommendations' endpoint is for retrieval, implying this generation would happen via a separate LLM call or internal process.",
      "prompt_string_template": "You are a personalized humor recommendation engine. Given the following user profile and past preferences: {USER_PROFILE_AND_PREFERENCES}, generate a list of 3-5 original, family-friendly joke recommendations. For each joke, include the joke text and a concise reason for why it's recommended, directly linking it to the user's preferences. Output as a JSON object with a 'recommendations' key, where the value is a list of objects, each having 'joke' (string) and 'reason' (string) keys. Example: {\"recommendations\": [{\"joke\": \"Why did the bicycle fall over? Because it was two tired!\", \"reason\": \"User enjoys clever puns and lighthearted humor.\"}, {\"joke\": \"What do you call a fake noodle? An impasta!\", \"reason\": \"User prefers food-related humor and short jokes.\"}]}",
      "api_payload_example_conceptual": {
        "endpoint": "/llm-generate" ,
        "method": "POST",
        "body": {
          "prompt": "You are a personalized humor recommendation engine. Given the following user profile and past preferences: { \"user_id\": \"user123\", \"liked_genres\": [\"puns\", \"observational\"], \"disliked_themes\": [\"dark humor\"], \"average_rating\": 4.2 }, generate a list of 3-5 original, family-friendly joke recommendations. For each joke, include the joke text and a concise reason for why it's recommended, directly linking it to the user's preferences. Output as a JSON object with a 'recommendations' key, where the value is a list of objects, each having 'joke' (string) and 'reason' (string) keys. Example: {\"recommendations\": [{\"joke\": \"Why did the bicycle fall over? Because it was two tired!\", \"reason\": \"User enjoys clever puns and lighthearted humor.\"}, {\"joke\": \"What do you call a fake noodle? An impasta!\", \"reason\": \"User prefers food-related humor and short jokes.\"}]}",
          "options": {
            "temperature": 0.8,
            "max_tokens": 300
          }
        }
      },
      "expected_response_schema": {
        "type": "object",
        "properties": {
          "recommendations": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "joke": {
                  "type": "string"
                },
                "reason": {
                  "type": "string"
                }
              },
              "required": [
                "joke",
                "reason"
              ]
            }
          }
        },
        "required": [
          "recommendations"
        ]
      },
      "notes": "The placeholder '{USER_PROFILE_AND_PREFERENCES}' in the `prompt_string_template` would be dynamically populated by the application's backend with actual user data before sending the request to the LLM API. The exact endpoint for this 'generation' (e.g., a generic `/llm-generate` or a specific `/recommendation/generate`) is assumed, as Kodax's `get_recommendations` endpoint is for retrieval."
    }
  },
  "prompt_testing_and_validation_strategy": {
    "approach": "A multi-faceted testing approach to validate prompt effectiveness and API integration.",
    "tools": [
      "Dedicated Python/JavaScript testing scripts (e.g., using `requests` in Python or `axios`/`fetch` in JS) to directly interact with `https://ai.violass.club/v1`.",
      "Postman/Insomnia collections for manual and automated API request testing.",
      "Unit tests within the API client module (developed by Kodax) to ensure correct prompt payload construction.",
      "Integration tests to verify end-to-end flow from UI input to LLM output display."
    ],
    "validation_metrics_and_criteria": {
      "format_compliance": {
        "description": "Verify that LLM outputs strictly adhere to the specified JSON schemas (e.g., 'joke' string, 'sentiment' enum, 'key_points' array of strings).",
        "method": "Automated JSON schema validation against expected structures."
      },
      "relevance_and_quality": {
        "description": "Assess the humor, originality, and appropriateness of generated jokes; the accuracy of sentiment and key points in feedback analysis; and the personalization and relevance of recommendations.",
        "method": "Combination of automated keyword/pattern matching (for basic quality checks) and human review for nuanced evaluation. For recommendations, verify that reasons logically connect to the provided user profile."
      },
      "conciseness_and_length": {
        "description": "Ensure outputs remain within 'max_tokens' limits and are concise as per prompt instructions.",
        "method": "Automated token count checks and character length validation."
      },
      "safety_and_appropriateness": {
        "description": "Confirm that all generated content is family-friendly and free from offensive or biased language.",
        "method": "Automated content moderation checks (if available via API or external service) and human review."
      },
      "consistency": {
        "description": "Evaluate if similar inputs yield consistent quality and type of outputs over multiple runs.",
        "method": "Running test suites multiple times with identical inputs and analyzing variance in outputs."
      },
      "error_handling": {
        "description": "Test how the system behaves with malformed prompts or unexpected LLM responses.",
        "method": "Injecting invalid inputs or simulating API errors to ensure graceful degradation and informative error messages."
      }
    },
    "testing_workflow": [
      "**Initial Prompt Validation:** Send raw API requests with each finalized prompt string and example inputs to the `https://ai.violass.club/v1` endpoint. Verify the immediate LLM response against the expected JSON schema and initial quality criteria.",
      "**API Client Integration Testing:** Once Kodax implements the API client, use it within test scripts to ensure the prompts are correctly encapsulated and sent via the client, and responses are parsed as expected.",
      "**Iterative Refinement:** Based on test results, adjust prompt wording, temperature, max_tokens, or add more specific instructions/examples to guide the LLM towards desired outputs. Repeat testing until optimal performance is achieved for each prompt type."
    ]
  }
}
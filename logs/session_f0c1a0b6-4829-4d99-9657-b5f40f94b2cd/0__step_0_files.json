{"README.md": "Links: [MTC|LCP](https://ai.violass.club/mtc-lcp/)\n[Demo Logs](./logs)\n\n\n# T20 Multi-Agent System\n\nT20 is a sophisticated, multi-agent framework designed to tackle complex tasks through collaborative AI. It employs an orchestrator-delegate model where a primary \"Orchestrator\" agent dynamically creates a plan and delegates sub-tasks to a team of specialized agents, each powered by different models from the Google Gemini family.\n\nThe system is built for autonomy and traceability. Once given a high-level goal, the agents work together, passing context and artifacts between steps, until the objective is met. Every action, prompt, and output is saved in a distinct session directory for easy debugging and review.\n\n---\n\n## Core Concepts\n\nThe workflow of the T20 system follows a clear, powerful pattern:\n\n1.  **Initialization**: The user provides a single, high-level goal via a command-line interface (e.g., \"Design a modern landing page for a new SaaS product\").\n2.  **Dynamic Planning**: The `Orchestrator` agent (Meta-AI) analyzes the goal and the capabilities of its team members. It then queries a powerful LLM (like Gemini 2.5 Pro) to generate a structured, step-by-step plan in JSON format. This plan outlines the roles and specific tasks required to achieve the goal.\n3.  **Task Delegation & Execution**: The `Orchestrator` proceeds through the plan, assigning each task to the appropriate specialized agent based on their role (e.g., a design task goes to `Aurora`, the Designer).\n4.  **Contextual Collaboration**: The output (artifact) of each step is saved and can be used as input for subsequent steps. This creates a chain of context, allowing agents to build upon each other's work.\n5.  **Meta-Learning & Adaptation**: A unique `Prompt Engineer` agent (Lyra) can be tasked with refining the system prompts of other agents *during* the workflow, optimizing their performance for the specific goal at hand.\n6.  **Session Logging**: The entire process\u2014from the initial plan to the final output\u2014is meticulously logged in a dedicated session folder, providing full transparency.\n\n## Features\n\n-   **Declarative Agent Definition**: Agents are defined in simple, easy-to-read YAML files.\n-   **Dynamic, AI-Generated Plans**: No hardcoded workflows. The Orchestrator creates a custom plan for every unique goal.\n-   **Role-Based Delegation**: Tasks are intelligently assigned to agents best suited for the job.\n-   **Structured LLM Outputs**: Utilizes JSON schema enforcement with Pydantic for reliable, machine-readable plans from the Orchestrator.\n-   **Stateful Sessions**: Each run is isolated in a session directory containing all artifacts, prompts, and results.\n-   **CLI-Driven**: Simple and straightforward to run from the command line.\n-   **Powered by Google Gemini**: Leverages a suite of Gemini models, from the highly capable `gemini-2.5-pro` for orchestration to the fast and efficient `gemini-2.5-flash-lite` for specialized tasks.\n\n## The Team\n\nThe system comes pre-configured with a team of specialized agents:\n\n| Name     | Role                        | Goal                                                                                         | Model                               |\n| :------- | :-------------------------- | :------------------------------------------------------------------------------------------- | :---------------------------------- |\n| **Meta-AI**  | Orchestrator                | Orchestrate tasks, manage roles, and maintain shared context.                                | `gemini-2.5-pro`                    |\n| **Lyra**     | Prompt Engineer             | Structure workflows and refine agent instructions for clarity and effectiveness.             | `gemini-2.5-flash`                  |\n| **Aurora**   | Designer                    | Generate aesthetic layouts, color palettes, typography, and UI flows.                        | `gemini-2.5-flash-lite-preview-06-17` |\n| **Kodax**    | Engineer                    | Implement designs into clean, modular, and performant code.                                  | `gemini-2.5-flash-lite-preview-06-17` |\n| **TASe**     | Task-Agnostic Step Extractor | Identify and extract each 'Task Agnostic Step' (TAS) towards the high-level goal.            | `gemini-2.5-flash-lite-preview-06-17` |\n\n## Project Structure\n\n```\nt20-multi-agent/\n\u251c\u2500\u2500 agents/                 # YAML definitions for each agent\n\u2502   \u251c\u2500\u2500 orchestrator.yaml\n\u2502   \u251c\u2500\u2500 lyra.yaml\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 prompts/                # System prompts and instructions for agents\n\u2502   \u251c\u2500\u2500 orchestrator_instructions.txt\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 runtime/                # Core Python source code for the framework\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 executor.py         # Main execution logic, agent classes, CLI entry point\n\u2502   \u2514\u2500\u2500 loader.py           # Utilities for loading configs, agents, and prompts\n\u251c\u2500\u2500 sessions/               # Output directory for all runtime sessions (auto-generated)\n\u2502   \u2514\u2500\u2500 session_.../\n\u2502       \u251c\u2500\u2500 initial_plan.json\n\u2502       \u251c\u2500\u2500 0__step_0_Lyra_result.txt\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 setup.py                # Project setup and dependencies\n```\n\n## Getting Started\n\n### Prerequisites\n\n-   Python 3.9+\n-   Git\n\n### Installation\n\n1.  **Clone the repository:**\n    ```bash\n    git clone https://github.com/your-username/t20-multi-agent.git\n    cd t20-multi-agent\n    ```\n\n2.  **Create and activate a virtual environment (recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows, use `venv\\Scripts\\activate`\n    ```\n\n3.  **Install the package and its dependencies:**\n    This command uses the `setup.py` file to install the necessary libraries and make the `t20-cli` command available.\n    ```bash\n    pip install -e .\n    ```\n\n4.  **Set up your environment variables:**\n    Create a file named `.env` in the root of the project directory and add your Google AI API key:\n    ```\n    # .env\n    GOOGLE_API_KEY=\"YOUR_API_KEY_HERE\"\n    ```\n\n## Usage\n\nThe framework is operated through the `t20-cli` command. Simply provide the high-level goal you want the agent team to accomplish as a string argument.\n\n### Example\n\nLet's ask the team to design and build a simple webpage.\n\n```bash\nt20-cli \"Design and create the HTML and CSS for a modern, minimalist landing page for a new SaaS product called 'Innovate'.\"\n```\n\n### What Happens Next\n\n1.  A new session is created in the `sessions/` directory.\n2.  `Meta-AI` (the Orchestrator) receives the goal and generates a plan, which is saved as `initial_plan.json`. The plan might look something like this:\n    -   **Step 1 (Prompt Engineer):** Refine the system prompts for the Designer and Engineer to align with a \"modern, minimalist\" aesthetic.\n    -   **Step 2 (Designer):** Generate a color palette, typography suggestions, and a layout description for the landing page.\n    -   **Step 3 (Engineer):** Take the design specifications from the Designer and write the complete HTML and CSS code.\n3.  The `Orchestrator` executes the plan step-by-step, calling the appropriate agents.\n4.  All intermediate and final outputs are saved as artifacts in the session folder. You can monitor the progress by watching the console output and exploring the generated files.\n\n```\nAfter the run is complete, you can find the final HTML and CSS code generated by `Kodax` inside the `sessions/session_<uuid>/` folder.\n```\n\nWrong, instead you get the last step's _task and _result in the session folder. Use these with Gemini, Qwen3-WebDev etc... they serve a highly-valuable purpose as templates!\n"}